{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import time\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_effort = pd.read_csv('Bike Effort Mileage Per Week.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>9/28/2015</th>\n",
       "      <th>10/5/2015</th>\n",
       "      <th>10/12/2015</th>\n",
       "      <th>10/19/2015</th>\n",
       "      <th>10/26/2015</th>\n",
       "      <th>11/2/2015</th>\n",
       "      <th>11/9/2015</th>\n",
       "      <th>11/16/2015</th>\n",
       "      <th>11/23/2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2465</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2439</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2456</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>828</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2458</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2468</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2473</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2466</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2469</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  9/28/2015  10/5/2015  10/12/2015  10/19/2015  10/26/2015  11/2/2015  11/9/2015  11/16/2015  11/23/2015\n",
       "0      2461        NaN       1.43        1.50        1.51         NaN       1.49       1.55        1.54        1.54\n",
       "1      2465       1.48       1.60        1.51        1.52         NaN       1.50       1.56        1.50        1.55\n",
       "2      2439       1.45       1.50        1.51        1.54        1.53       1.53       1.52        1.55         NaN\n",
       "3      2456       1.52       1.52        1.54         NaN         NaN        NaN        NaN         NaN        1.73\n",
       "4      2508        NaN       1.42        1.43        1.48        1.42       1.47       1.42        1.23        1.46\n",
       "5       828       1.61       1.40        1.57        1.56        1.62       1.44       1.56        1.75        2.02\n",
       "6      2458       1.50       1.55        1.53        1.51        1.23       1.40       1.53        1.39        1.52\n",
       "7      2468       1.68       1.60        1.53        1.57        1.58       1.50       1.56        1.54        1.33\n",
       "8      2473       1.59       1.62        1.55        1.57        1.58        NaN       1.50         NaN        1.60\n",
       "9      2466       1.21       1.51        1.48        1.46        1.53       1.51       1.51        1.50        1.61\n",
       "10     2469       1.50       1.53        1.50        1.50        1.50       1.49       1.51        1.51        1.53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2461, 2465, 2439, 2456, 2508, 828, 2458, 2468, 2473, 2466, 2469]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of user_ids\n",
    "users=[]\n",
    "for i in range(0, len(bike_effort)):\n",
    "    users.append(bike_effort['user_id'][i])\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a dictionary where the key is the user_id, and the values are the bike efforts in order\n",
    "n = bike_effort.shape[1]\n",
    "bike_dict={}\n",
    "for i in range(0, len(bike_effort)):\n",
    "    bike_dict[users[i]]=bike_effort.values[i][1:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{828: array([ 1.61,  1.4 ,  1.57,  1.56,  1.62,  1.44,  1.56,  1.75,  2.02]),\n",
       " 2439: array([ 1.45,  1.5 ,  1.51,  1.54,  1.53,  1.53,  1.52,  1.55,   nan]),\n",
       " 2456: array([ 1.52,  1.52,  1.54,   nan,   nan,   nan,   nan,   nan,  1.73]),\n",
       " 2458: array([ 1.5 ,  1.55,  1.53,  1.51,  1.23,  1.4 ,  1.53,  1.39,  1.52]),\n",
       " 2461: array([  nan,  1.43,  1.5 ,  1.51,   nan,  1.49,  1.55,  1.54,  1.54]),\n",
       " 2465: array([ 1.48,  1.6 ,  1.51,  1.52,   nan,  1.5 ,  1.56,  1.5 ,  1.55]),\n",
       " 2466: array([ 1.21,  1.51,  1.48,  1.46,  1.53,  1.51,  1.51,  1.5 ,  1.61]),\n",
       " 2468: array([ 1.68,  1.6 ,  1.53,  1.57,  1.58,  1.5 ,  1.56,  1.54,  1.33]),\n",
       " 2469: array([ 1.5 ,  1.53,  1.5 ,  1.5 ,  1.5 ,  1.49,  1.51,  1.51,  1.53]),\n",
       " 2473: array([ 1.59,  1.62,  1.55,  1.57,  1.58,   nan,  1.5 ,   nan,  1.6 ]),\n",
       " 2508: array([  nan,  1.42,  1.43,  1.48,  1.42,  1.47,  1.42,  1.23,  1.46])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(bike_dict[2456][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempbike_dict={}\n",
    "for biker in bike_dict:\n",
    "    new_list=[]\n",
    "    for i in bike_dict[biker]:\n",
    "        if np.isnan(i) == False:\n",
    "            new_list.append(i)\n",
    "    #biker is the user_id\n",
    "    tempbike_dict[biker]=new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{828: 1.6144444444444443,\n",
       " 2439: 1.5162500000000001,\n",
       " 2456: 1.5775000000000001,\n",
       " 2458: 1.4622222222222223,\n",
       " 2461: 1.5085714285714285,\n",
       " 2465: 1.5274999999999999,\n",
       " 2466: 1.48,\n",
       " 2468: 1.5433333333333334,\n",
       " 2469: 1.5077777777777777,\n",
       " 2473: 1.5728571428571427,\n",
       " 2508: 1.41625}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean performance:\n",
    "user_means={}\n",
    "for u in users:\n",
    "    user_means[u]= np.mean(tempbike_dict[u])\n",
    "user_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BUCKBEAK\\Anaconda\\lib\\site-packages\\matplotlib\\figure.py:1653: UserWarning: This figure includes Axes that are not compatible with tight_layout, so its results might be incorrect.\n",
      "  warnings.warn(\"This figure includes Axes that are not \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAWYCAYAAACrgjAPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDPwXTLYDEqLEwKUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ef9e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(10, 20), tight_layout=True)\n",
    "for ax, u in zip(axes.ravel(),users):\n",
    "    ax.plot(bike_dict[u], 'o')\n",
    "    ax.set_xlim(-.2, 8.2)\n",
    "    ax.set_ylim(1.15, 2.1)\n",
    "    ax.set_xlabel('Week')\n",
    "    ax.set_ylabel('Mileage')\n",
    "    ax.set_title(u)\n",
    "    ax.axhline(user_means[u], color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Same Analysis as Race Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Simple OLS Regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>bike_period</th>\n",
       "      <th>resting_heart_rate</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>time_in_bed</th>\n",
       "      <th>latency</th>\n",
       "      <th>rem_sleep_duration</th>\n",
       "      <th>slow_wave_sleep_duration</th>\n",
       "      <th>light_sleep_duration</th>\n",
       "      <th>wake_duration</th>\n",
       "      <th>cycles_count</th>\n",
       "      <th>score</th>\n",
       "      <th>recovery_score</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>user_2439</th>\n",
       "      <th>user_2456</th>\n",
       "      <th>user_2458</th>\n",
       "      <th>user_2465</th>\n",
       "      <th>user_2466</th>\n",
       "      <th>user_2468</th>\n",
       "      <th>user_2469</th>\n",
       "      <th>user_2473</th>\n",
       "      <th>user_2508</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "      <td>1</td>\n",
       "      <td>45.840000</td>\n",
       "      <td>0.071358</td>\n",
       "      <td>32839321.5714</td>\n",
       "      <td>1602048.400000</td>\n",
       "      <td>4230571.42857</td>\n",
       "      <td>3967428.43810</td>\n",
       "      <td>20112571.4286</td>\n",
       "      <td>4433714.17143</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>82.361905</td>\n",
       "      <td>65.180000</td>\n",
       "      <td>28310571.2952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>46.321429</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>34242557.5714</td>\n",
       "      <td>1394205.142860</td>\n",
       "      <td>5795357.14286</td>\n",
       "      <td>3725357.07143</td>\n",
       "      <td>21417857.1429</td>\n",
       "      <td>3306428.42857</td>\n",
       "      <td>7.321429</td>\n",
       "      <td>95.107143</td>\n",
       "      <td>78.642857</td>\n",
       "      <td>30938571.3571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>3</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>0.050283</td>\n",
       "      <td>33588485.8000</td>\n",
       "      <td>1143982.300000</td>\n",
       "      <td>5506000.00000</td>\n",
       "      <td>3923000.00000</td>\n",
       "      <td>20757000.0000</td>\n",
       "      <td>3390999.93333</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>50.366667</td>\n",
       "      <td>30186000.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>828</td>\n",
       "      <td>4</td>\n",
       "      <td>47.714286</td>\n",
       "      <td>0.071248</td>\n",
       "      <td>35214528.2381</td>\n",
       "      <td>1634822.619050</td>\n",
       "      <td>1757142.85714</td>\n",
       "      <td>7674285.71429</td>\n",
       "      <td>18864285.7143</td>\n",
       "      <td>6920000.00000</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>87.333333</td>\n",
       "      <td>62.285714</td>\n",
       "      <td>28295714.2857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>828</td>\n",
       "      <td>5</td>\n",
       "      <td>45.384615</td>\n",
       "      <td>0.067056</td>\n",
       "      <td>35683863.9744</td>\n",
       "      <td>1392863.461540</td>\n",
       "      <td>1517692.30769</td>\n",
       "      <td>7470000.00000</td>\n",
       "      <td>20396153.8462</td>\n",
       "      <td>6299230.76923</td>\n",
       "      <td>3.358974</td>\n",
       "      <td>88.461538</td>\n",
       "      <td>53.692308</td>\n",
       "      <td>29383846.1538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>828</td>\n",
       "      <td>6</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.060430</td>\n",
       "      <td>35612000.0000</td>\n",
       "      <td>1122353.333330</td>\n",
       "      <td>2222000.00000</td>\n",
       "      <td>9090000.00000</td>\n",
       "      <td>18538000.0000</td>\n",
       "      <td>5776000.00000</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>85.733333</td>\n",
       "      <td>51.533333</td>\n",
       "      <td>29850000.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>828</td>\n",
       "      <td>7</td>\n",
       "      <td>44.771429</td>\n",
       "      <td>0.065066</td>\n",
       "      <td>35897440.7429</td>\n",
       "      <td>896221.514286</td>\n",
       "      <td>1579714.28571</td>\n",
       "      <td>7746000.00000</td>\n",
       "      <td>20193428.5714</td>\n",
       "      <td>6378000.00000</td>\n",
       "      <td>4.057143</td>\n",
       "      <td>94.514286</td>\n",
       "      <td>66.085714</td>\n",
       "      <td>29519142.8571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>828</td>\n",
       "      <td>8</td>\n",
       "      <td>45.357143</td>\n",
       "      <td>0.074717</td>\n",
       "      <td>38029717.7143</td>\n",
       "      <td>1217814.321430</td>\n",
       "      <td>3429642.85714</td>\n",
       "      <td>8664642.85714</td>\n",
       "      <td>18999642.8571</td>\n",
       "      <td>6936428.57143</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>93.678571</td>\n",
       "      <td>63.392857</td>\n",
       "      <td>31093928.5714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>828</td>\n",
       "      <td>9</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>33960000.0000</td>\n",
       "      <td>990941.000000</td>\n",
       "      <td>2010000.00000</td>\n",
       "      <td>4440000.00000</td>\n",
       "      <td>22350000.0000</td>\n",
       "      <td>5040000.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>28800000.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2439</td>\n",
       "      <td>1</td>\n",
       "      <td>43.979798</td>\n",
       "      <td>0.145445</td>\n",
       "      <td>31539133.9596</td>\n",
       "      <td>1298529.121210</td>\n",
       "      <td>3969090.90909</td>\n",
       "      <td>3264848.48485</td>\n",
       "      <td>22241818.1313</td>\n",
       "      <td>2143939.39394</td>\n",
       "      <td>5.797980</td>\n",
       "      <td>85.939394</td>\n",
       "      <td>71.919192</td>\n",
       "      <td>29475757.5253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2439</td>\n",
       "      <td>2</td>\n",
       "      <td>45.964286</td>\n",
       "      <td>0.120886</td>\n",
       "      <td>29646299.7500</td>\n",
       "      <td>1427141.785710</td>\n",
       "      <td>2942142.85714</td>\n",
       "      <td>2743928.42857</td>\n",
       "      <td>22182857.1429</td>\n",
       "      <td>1848214.28571</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>89.035714</td>\n",
       "      <td>70.928571</td>\n",
       "      <td>27868928.4286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2439</td>\n",
       "      <td>3</td>\n",
       "      <td>47.187500</td>\n",
       "      <td>0.131832</td>\n",
       "      <td>32941763.5000</td>\n",
       "      <td>900271.218750</td>\n",
       "      <td>2701875.00000</td>\n",
       "      <td>1715625.00000</td>\n",
       "      <td>25756875.0000</td>\n",
       "      <td>2851875.00000</td>\n",
       "      <td>4.343750</td>\n",
       "      <td>93.968750</td>\n",
       "      <td>80.781250</td>\n",
       "      <td>30174375.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2439</td>\n",
       "      <td>4</td>\n",
       "      <td>45.285714</td>\n",
       "      <td>0.132433</td>\n",
       "      <td>30310481.3810</td>\n",
       "      <td>892018.619048</td>\n",
       "      <td>2794285.71429</td>\n",
       "      <td>5237142.85714</td>\n",
       "      <td>18151428.5714</td>\n",
       "      <td>4208571.42857</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>67.095238</td>\n",
       "      <td>26182857.1429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2439</td>\n",
       "      <td>5</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>0.150156</td>\n",
       "      <td>27478716.1667</td>\n",
       "      <td>1412255.305560</td>\n",
       "      <td>3008333.33333</td>\n",
       "      <td>3525833.33333</td>\n",
       "      <td>16939166.6667</td>\n",
       "      <td>4076666.66667</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>70.722222</td>\n",
       "      <td>71.111111</td>\n",
       "      <td>23473333.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2439</td>\n",
       "      <td>6</td>\n",
       "      <td>46.428571</td>\n",
       "      <td>0.128796</td>\n",
       "      <td>27870847.3929</td>\n",
       "      <td>1252047.571430</td>\n",
       "      <td>3363214.28571</td>\n",
       "      <td>4437857.14286</td>\n",
       "      <td>16550357.1429</td>\n",
       "      <td>3566785.71429</td>\n",
       "      <td>4.642857</td>\n",
       "      <td>74.821429</td>\n",
       "      <td>60.892857</td>\n",
       "      <td>24351428.5714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2439</td>\n",
       "      <td>7</td>\n",
       "      <td>46.142857</td>\n",
       "      <td>0.134214</td>\n",
       "      <td>26062830.5714</td>\n",
       "      <td>1125032.785710</td>\n",
       "      <td>2485714.28571</td>\n",
       "      <td>2350714.28571</td>\n",
       "      <td>17966785.7143</td>\n",
       "      <td>3324642.85714</td>\n",
       "      <td>2.892857</td>\n",
       "      <td>71.607143</td>\n",
       "      <td>67.571429</td>\n",
       "      <td>22803214.2857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2439</td>\n",
       "      <td>8</td>\n",
       "      <td>44.964286</td>\n",
       "      <td>0.148276</td>\n",
       "      <td>28916996.3929</td>\n",
       "      <td>1461126.571430</td>\n",
       "      <td>3860357.14286</td>\n",
       "      <td>5950714.28571</td>\n",
       "      <td>15071785.7143</td>\n",
       "      <td>4108928.57143</td>\n",
       "      <td>5.107143</td>\n",
       "      <td>69.714286</td>\n",
       "      <td>69.464286</td>\n",
       "      <td>24882857.1429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2439</td>\n",
       "      <td>9</td>\n",
       "      <td>41.900000</td>\n",
       "      <td>0.178011</td>\n",
       "      <td>24815892.0000</td>\n",
       "      <td>1164509.900000</td>\n",
       "      <td>3501000.00000</td>\n",
       "      <td>5310000.00000</td>\n",
       "      <td>12327000.0000</td>\n",
       "      <td>3744000.00000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>60.100000</td>\n",
       "      <td>71.900000</td>\n",
       "      <td>21138000.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2456</td>\n",
       "      <td>1</td>\n",
       "      <td>44.684211</td>\n",
       "      <td>0.076940</td>\n",
       "      <td>31074382.2421</td>\n",
       "      <td>901804.273684</td>\n",
       "      <td>5123999.92632</td>\n",
       "      <td>3464210.52632</td>\n",
       "      <td>19160210.5263</td>\n",
       "      <td>3363157.89474</td>\n",
       "      <td>5.778947</td>\n",
       "      <td>68.505263</td>\n",
       "      <td>56.357895</td>\n",
       "      <td>27748420.9789</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2456</td>\n",
       "      <td>2</td>\n",
       "      <td>46.454545</td>\n",
       "      <td>0.070956</td>\n",
       "      <td>31363921.6364</td>\n",
       "      <td>660788.727273</td>\n",
       "      <td>4160454.54545</td>\n",
       "      <td>3383181.81818</td>\n",
       "      <td>21426818.1818</td>\n",
       "      <td>2428636.36364</td>\n",
       "      <td>5.227273</td>\n",
       "      <td>73.681818</td>\n",
       "      <td>59.045455</td>\n",
       "      <td>28970454.5455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  user_id  bike_period  resting_heart_rate  hrv_rmssd    time_in_bed         latency  rem_sleep_duration  slow_wave_sleep_duration  light_sleep_duration  wake_duration  cycles_count      score  recovery_score  sleep_duration  user_2439  user_2456  user_2458  user_2465  user_2466  user_2468  user_2469  user_2473  user_2508  distance\n",
       "0            0      828            1           45.840000   0.071358  32839321.5714  1602048.400000       4230571.42857             3967428.43810         20112571.4286  4433714.17143      6.110000  82.361905       65.180000   28310571.2952          0          0          0          0          0          0          0          0          0      1.61\n",
       "1            1      828            2           46.321429   0.101769  34242557.5714  1394205.142860       5795357.14286             3725357.07143         21417857.1429  3306428.42857      7.321429  95.107143       78.642857   30938571.3571          0          0          0          0          0          0          0          0          0      1.40\n",
       "2            2      828            3           45.600000   0.050283  33588485.8000  1143982.300000       5506000.00000             3923000.00000         20757000.0000  3390999.93333      7.033333  87.400000       50.366667   30186000.0000          0          0          0          0          0          0          0          0          0      1.57\n",
       "3            3      828            4           47.714286   0.071248  35214528.2381  1634822.619050       1757142.85714             7674285.71429         18864285.7143  6920000.00000      3.809524  87.333333       62.285714   28295714.2857          0          0          0          0          0          0          0          0          0      1.56\n",
       "4            4      828            5           45.384615   0.067056  35683863.9744  1392863.461540       1517692.30769             7470000.00000         20396153.8462  6299230.76923      3.358974  88.461538       53.692308   29383846.1538          0          0          0          0          0          0          0          0          0      1.62\n",
       "5            5      828            6           46.000000   0.060430  35612000.0000  1122353.333330       2222000.00000             9090000.00000         18538000.0000  5776000.00000      4.466667  85.733333       51.533333   29850000.0000          0          0          0          0          0          0          0          0          0      1.44\n",
       "6            6      828            7           44.771429   0.065066  35897440.7429   896221.514286       1579714.28571             7746000.00000         20193428.5714  6378000.00000      4.057143  94.514286       66.085714   29519142.8571          0          0          0          0          0          0          0          0          0      1.56\n",
       "7            7      828            8           45.357143   0.074717  38029717.7143  1217814.321430       3429642.85714             8664642.85714         18999642.8571  6936428.57143      6.642857  93.678571       63.392857   31093928.5714          0          0          0          0          0          0          0          0          0      1.75\n",
       "8            8      828            9           45.000000   0.079693  33960000.0000   990941.000000       2010000.00000             4440000.00000         22350000.0000  5040000.00000      3.000000  93.000000       62.000000   28800000.0000          0          0          0          0          0          0          0          0          0      2.02\n",
       "9            9     2439            1           43.979798   0.145445  31539133.9596  1298529.121210       3969090.90909             3264848.48485         22241818.1313  2143939.39394      5.797980  85.939394       71.919192   29475757.5253          1          0          0          0          0          0          0          0          0      1.45\n",
       "10          10     2439            2           45.964286   0.120886  29646299.7500  1427141.785710       2942142.85714             2743928.42857         22182857.1429  1848214.28571      4.285714  89.035714       70.928571   27868928.4286          1          0          0          0          0          0          0          0          0      1.50\n",
       "11          11     2439            3           47.187500   0.131832  32941763.5000   900271.218750       2701875.00000             1715625.00000         25756875.0000  2851875.00000      4.343750  93.968750       80.781250   30174375.0000          1          0          0          0          0          0          0          0          0      1.51\n",
       "12          12     2439            4           45.285714   0.132433  30310481.3810   892018.619048       2794285.71429             5237142.85714         18151428.5714  4208571.42857      4.428571  81.666667       67.095238   26182857.1429          1          0          0          0          0          0          0          0          0      1.54\n",
       "13          13     2439            5           46.666667   0.150156  27478716.1667  1412255.305560       3008333.33333             3525833.33333         16939166.6667  4076666.66667      3.722222  70.722222       71.111111   23473333.3333          1          0          0          0          0          0          0          0          0      1.53\n",
       "14          14     2439            6           46.428571   0.128796  27870847.3929  1252047.571430       3363214.28571             4437857.14286         16550357.1429  3566785.71429      4.642857  74.821429       60.892857   24351428.5714          1          0          0          0          0          0          0          0          0      1.53\n",
       "15          15     2439            7           46.142857   0.134214  26062830.5714  1125032.785710       2485714.28571             2350714.28571         17966785.7143  3324642.85714      2.892857  71.607143       67.571429   22803214.2857          1          0          0          0          0          0          0          0          0      1.52\n",
       "16          16     2439            8           44.964286   0.148276  28916996.3929  1461126.571430       3860357.14286             5950714.28571         15071785.7143  4108928.57143      5.107143  69.714286       69.464286   24882857.1429          1          0          0          0          0          0          0          0          0      1.55\n",
       "17          17     2439            9           41.900000   0.178011  24815892.0000  1164509.900000       3501000.00000             5310000.00000         12327000.0000  3744000.00000      3.200000  60.100000       71.900000   21138000.0000          1          0          0          0          0          0          0          0          0       NaN\n",
       "18          18     2456            1           44.684211   0.076940  31074382.2421   901804.273684       5123999.92632             3464210.52632         19160210.5263  3363157.89474      5.778947  68.505263       56.357895   27748420.9789          0          1          0          0          0          0          0          0          0      1.52\n",
       "19          19     2456            2           46.454545   0.070956  31363921.6364   660788.727273       4160454.54545             3383181.81818         21426818.1818  2428636.36364      5.227273  73.681818       59.045455   28970454.5455          0          1          0          0          0          0          0          0          0      1.52"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These data contain weighted averages for ALL days before a race\n",
    "\n",
    "df = pd.read_csv('final_bike_df.csv')\n",
    "df2 = pd.read_csv('workout_final_bike_df.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merging the two dataframes\n",
    "reg_df = pd.merge(df, df2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'user_id', u'bike_period', u'resting_heart_rate', u'hrv_rmssd', u'time_in_bed', u'latency', u'rem_sleep_duration', u'slow_wave_sleep_duration', u'light_sleep_duration', u'wake_duration', u'cycles_count', u'score', u'recovery_score', u'sleep_duration', u'user_2439', u'user_2456', u'user_2458', u'user_2465', u'user_2466', u'user_2468', u'user_2469', u'user_2473', u'user_2508', u'distance', u'z1', u'z2', u'z3', u'z4', u'z5'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the first column, which was just the index from when saving the dataframe to a csv earlier\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "reg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>bike_period</th>\n",
       "      <th>resting_heart_rate</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>time_in_bed</th>\n",
       "      <th>latency</th>\n",
       "      <th>rem_sleep_duration</th>\n",
       "      <th>slow_wave_sleep_duration</th>\n",
       "      <th>light_sleep_duration</th>\n",
       "      <th>wake_duration</th>\n",
       "      <th>cycles_count</th>\n",
       "      <th>score</th>\n",
       "      <th>recovery_score</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>user_2439</th>\n",
       "      <th>user_2456</th>\n",
       "      <th>user_2458</th>\n",
       "      <th>user_2465</th>\n",
       "      <th>user_2466</th>\n",
       "      <th>user_2468</th>\n",
       "      <th>user_2469</th>\n",
       "      <th>user_2473</th>\n",
       "      <th>user_2508</th>\n",
       "      <th>distance</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>z3</th>\n",
       "      <th>z4</th>\n",
       "      <th>z5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>828</td>\n",
       "      <td>1</td>\n",
       "      <td>45.840000</td>\n",
       "      <td>0.071358</td>\n",
       "      <td>32839321.5714</td>\n",
       "      <td>1602048.400000</td>\n",
       "      <td>4230571.42857</td>\n",
       "      <td>3967428.43810</td>\n",
       "      <td>20112571.4286</td>\n",
       "      <td>4433714.17143</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>82.361905</td>\n",
       "      <td>65.180000</td>\n",
       "      <td>28310571.2952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>552.714286</td>\n",
       "      <td>705.054945</td>\n",
       "      <td>804.956044</td>\n",
       "      <td>1670.934066</td>\n",
       "      <td>281.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>46.321429</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>34242557.5714</td>\n",
       "      <td>1394205.142860</td>\n",
       "      <td>5795357.14286</td>\n",
       "      <td>3725357.07143</td>\n",
       "      <td>21417857.1429</td>\n",
       "      <td>3306428.42857</td>\n",
       "      <td>7.321429</td>\n",
       "      <td>95.107143</td>\n",
       "      <td>78.642857</td>\n",
       "      <td>30938571.3571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>718.142857</td>\n",
       "      <td>1331.619048</td>\n",
       "      <td>2212.047619</td>\n",
       "      <td>2385.952381</td>\n",
       "      <td>235.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>828</td>\n",
       "      <td>3</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>0.050283</td>\n",
       "      <td>33588485.8000</td>\n",
       "      <td>1143982.300000</td>\n",
       "      <td>5506000.00000</td>\n",
       "      <td>3923000.00000</td>\n",
       "      <td>20757000.0000</td>\n",
       "      <td>3390999.93333</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>50.366667</td>\n",
       "      <td>30186000.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>412.321429</td>\n",
       "      <td>270.714286</td>\n",
       "      <td>674.607143</td>\n",
       "      <td>1390.142857</td>\n",
       "      <td>438.964286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>828</td>\n",
       "      <td>4</td>\n",
       "      <td>47.714286</td>\n",
       "      <td>0.071248</td>\n",
       "      <td>35214528.2381</td>\n",
       "      <td>1634822.619050</td>\n",
       "      <td>1757142.85714</td>\n",
       "      <td>7674285.71429</td>\n",
       "      <td>18864285.7143</td>\n",
       "      <td>6920000.00000</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>87.333333</td>\n",
       "      <td>62.285714</td>\n",
       "      <td>28295714.2857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>944.733333</td>\n",
       "      <td>898.600000</td>\n",
       "      <td>784.466667</td>\n",
       "      <td>1819.200000</td>\n",
       "      <td>388.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>828</td>\n",
       "      <td>5</td>\n",
       "      <td>45.384615</td>\n",
       "      <td>0.067056</td>\n",
       "      <td>35683863.9744</td>\n",
       "      <td>1392863.461540</td>\n",
       "      <td>1517692.30769</td>\n",
       "      <td>7470000.00000</td>\n",
       "      <td>20396153.8462</td>\n",
       "      <td>6299230.76923</td>\n",
       "      <td>3.358974</td>\n",
       "      <td>88.461538</td>\n",
       "      <td>53.692308</td>\n",
       "      <td>29383846.1538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>641.055556</td>\n",
       "      <td>721.611111</td>\n",
       "      <td>580.444444</td>\n",
       "      <td>1651.055556</td>\n",
       "      <td>222.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>828</td>\n",
       "      <td>6</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.060430</td>\n",
       "      <td>35612000.0000</td>\n",
       "      <td>1122353.333330</td>\n",
       "      <td>2222000.00000</td>\n",
       "      <td>9090000.00000</td>\n",
       "      <td>18538000.0000</td>\n",
       "      <td>5776000.00000</td>\n",
       "      <td>4.466667</td>\n",
       "      <td>85.733333</td>\n",
       "      <td>51.533333</td>\n",
       "      <td>29850000.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>976.500000</td>\n",
       "      <td>811.700000</td>\n",
       "      <td>748.900000</td>\n",
       "      <td>2692.000000</td>\n",
       "      <td>682.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>828</td>\n",
       "      <td>7</td>\n",
       "      <td>44.771429</td>\n",
       "      <td>0.065066</td>\n",
       "      <td>35897440.7429</td>\n",
       "      <td>896221.514286</td>\n",
       "      <td>1579714.28571</td>\n",
       "      <td>7746000.00000</td>\n",
       "      <td>20193428.5714</td>\n",
       "      <td>6378000.00000</td>\n",
       "      <td>4.057143</td>\n",
       "      <td>94.514286</td>\n",
       "      <td>66.085714</td>\n",
       "      <td>29519142.8571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>744.178571</td>\n",
       "      <td>628.214286</td>\n",
       "      <td>917.571429</td>\n",
       "      <td>2152.107143</td>\n",
       "      <td>200.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>828</td>\n",
       "      <td>8</td>\n",
       "      <td>45.357143</td>\n",
       "      <td>0.074717</td>\n",
       "      <td>38029717.7143</td>\n",
       "      <td>1217814.321430</td>\n",
       "      <td>3429642.85714</td>\n",
       "      <td>8664642.85714</td>\n",
       "      <td>18999642.8571</td>\n",
       "      <td>6936428.57143</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>93.678571</td>\n",
       "      <td>63.392857</td>\n",
       "      <td>31093928.5714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>620.714286</td>\n",
       "      <td>742.047619</td>\n",
       "      <td>1019.190476</td>\n",
       "      <td>2360.619048</td>\n",
       "      <td>312.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>828</td>\n",
       "      <td>9</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>33960000.0000</td>\n",
       "      <td>990941.000000</td>\n",
       "      <td>2010000.00000</td>\n",
       "      <td>4440000.00000</td>\n",
       "      <td>22350000.0000</td>\n",
       "      <td>5040000.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>28800000.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>89.066667</td>\n",
       "      <td>84.200000</td>\n",
       "      <td>54.866667</td>\n",
       "      <td>121.933333</td>\n",
       "      <td>5.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2439</td>\n",
       "      <td>1</td>\n",
       "      <td>43.979798</td>\n",
       "      <td>0.145445</td>\n",
       "      <td>31539133.9596</td>\n",
       "      <td>1298529.121210</td>\n",
       "      <td>3969090.90909</td>\n",
       "      <td>3264848.48485</td>\n",
       "      <td>22241818.1313</td>\n",
       "      <td>2143939.39394</td>\n",
       "      <td>5.797980</td>\n",
       "      <td>85.939394</td>\n",
       "      <td>71.919192</td>\n",
       "      <td>29475757.5253</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>441.714286</td>\n",
       "      <td>824.560440</td>\n",
       "      <td>753.604396</td>\n",
       "      <td>1083.406593</td>\n",
       "      <td>4.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2439</td>\n",
       "      <td>2</td>\n",
       "      <td>45.964286</td>\n",
       "      <td>0.120886</td>\n",
       "      <td>29646299.7500</td>\n",
       "      <td>1427141.785710</td>\n",
       "      <td>2942142.85714</td>\n",
       "      <td>2743928.42857</td>\n",
       "      <td>22182857.1429</td>\n",
       "      <td>1848214.28571</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>89.035714</td>\n",
       "      <td>70.928571</td>\n",
       "      <td>27868928.4286</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>352.476190</td>\n",
       "      <td>736.095238</td>\n",
       "      <td>660.952381</td>\n",
       "      <td>256.333333</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2439</td>\n",
       "      <td>3</td>\n",
       "      <td>47.187500</td>\n",
       "      <td>0.131832</td>\n",
       "      <td>32941763.5000</td>\n",
       "      <td>900271.218750</td>\n",
       "      <td>2701875.00000</td>\n",
       "      <td>1715625.00000</td>\n",
       "      <td>25756875.0000</td>\n",
       "      <td>2851875.00000</td>\n",
       "      <td>4.343750</td>\n",
       "      <td>93.968750</td>\n",
       "      <td>80.781250</td>\n",
       "      <td>30174375.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.51</td>\n",
       "      <td>474.500000</td>\n",
       "      <td>477.214286</td>\n",
       "      <td>965.035714</td>\n",
       "      <td>819.357143</td>\n",
       "      <td>18.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2439</td>\n",
       "      <td>4</td>\n",
       "      <td>45.285714</td>\n",
       "      <td>0.132433</td>\n",
       "      <td>30310481.3810</td>\n",
       "      <td>892018.619048</td>\n",
       "      <td>2794285.71429</td>\n",
       "      <td>5237142.85714</td>\n",
       "      <td>18151428.5714</td>\n",
       "      <td>4208571.42857</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>81.666667</td>\n",
       "      <td>67.095238</td>\n",
       "      <td>26182857.1429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>121.200000</td>\n",
       "      <td>343.333333</td>\n",
       "      <td>731.933333</td>\n",
       "      <td>826.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2439</td>\n",
       "      <td>5</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>0.150156</td>\n",
       "      <td>27478716.1667</td>\n",
       "      <td>1412255.305560</td>\n",
       "      <td>3008333.33333</td>\n",
       "      <td>3525833.33333</td>\n",
       "      <td>16939166.6667</td>\n",
       "      <td>4076666.66667</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>70.722222</td>\n",
       "      <td>71.111111</td>\n",
       "      <td>23473333.3333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1362.964286</td>\n",
       "      <td>2185.928571</td>\n",
       "      <td>1237.750000</td>\n",
       "      <td>808.428571</td>\n",
       "      <td>7.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2439</td>\n",
       "      <td>6</td>\n",
       "      <td>46.428571</td>\n",
       "      <td>0.128796</td>\n",
       "      <td>27870847.3929</td>\n",
       "      <td>1252047.571430</td>\n",
       "      <td>3363214.28571</td>\n",
       "      <td>4437857.14286</td>\n",
       "      <td>16550357.1429</td>\n",
       "      <td>3566785.71429</td>\n",
       "      <td>4.642857</td>\n",
       "      <td>74.821429</td>\n",
       "      <td>60.892857</td>\n",
       "      <td>24351428.5714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1210.476190</td>\n",
       "      <td>2708.285714</td>\n",
       "      <td>2120.714286</td>\n",
       "      <td>194.285714</td>\n",
       "      <td>17.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2439</td>\n",
       "      <td>7</td>\n",
       "      <td>46.142857</td>\n",
       "      <td>0.134214</td>\n",
       "      <td>26062830.5714</td>\n",
       "      <td>1125032.785710</td>\n",
       "      <td>2485714.28571</td>\n",
       "      <td>2350714.28571</td>\n",
       "      <td>17966785.7143</td>\n",
       "      <td>3324642.85714</td>\n",
       "      <td>2.892857</td>\n",
       "      <td>71.607143</td>\n",
       "      <td>67.571429</td>\n",
       "      <td>22803214.2857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>511.000000</td>\n",
       "      <td>1718.428571</td>\n",
       "      <td>1695.095238</td>\n",
       "      <td>1012.380952</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2439</td>\n",
       "      <td>8</td>\n",
       "      <td>44.964286</td>\n",
       "      <td>0.148276</td>\n",
       "      <td>28916996.3929</td>\n",
       "      <td>1461126.571430</td>\n",
       "      <td>3860357.14286</td>\n",
       "      <td>5950714.28571</td>\n",
       "      <td>15071785.7143</td>\n",
       "      <td>4108928.57143</td>\n",
       "      <td>5.107143</td>\n",
       "      <td>69.714286</td>\n",
       "      <td>69.464286</td>\n",
       "      <td>24882857.1429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2159.857143</td>\n",
       "      <td>2698.047619</td>\n",
       "      <td>1061.000000</td>\n",
       "      <td>449.047619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2439</td>\n",
       "      <td>9</td>\n",
       "      <td>41.900000</td>\n",
       "      <td>0.178011</td>\n",
       "      <td>24815892.0000</td>\n",
       "      <td>1164509.900000</td>\n",
       "      <td>3501000.00000</td>\n",
       "      <td>5310000.00000</td>\n",
       "      <td>12327000.0000</td>\n",
       "      <td>3744000.00000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>60.100000</td>\n",
       "      <td>71.900000</td>\n",
       "      <td>21138000.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1151.066667</td>\n",
       "      <td>1832.066667</td>\n",
       "      <td>748.066667</td>\n",
       "      <td>474.733333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2456</td>\n",
       "      <td>1</td>\n",
       "      <td>44.684211</td>\n",
       "      <td>0.076940</td>\n",
       "      <td>31074382.2421</td>\n",
       "      <td>901804.273684</td>\n",
       "      <td>5123999.92632</td>\n",
       "      <td>3464210.52632</td>\n",
       "      <td>19160210.5263</td>\n",
       "      <td>3363157.89474</td>\n",
       "      <td>5.778947</td>\n",
       "      <td>68.505263</td>\n",
       "      <td>56.357895</td>\n",
       "      <td>27748420.9789</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>693.538462</td>\n",
       "      <td>626.912088</td>\n",
       "      <td>652.692308</td>\n",
       "      <td>1552.285714</td>\n",
       "      <td>1845.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2456</td>\n",
       "      <td>2</td>\n",
       "      <td>46.454545</td>\n",
       "      <td>0.070956</td>\n",
       "      <td>31363921.6364</td>\n",
       "      <td>660788.727273</td>\n",
       "      <td>4160454.54545</td>\n",
       "      <td>3383181.81818</td>\n",
       "      <td>21426818.1818</td>\n",
       "      <td>2428636.36364</td>\n",
       "      <td>5.227273</td>\n",
       "      <td>73.681818</td>\n",
       "      <td>59.045455</td>\n",
       "      <td>28970454.5455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>545.619048</td>\n",
       "      <td>499.047619</td>\n",
       "      <td>405.380952</td>\n",
       "      <td>1728.142857</td>\n",
       "      <td>2647.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  bike_period  resting_heart_rate  hrv_rmssd    time_in_bed         latency  rem_sleep_duration  slow_wave_sleep_duration  light_sleep_duration  wake_duration  cycles_count      score  recovery_score  sleep_duration  user_2439  user_2456  user_2458  user_2465  user_2466  user_2468  user_2469  user_2473  user_2508  distance           z1           z2           z3           z4           z5\n",
       "0       828            1           45.840000   0.071358  32839321.5714  1602048.400000       4230571.42857             3967428.43810         20112571.4286  4433714.17143      6.110000  82.361905       65.180000   28310571.2952          0          0          0          0          0          0          0          0          0      1.61   552.714286   705.054945   804.956044  1670.934066   281.527473\n",
       "1       828            2           46.321429   0.101769  34242557.5714  1394205.142860       5795357.14286             3725357.07143         21417857.1429  3306428.42857      7.321429  95.107143       78.642857   30938571.3571          0          0          0          0          0          0          0          0          0      1.40   718.142857  1331.619048  2212.047619  2385.952381   235.190476\n",
       "2       828            3           45.600000   0.050283  33588485.8000  1143982.300000       5506000.00000             3923000.00000         20757000.0000  3390999.93333      7.033333  87.400000       50.366667   30186000.0000          0          0          0          0          0          0          0          0          0      1.57   412.321429   270.714286   674.607143  1390.142857   438.964286\n",
       "3       828            4           47.714286   0.071248  35214528.2381  1634822.619050       1757142.85714             7674285.71429         18864285.7143  6920000.00000      3.809524  87.333333       62.285714   28295714.2857          0          0          0          0          0          0          0          0          0      1.56   944.733333   898.600000   784.466667  1819.200000   388.466667\n",
       "4       828            5           45.384615   0.067056  35683863.9744  1392863.461540       1517692.30769             7470000.00000         20396153.8462  6299230.76923      3.358974  88.461538       53.692308   29383846.1538          0          0          0          0          0          0          0          0          0      1.62   641.055556   721.611111   580.444444  1651.055556   222.138889\n",
       "5       828            6           46.000000   0.060430  35612000.0000  1122353.333330       2222000.00000             9090000.00000         18538000.0000  5776000.00000      4.466667  85.733333       51.533333   29850000.0000          0          0          0          0          0          0          0          0          0      1.44   976.500000   811.700000   748.900000  2692.000000   682.800000\n",
       "6       828            7           44.771429   0.065066  35897440.7429   896221.514286       1579714.28571             7746000.00000         20193428.5714  6378000.00000      4.057143  94.514286       66.085714   29519142.8571          0          0          0          0          0          0          0          0          0      1.56   744.178571   628.214286   917.571429  2152.107143   200.607143\n",
       "7       828            8           45.357143   0.074717  38029717.7143  1217814.321430       3429642.85714             8664642.85714         18999642.8571  6936428.57143      6.642857  93.678571       63.392857   31093928.5714          0          0          0          0          0          0          0          0          0      1.75   620.714286   742.047619  1019.190476  2360.619048   312.666667\n",
       "8       828            9           45.000000   0.079693  33960000.0000   990941.000000       2010000.00000             4440000.00000         22350000.0000  5040000.00000      3.000000  93.000000       62.000000   28800000.0000          0          0          0          0          0          0          0          0          0      2.02    89.066667    84.200000    54.866667   121.933333     5.200000\n",
       "9      2439            1           43.979798   0.145445  31539133.9596  1298529.121210       3969090.90909             3264848.48485         22241818.1313  2143939.39394      5.797980  85.939394       71.919192   29475757.5253          1          0          0          0          0          0          0          0          0      1.45   441.714286   824.560440   753.604396  1083.406593     4.120879\n",
       "10     2439            2           45.964286   0.120886  29646299.7500  1427141.785710       2942142.85714             2743928.42857         22182857.1429  1848214.28571      4.285714  89.035714       70.928571   27868928.4286          1          0          0          0          0          0          0          0          0      1.50   352.476190   736.095238   660.952381   256.333333     8.333333\n",
       "11     2439            3           47.187500   0.131832  32941763.5000   900271.218750       2701875.00000             1715625.00000         25756875.0000  2851875.00000      4.343750  93.968750       80.781250   30174375.0000          1          0          0          0          0          0          0          0          0      1.51   474.500000   477.214286   965.035714   819.357143    18.142857\n",
       "12     2439            4           45.285714   0.132433  30310481.3810   892018.619048       2794285.71429             5237142.85714         18151428.5714  4208571.42857      4.428571  81.666667       67.095238   26182857.1429          1          0          0          0          0          0          0          0          0      1.54   121.200000   343.333333   731.933333   826.000000     0.000000\n",
       "13     2439            5           46.666667   0.150156  27478716.1667  1412255.305560       3008333.33333             3525833.33333         16939166.6667  4076666.66667      3.722222  70.722222       71.111111   23473333.3333          1          0          0          0          0          0          0          0          0      1.53  1362.964286  2185.928571  1237.750000   808.428571     7.821429\n",
       "14     2439            6           46.428571   0.128796  27870847.3929  1252047.571430       3363214.28571             4437857.14286         16550357.1429  3566785.71429      4.642857  74.821429       60.892857   24351428.5714          1          0          0          0          0          0          0          0          0      1.53  1210.476190  2708.285714  2120.714286   194.285714    17.285714\n",
       "15     2439            7           46.142857   0.134214  26062830.5714  1125032.785710       2485714.28571             2350714.28571         17966785.7143  3324642.85714      2.892857  71.607143       67.571429   22803214.2857          1          0          0          0          0          0          0          0          0      1.52   511.000000  1718.428571  1695.095238  1012.380952    50.000000\n",
       "16     2439            8           44.964286   0.148276  28916996.3929  1461126.571430       3860357.14286             5950714.28571         15071785.7143  4108928.57143      5.107143  69.714286       69.464286   24882857.1429          1          0          0          0          0          0          0          0          0      1.55  2159.857143  2698.047619  1061.000000   449.047619     0.000000\n",
       "17     2439            9           41.900000   0.178011  24815892.0000  1164509.900000       3501000.00000             5310000.00000         12327000.0000  3744000.00000      3.200000  60.100000       71.900000   21138000.0000          1          0          0          0          0          0          0          0          0       NaN  1151.066667  1832.066667   748.066667   474.733333     0.933333\n",
       "18     2456            1           44.684211   0.076940  31074382.2421   901804.273684       5123999.92632             3464210.52632         19160210.5263  3363157.89474      5.778947  68.505263       56.357895   27748420.9789          0          1          0          0          0          0          0          0          0      1.52   693.538462   626.912088   652.692308  1552.285714  1845.010989\n",
       "19     2456            2           46.454545   0.070956  31363921.6364   660788.727273       4160454.54545             3383181.81818         21426818.1818  2428636.36364      5.227273  73.681818       59.045455   28970454.5455          0          1          0          0          0          0          0          0          0      1.52   545.619048   499.047619   405.380952  1728.142857  2647.904762"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1 = sm.ols(formula=\"distance~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"distance~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"distance~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"distance~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"distance~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"distance~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"distance~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"distance~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"distance~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"distance~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"distance~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"distance~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"distance~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"distance~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"distance~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we regress one variable at a time, and also include the dummy variables for the racer.\n",
    "\n",
    "Significant results:\n",
    "- hrv, coefficient -1.1973 and p-value 0.028\n",
    "- recovery score, coefficient -0.002 and pvalue 0.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>distance</td>     <th>  R-squared:         </th> <td>   0.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 11 Feb 2016</td> <th>  Prob (F-statistic):</th>  <td>0.00608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:24:55</td>     <th>  Log-Likelihood:    </th> <td>  80.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    80</td>      <th>  AIC:               </th> <td>  -140.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    70</td>      <th>  BIC:               </th> <td>  -117.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    1.7016</td> <td>    0.082</td> <td>   20.687</td> <td> 0.000</td> <td>    1.538     1.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recovery_score</th> <td>   -0.0020</td> <td>    0.001</td> <td>   -1.688</td> <td> 0.096</td> <td>   -0.004     0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>      <td>   -0.0016</td> <td>    0.053</td> <td>   -0.029</td> <td> 0.977</td> <td>   -0.107     0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>      <td>   -0.0787</td> <td>    0.042</td> <td>   -1.894</td> <td> 0.062</td> <td>   -0.162     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>      <td>   -0.0452</td> <td>    0.041</td> <td>   -1.111</td> <td> 0.270</td> <td>   -0.126     0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>      <td>   -0.1033</td> <td>    0.040</td> <td>   -2.580</td> <td> 0.012</td> <td>   -0.183    -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>      <td>   -0.0200</td> <td>    0.039</td> <td>   -0.511</td> <td> 0.611</td> <td>   -0.098     0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>      <td>   -0.0582</td> <td>    0.039</td> <td>   -1.491</td> <td> 0.140</td> <td>   -0.136     0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>      <td>    0.0324</td> <td>    0.046</td> <td>    0.711</td> <td> 0.480</td> <td>   -0.059     0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>      <td>   -0.1810</td> <td>    0.044</td> <td>   -4.106</td> <td> 0.000</td> <td>   -0.269    -0.093</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>32.640</td> <th>  Durbin-Watson:     </th> <td>   1.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 195.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.940</td> <th>  Prob(JB):          </th> <td>2.76e-43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.434</td> <th>  Cond. No.          </th> <td>    579.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               distance   R-squared:                       0.270\n",
       "Model:                            OLS   Adj. R-squared:                  0.176\n",
       "Method:                 Least Squares   F-statistic:                     2.871\n",
       "Date:                Thu, 11 Feb 2016   Prob (F-statistic):            0.00608\n",
       "Time:                        07:24:55   Log-Likelihood:                 80.410\n",
       "No. Observations:                  80   AIC:                            -140.8\n",
       "Df Residuals:                      70   BIC:                            -117.0\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          1.7016      0.082     20.687      0.000         1.538     1.866\n",
       "recovery_score    -0.0020      0.001     -1.688      0.096        -0.004     0.000\n",
       "user_2456         -0.0016      0.053     -0.029      0.977        -0.107     0.104\n",
       "user_2458         -0.0787      0.042     -1.894      0.062        -0.162     0.004\n",
       "user_2465         -0.0452      0.041     -1.111      0.270        -0.126     0.036\n",
       "user_2466         -0.1033      0.040     -2.580      0.012        -0.183    -0.023\n",
       "user_2468         -0.0200      0.039     -0.511      0.611        -0.098     0.058\n",
       "user_2469         -0.0582      0.039     -1.491      0.140        -0.136     0.020\n",
       "user_2473          0.0324      0.046      0.711      0.480        -0.059     0.123\n",
       "user_2508         -0.1810      0.044     -4.106      0.000        -0.269    -0.093\n",
       "==============================================================================\n",
       "Omnibus:                       32.640   Durbin-Watson:                   1.967\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              195.991\n",
       "Skew:                           0.940   Prob(JB):                     2.76e-43\n",
       "Kurtosis:                      10.434   Cond. No.                         579.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>distance</td>     <th>  R-squared:         </th> <td>   0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 11 Feb 2016</td> <th>  Prob (F-statistic):</th>  <td>0.00276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>07:24:55</td>     <th>  Log-Likelihood:    </th> <td>  81.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    80</td>      <th>  AIC:               </th> <td>  -143.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    70</td>      <th>  BIC:               </th> <td>  -119.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.6903</td> <td>    0.059</td> <td>   28.639</td> <td> 0.000</td> <td>    1.573     1.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hrv_rmssd</th> <td>   -1.1973</td> <td>    0.535</td> <td>   -2.240</td> <td> 0.028</td> <td>   -2.263    -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -0.0202</td> <td>    0.053</td> <td>   -0.377</td> <td> 0.707</td> <td>   -0.127     0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>   -0.0626</td> <td>    0.042</td> <td>   -1.475</td> <td> 0.145</td> <td>   -0.147     0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -0.0434</td> <td>    0.040</td> <td>   -1.084</td> <td> 0.282</td> <td>   -0.123     0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>   -0.0385</td> <td>    0.044</td> <td>   -0.867</td> <td> 0.389</td> <td>   -0.127     0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -0.0690</td> <td>    0.043</td> <td>   -1.597</td> <td> 0.115</td> <td>   -0.155     0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>   -0.1249</td> <td>    0.048</td> <td>   -2.600</td> <td> 0.011</td> <td>   -0.221    -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>    0.0357</td> <td>    0.044</td> <td>    0.808</td> <td> 0.422</td> <td>   -0.052     0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>   -0.1986</td> <td>    0.045</td> <td>   -4.404</td> <td> 0.000</td> <td>   -0.288    -0.109</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>27.021</td> <th>  Durbin-Watson:     </th> <td>   1.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 171.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.651</td> <th>  Prob(JB):          </th> <td>4.54e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.064</td> <th>  Cond. No.          </th> <td>    54.1</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               distance   R-squared:                       0.291\n",
       "Model:                            OLS   Adj. R-squared:                  0.200\n",
       "Method:                 Least Squares   F-statistic:                     3.188\n",
       "Date:                Thu, 11 Feb 2016   Prob (F-statistic):            0.00276\n",
       "Time:                        07:24:55   Log-Likelihood:                 81.583\n",
       "No. Observations:                  80   AIC:                            -143.2\n",
       "Df Residuals:                      70   BIC:                            -119.3\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.6903      0.059     28.639      0.000         1.573     1.808\n",
       "hrv_rmssd     -1.1973      0.535     -2.240      0.028        -2.263    -0.131\n",
       "user_2456     -0.0202      0.053     -0.377      0.707        -0.127     0.087\n",
       "user_2458     -0.0626      0.042     -1.475      0.145        -0.147     0.022\n",
       "user_2465     -0.0434      0.040     -1.084      0.282        -0.123     0.036\n",
       "user_2466     -0.0385      0.044     -0.867      0.389        -0.127     0.050\n",
       "user_2468     -0.0690      0.043     -1.597      0.115        -0.155     0.017\n",
       "user_2469     -0.1249      0.048     -2.600      0.011        -0.221    -0.029\n",
       "user_2473      0.0357      0.044      0.808      0.422        -0.052     0.124\n",
       "user_2508     -0.1986      0.045     -4.404      0.000        -0.288    -0.109\n",
       "==============================================================================\n",
       "Omnibus:                       27.021   Durbin-Watson:                   1.873\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              171.972\n",
       "Skew:                           0.651   Prob(JB):                     4.54e-38\n",
       "Kurtosis:                      10.064   Cond. No.                         54.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###6 days weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_bike_df_6daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_bike_df_6daysweighted.csv')\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = sm.ols(formula=\"distance~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"distance~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"distance~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"distance~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"distance~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"distance~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"distance~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"distance~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"distance~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"distance~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"distance~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"distance~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"distance~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"distance~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"distance~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant Predictors:\n",
    "- hrv, -1.2004 and p-value of 0.028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.291\n",
      "Model:                            OLS   Adj. R-squared:                  0.200\n",
      "Method:                 Least Squares   F-statistic:                     3.195\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):            0.00271\n",
      "Time:                        07:24:56   Log-Likelihood:                 81.609\n",
      "No. Observations:                  80   AIC:                            -143.2\n",
      "Df Residuals:                      70   BIC:                            -119.4\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6908      0.059     28.675      0.000         1.573     1.808\n",
      "hrv_rmssd     -1.2004      0.533     -2.251      0.028        -2.264    -0.137\n",
      "user_2456     -0.0194      0.053     -0.363      0.718        -0.126     0.087\n",
      "user_2458     -0.0615      0.043     -1.444      0.153        -0.146     0.023\n",
      "user_2465     -0.0442      0.040     -1.105      0.273        -0.124     0.036\n",
      "user_2466     -0.0381      0.044     -0.858      0.394        -0.127     0.050\n",
      "user_2468     -0.0690      0.043     -1.598      0.115        -0.155     0.017\n",
      "user_2469     -0.1257      0.048     -2.610      0.011        -0.222    -0.030\n",
      "user_2473      0.0350      0.044      0.795      0.430        -0.053     0.123\n",
      "user_2508     -0.1994      0.045     -4.412      0.000        -0.290    -0.109\n",
      "==============================================================================\n",
      "Omnibus:                       27.081   Durbin-Watson:                   1.875\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              169.226\n",
      "Skew:                           0.664   Prob(JB):                     1.79e-37\n",
      "Kurtosis:                      10.000   Cond. No.                         54.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5 Days Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_bike_df_5daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_bike_df_5daysweighted.csv')\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"distance~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"distance~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"distance~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"distance~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"distance~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"distance~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"distance~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"distance~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"distance~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"distance~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"distance~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"distance~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"distance~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"distance~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"distance~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant Predictors\n",
    "- HRV: -1.802, pvalue 0.026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.292\n",
      "Model:                            OLS   Adj. R-squared:                  0.201\n",
      "Method:                 Least Squares   F-statistic:                     3.209\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):            0.00262\n",
      "Time:                        07:24:56   Log-Likelihood:                 81.659\n",
      "No. Observations:                  80   AIC:                            -143.3\n",
      "Df Residuals:                      70   BIC:                            -119.5\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6886      0.058     29.309      0.000         1.574     1.804\n",
      "hrv_rmssd     -1.1802      0.520     -2.271      0.026        -2.217    -0.144\n",
      "user_2456     -0.0185      0.053     -0.347      0.730        -0.125     0.088\n",
      "user_2458     -0.0615      0.042     -1.448      0.152        -0.146     0.023\n",
      "user_2465     -0.0449      0.040     -1.121      0.266        -0.125     0.035\n",
      "user_2466     -0.0380      0.044     -0.857      0.394        -0.126     0.050\n",
      "user_2468     -0.0685      0.043     -1.595      0.115        -0.154     0.017\n",
      "user_2469     -0.1250      0.048     -2.615      0.011        -0.220    -0.030\n",
      "user_2473      0.0349      0.044      0.795      0.429        -0.053     0.123\n",
      "user_2508     -0.2000      0.045     -4.424      0.000        -0.290    -0.110\n",
      "==============================================================================\n",
      "Omnibus:                       27.377   Durbin-Watson:                   1.877\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              170.076\n",
      "Skew:                           0.681   Prob(JB):                     1.17e-37\n",
      "Kurtosis:                      10.012   Cond. No.                         52.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 4 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_bike_df_4daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_bike_df_4daysweighted.csv')\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"distance~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"distance~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"distance~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"distance~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"distance~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"distance~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"distance~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"distance~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"distance~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"distance~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"distance~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"distance~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"distance~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"distance~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"distance~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant results\n",
    "- HRV: -.8996, p value 0.035\n",
    "- slow wave sleep duration: very very small, positive, and p value 0.023\n",
    "- recovery score: -0.0017, p-value 0.041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.321\n",
      "Model:                            OLS   Adj. R-squared:                  0.233\n",
      "Method:                 Least Squares   F-statistic:                     3.628\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000944\n",
      "Time:                        07:24:56   Log-Likelihood:                 95.674\n",
      "No. Observations:                  79   AIC:                            -171.3\n",
      "Df Residuals:                      69   BIC:                            -147.7\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          1.6518      0.057     28.906      0.000         1.538     1.766\n",
      "recovery_score    -0.0017      0.001     -2.079      0.041        -0.003 -6.91e-05\n",
      "user_2456          0.0338      0.043      0.783      0.436        -0.052     0.120\n",
      "user_2458         -0.0526      0.034     -1.555      0.124        -0.120     0.015\n",
      "user_2465         -0.0190      0.034     -0.565      0.574        -0.086     0.048\n",
      "user_2466         -0.0725      0.033     -2.217      0.030        -0.138    -0.007\n",
      "user_2468          0.0085      0.032      0.264      0.793        -0.056     0.073\n",
      "user_2469         -0.0335      0.032     -1.042      0.301        -0.098     0.031\n",
      "user_2473          0.0571      0.037      1.549      0.126        -0.016     0.131\n",
      "user_2508         -0.1531      0.036     -4.223      0.000        -0.226    -0.081\n",
      "==============================================================================\n",
      "Omnibus:                       18.704   Durbin-Watson:                   2.223\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.224\n",
      "Skew:                          -0.886   Prob(JB):                     1.01e-07\n",
      "Kurtosis:                       5.579   Cond. No.                         533.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.331\n",
      "Model:                            OLS   Adj. R-squared:                  0.244\n",
      "Method:                 Least Squares   F-statistic:                     3.790\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000633\n",
      "Time:                        07:24:56   Log-Likelihood:                 96.238\n",
      "No. Observations:                  79   AIC:                            -172.5\n",
      "Df Residuals:                      69   BIC:                            -148.8\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    1.4759      0.034     43.873      0.000         1.409     1.543\n",
      "slow_wave_sleep_duration  1.227e-08   5.29e-09      2.319      0.023      1.71e-09  2.28e-08\n",
      "user_2456                    0.0517      0.043      1.195      0.236        -0.035     0.138\n",
      "user_2458                   -0.0737      0.032     -2.310      0.024        -0.137    -0.010\n",
      "user_2465                   -0.0247      0.034     -0.737      0.464        -0.092     0.042\n",
      "user_2466                   -0.0264      0.035     -0.753      0.454        -0.096     0.044\n",
      "user_2468                   -0.0086      0.032     -0.266      0.791        -0.073     0.056\n",
      "user_2469                   -0.0171      0.033     -0.525      0.601        -0.082     0.048\n",
      "user_2473                    0.0492      0.035      1.388      0.169        -0.021     0.120\n",
      "user_2508                   -0.1008      0.035     -2.911      0.005        -0.170    -0.032\n",
      "==============================================================================\n",
      "Omnibus:                       21.993   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.483\n",
      "Skew:                          -1.076   Prob(JB):                     1.20e-08\n",
      "Kurtosis:                       5.540   Cond. No.                     3.93e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.93e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.324\n",
      "Model:                            OLS   Adj. R-squared:                  0.236\n",
      "Method:                 Least Squares   F-statistic:                     3.678\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000833\n",
      "Time:                        07:24:56   Log-Likelihood:                 95.851\n",
      "No. Observations:                  79   AIC:                            -171.7\n",
      "Df Residuals:                      69   BIC:                            -148.0\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6328      0.047     34.635      0.000         1.539     1.727\n",
      "hrv_rmssd     -0.8996      0.417     -2.156      0.035        -1.732    -0.067\n",
      "user_2456      0.0149      0.044      0.336      0.738        -0.073     0.103\n",
      "user_2458     -0.0437      0.035     -1.247      0.217        -0.114     0.026\n",
      "user_2465     -0.0176      0.033     -0.526      0.601        -0.084     0.049\n",
      "user_2466     -0.0226      0.036     -0.620      0.537        -0.095     0.050\n",
      "user_2468     -0.0312      0.036     -0.871      0.387        -0.103     0.040\n",
      "user_2469     -0.0829      0.040     -2.085      0.041        -0.162    -0.004\n",
      "user_2473      0.0545      0.036      1.503      0.137        -0.018     0.127\n",
      "user_2508     -0.1631      0.038     -4.293      0.000        -0.239    -0.087\n",
      "==============================================================================\n",
      "Omnibus:                       23.743   Durbin-Watson:                   2.121\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               45.292\n",
      "Skew:                          -1.084   Prob(JB):                     1.46e-10\n",
      "Kurtosis:                       6.010   Cond. No.                         50.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 3 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_bike_df_3daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_bike_df_3daysweighted.csv')\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"distance~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"distance~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"distance~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"distance~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"distance~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"distance~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"distance~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"distance~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"distance~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"distance~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"distance~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"distance~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"distance~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"distance~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"distance~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "significant results:\n",
    "- HRV -0.8927, p-value 0.030\n",
    "- slow wave sleep duration, very small, p-value 0.015\n",
    "- recovery score: -0.0016, p-value 0.037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.323\n",
      "Model:                            OLS   Adj. R-squared:                  0.233\n",
      "Method:                 Least Squares   F-statistic:                     3.606\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):            0.00102\n",
      "Time:                        07:24:57   Log-Likelihood:                 94.164\n",
      "No. Observations:                  78   AIC:                            -168.3\n",
      "Df Residuals:                      68   BIC:                            -144.8\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          1.6453      0.053     30.959      0.000         1.539     1.751\n",
      "recovery_score    -0.0016      0.001     -2.127      0.037        -0.003 -9.99e-05\n",
      "user_2456          0.0342      0.043      0.790      0.432        -0.052     0.121\n",
      "user_2458         -0.0543      0.034     -1.615      0.111        -0.121     0.013\n",
      "user_2465         -0.0204      0.034     -0.605      0.547        -0.088     0.047\n",
      "user_2466         -0.0729      0.033     -2.220      0.030        -0.138    -0.007\n",
      "user_2468          0.0079      0.032      0.243      0.809        -0.057     0.072\n",
      "user_2469         -0.0353      0.032     -1.093      0.278        -0.100     0.029\n",
      "user_2473          0.0582      0.038      1.513      0.135        -0.019     0.135\n",
      "user_2508         -0.1554      0.037     -4.234      0.000        -0.229    -0.082\n",
      "==============================================================================\n",
      "Omnibus:                       18.015   Durbin-Watson:                   2.208\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.639\n",
      "Skew:                          -0.881   Prob(JB):                     3.66e-07\n",
      "Kurtosis:                       5.453   Cond. No.                         518.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.338\n",
      "Model:                            OLS   Adj. R-squared:                  0.251\n",
      "Method:                 Least Squares   F-statistic:                     3.862\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000543\n",
      "Time:                        07:24:57   Log-Likelihood:                 95.052\n",
      "No. Observations:                  78   AIC:                            -170.1\n",
      "Df Residuals:                      68   BIC:                            -146.5\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    1.4730      0.033     44.591      0.000         1.407     1.539\n",
      "slow_wave_sleep_duration  1.275e-08   5.12e-09      2.489      0.015      2.53e-09   2.3e-08\n",
      "user_2456                    0.0531      0.043      1.228      0.224        -0.033     0.140\n",
      "user_2458                   -0.0731      0.032     -2.288      0.025        -0.137    -0.009\n",
      "user_2465                   -0.0225      0.033     -0.675      0.502        -0.089     0.044\n",
      "user_2466                   -0.0238      0.035     -0.679      0.499        -0.094     0.046\n",
      "user_2468                   -0.0105      0.032     -0.325      0.746        -0.075     0.054\n",
      "user_2469                   -0.0145      0.033     -0.445      0.658        -0.080     0.051\n",
      "user_2473                    0.0538      0.037      1.442      0.154        -0.021     0.128\n",
      "user_2508                   -0.0989      0.035     -2.855      0.006        -0.168    -0.030\n",
      "==============================================================================\n",
      "Omnibus:                       21.805   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.127\n",
      "Skew:                          -1.092   Prob(JB):                     2.36e-08\n",
      "Kurtosis:                       5.457   Cond. No.                     3.93e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.93e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.327\n",
      "Model:                            OLS   Adj. R-squared:                  0.237\n",
      "Method:                 Least Squares   F-statistic:                     3.664\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000881\n",
      "Time:                        07:24:57   Log-Likelihood:                 94.368\n",
      "No. Observations:                  78   AIC:                            -168.7\n",
      "Df Residuals:                      68   BIC:                            -145.2\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6323      0.046     35.530      0.000         1.541     1.724\n",
      "hrv_rmssd     -0.8927      0.403     -2.215      0.030        -1.697    -0.088\n",
      "user_2456      0.0148      0.044      0.334      0.739        -0.074     0.103\n",
      "user_2458     -0.0443      0.035     -1.266      0.210        -0.114     0.026\n",
      "user_2465     -0.0186      0.034     -0.555      0.581        -0.086     0.048\n",
      "user_2466     -0.0232      0.036     -0.640      0.524        -0.096     0.049\n",
      "user_2468     -0.0317      0.036     -0.883      0.380        -0.103     0.040\n",
      "user_2469     -0.0826      0.039     -2.095      0.040        -0.161    -0.004\n",
      "user_2473      0.0570      0.038      1.495      0.140        -0.019     0.133\n",
      "user_2508     -0.1648      0.038     -4.308      0.000        -0.241    -0.088\n",
      "==============================================================================\n",
      "Omnibus:                       23.255   Durbin-Watson:                   2.111\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               41.903\n",
      "Skew:                          -1.100   Prob(JB):                     7.96e-10\n",
      "Kurtosis:                       5.838   Cond. No.                         48.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 2 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_bike_df_2daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_bike_df_2daysweighted.csv')\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"distance~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"distance~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"distance~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"distance~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"distance~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"distance~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"distance~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"distance~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"distance~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"distance~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"distance~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"distance~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"distance~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"distance~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"distance~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"distance~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant results:\n",
    "- HRV: -0.8524, p-value 0.032\n",
    "- slow wave sleep duration: very small, p value 0.014\n",
    "- recovery score: p-value 0.049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.318\n",
      "Model:                            OLS   Adj. R-squared:                  0.228\n",
      "Method:                 Least Squares   F-statistic:                     3.530\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):            0.00122\n",
      "Time:                        07:24:58   Log-Likelihood:                 93.899\n",
      "No. Observations:                  78   AIC:                            -167.8\n",
      "Df Residuals:                      68   BIC:                            -144.2\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          1.6276      0.048     34.092      0.000         1.532     1.723\n",
      "recovery_score    -0.0013      0.001     -2.009      0.049        -0.003 -8.77e-06\n",
      "user_2456          0.0363      0.043      0.836      0.406        -0.050     0.123\n",
      "user_2458         -0.0586      0.033     -1.758      0.083        -0.125     0.008\n",
      "user_2465         -0.0201      0.034     -0.593      0.555        -0.088     0.048\n",
      "user_2466         -0.0711      0.033     -2.163      0.034        -0.137    -0.006\n",
      "user_2468          0.0077      0.032      0.238      0.812        -0.057     0.073\n",
      "user_2469         -0.0367      0.032     -1.130      0.263        -0.101     0.028\n",
      "user_2473          0.0520      0.038      1.368      0.176        -0.024     0.128\n",
      "user_2508         -0.1534      0.037     -4.173      0.000        -0.227    -0.080\n",
      "==============================================================================\n",
      "Omnibus:                       17.559   Durbin-Watson:                   2.197\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.248\n",
      "Skew:                          -0.850   Prob(JB):                     4.46e-07\n",
      "Kurtosis:                       5.471   Cond. No.                         508.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.340\n",
      "Model:                            OLS   Adj. R-squared:                  0.252\n",
      "Method:                 Least Squares   F-statistic:                     3.889\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000509\n",
      "Time:                        07:24:58   Log-Likelihood:                 95.142\n",
      "No. Observations:                  78   AIC:                            -170.3\n",
      "Df Residuals:                      68   BIC:                            -146.7\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    1.4743      0.032     45.632      0.000         1.410     1.539\n",
      "slow_wave_sleep_duration  1.273e-08   5.05e-09      2.523      0.014      2.66e-09  2.28e-08\n",
      "user_2456                    0.0526      0.043      1.218      0.227        -0.034     0.139\n",
      "user_2458                   -0.0725      0.032     -2.273      0.026        -0.136    -0.009\n",
      "user_2465                   -0.0216      0.033     -0.648      0.519        -0.088     0.045\n",
      "user_2466                   -0.0232      0.035     -0.663      0.509        -0.093     0.047\n",
      "user_2468                   -0.0127      0.033     -0.392      0.697        -0.078     0.052\n",
      "user_2469                   -0.0141      0.033     -0.431      0.668        -0.079     0.051\n",
      "user_2473                    0.0539      0.037      1.445      0.153        -0.020     0.128\n",
      "user_2508                   -0.0990      0.035     -2.866      0.006        -0.168    -0.030\n",
      "==============================================================================\n",
      "Omnibus:                       21.935   Durbin-Watson:                   2.047\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.139\n",
      "Skew:                          -1.103   Prob(JB):                     2.34e-08\n",
      "Kurtosis:                       5.439   Cond. No.                     3.86e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.86e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.326\n",
      "Model:                            OLS   Adj. R-squared:                  0.237\n",
      "Method:                 Least Squares   F-statistic:                     3.651\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000909\n",
      "Time:                        07:24:58   Log-Likelihood:                 94.323\n",
      "No. Observations:                  78   AIC:                            -168.6\n",
      "Df Residuals:                      68   BIC:                            -145.1\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6291      0.045     36.252      0.000         1.539     1.719\n",
      "hrv_rmssd     -0.8524      0.388     -2.196      0.032        -1.627    -0.078\n",
      "user_2456      0.0155      0.044      0.350      0.727        -0.073     0.104\n",
      "user_2458     -0.0471      0.035     -1.365      0.177        -0.116     0.022\n",
      "user_2465     -0.0205      0.034     -0.609      0.545        -0.088     0.047\n",
      "user_2466     -0.0252      0.036     -0.700      0.486        -0.097     0.047\n",
      "user_2468     -0.0311      0.036     -0.867      0.389        -0.103     0.040\n",
      "user_2469     -0.0812      0.039     -2.072      0.042        -0.159    -0.003\n",
      "user_2473      0.0524      0.038      1.390      0.169        -0.023     0.128\n",
      "user_2508     -0.1658      0.039     -4.298      0.000        -0.243    -0.089\n",
      "==============================================================================\n",
      "Omnibus:                       22.301   Durbin-Watson:                   2.126\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               38.871\n",
      "Skew:                          -1.070   Prob(JB):                     3.62e-09\n",
      "Kurtosis:                       5.717   Cond. No.                         46.9\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print result1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 night before the bike effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bike_df_pre_weighting.csv')\n",
    "dummies = pd.get_dummies(df['user_id'], prefix='user')\n",
    "temp_df = pd.concat([df, dummies], axis=1)\n",
    "bike_dist = pd.read_csv('huxc_bike_distances.csv')\n",
    "bike_dist=bike_dist[bike_dist['user_id']!=2461]\n",
    "bike_dist=bike_dist[bike_dist['user_id']!=2509]\n",
    "bike_dist=bike_dist.drop(['date_start_epoch', 'date_md'], axis=1)\n",
    "reg_df = temp_df.merge(bike_dist, how='left')\n",
    "reg_df = reg_df.drop(['user_828'], axis=1)\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1).reset_index(drop=True)\n",
    "\n",
    "#Use for each individual buildup day\n",
    "reg_df0 = reg_df[reg_df['buildup_days']==0].reset_index(drop=True)\n",
    "reg_df1 = reg_df[reg_df['buildup_days']==1].reset_index(drop=True)\n",
    "reg_df2 = reg_df[reg_df['buildup_days']==2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ols_regressions(y_var, x_vars, df):\n",
    "    return sm.ols(formula= y_var + \"~ \" + x_vars + \" + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508\", data=df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no significant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1 = ols_regressions('distance', 'hrv_rmssd', reg_df0)\n",
    "result2 = ols_regressions('distance', 'resting_heart_rate', reg_df0)\n",
    "result3 = ols_regressions('distance', 'sleep_duration', reg_df0)\n",
    "result4 = ols_regressions('distance', 'rem_sleep_duration', reg_df0)\n",
    "result5 = ols_regressions('distance', 'slow_wave_sleep_duration', reg_df0)\n",
    "result6 = ols_regressions('distance', 'light_sleep_duration', reg_df0)\n",
    "result7 = ols_regressions('distance', 'time_in_bed', reg_df0)\n",
    "result8 = ols_regressions('distance', 'cycles_count', reg_df0)\n",
    "result9 = ols_regressions('distance', 'latency', reg_df0)\n",
    "result10 = ols_regressions('distance', 'score', reg_df0)\n",
    "result11 = ols_regressions('distance', 'recovery_score', reg_df0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2nd night before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1 = ols_regressions('distance', 'hrv_rmssd', reg_df1)\n",
    "result2 = ols_regressions('distance', 'resting_heart_rate', reg_df1)\n",
    "result3 = ols_regressions('distance', 'sleep_duration', reg_df1)\n",
    "result4 = ols_regressions('distance', 'rem_sleep_duration', reg_df1)\n",
    "result5 = ols_regressions('distance', 'slow_wave_sleep_duration', reg_df1)\n",
    "result6 = ols_regressions('distance', 'light_sleep_duration', reg_df1)\n",
    "result7 = ols_regressions('distance', 'time_in_bed', reg_df1)\n",
    "result8 = ols_regressions('distance', 'cycles_count', reg_df1)\n",
    "result9 = ols_regressions('distance', 'latency', reg_df1)\n",
    "result10 = ols_regressions('distance', 'score', reg_df1)\n",
    "result11 = ols_regressions('distance', 'recovery_score', reg_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signficant results:\n",
    "- slow wave sleep duration, very small, p-value = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               distance   R-squared:                       0.407\n",
      "Model:                            OLS   Adj. R-squared:                  0.318\n",
      "Method:                 Least Squares   F-statistic:                     4.578\n",
      "Date:                Thu, 11 Feb 2016   Prob (F-statistic):           0.000129\n",
      "Time:                        07:24:58   Log-Likelihood:                 85.581\n",
      "No. Observations:                  70   AIC:                            -151.2\n",
      "Df Residuals:                      60   BIC:                            -128.7\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------------\n",
      "Intercept                    1.4654      0.030     48.494      0.000         1.405     1.526\n",
      "slow_wave_sleep_duration  1.388e-08   4.33e-09      3.201      0.002      5.21e-09  2.25e-08\n",
      "user_2456                    0.0552      0.048      1.140      0.259        -0.042     0.152\n",
      "user_2458                   -0.0809      0.033     -2.428      0.018        -0.148    -0.014\n",
      "user_2465                   -0.0173      0.037     -0.468      0.641        -0.091     0.057\n",
      "user_2466                   -0.0158      0.035     -0.452      0.653        -0.086     0.054\n",
      "user_2468                   -0.0200      0.033     -0.608      0.545        -0.086     0.046\n",
      "user_2469                   -0.0076      0.036     -0.212      0.833        -0.079     0.064\n",
      "user_2473                    0.0707      0.040      1.774      0.081        -0.009     0.150\n",
      "user_2508                   -0.1096      0.036     -3.084      0.003        -0.181    -0.038\n",
      "==============================================================================\n",
      "Omnibus:                       23.958   Durbin-Watson:                   2.126\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               37.683\n",
      "Skew:                          -1.308   Prob(JB):                     6.57e-09\n",
      "Kurtosis:                       5.464   Cond. No.                     3.97e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.97e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mixed Effects Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Addressing the Multiple Comparisons Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to an R session\n",
    "import rpy2.robjects\n",
    "r = rpy2.robjects.r\n",
    "\n",
    "# For a Pythonic interface to R\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import Formula\n",
    "from rpy2.robjects.environments import Environment\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# Make it so we can send numpy arrays to R\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "#Specify path with downloaded R packages\n",
    "lib_path = 'C:/Users/BUCKBEAK/Documents/BUCKBEAK/R/win-library/3.2'\n",
    "\n",
    "# load some required packages\n",
    "utils = importr('utils')\n",
    "langR = importr('languageR', lib_loc=lib_path)\n",
    "lme4 = importr('lme4', lib_path)\n",
    "lmerTest=importr('lmerTest', lib_path)\n",
    "\n",
    "#allow to convert pandas dataframes into R dataframes\n",
    "pandas2ri.activate()\n",
    "r_reg_df0 = pandas2ri.py2ri(reg_df0)\n",
    "r_reg_df1 = pandas2ri.py2ri(reg_df1)\n",
    "r_reg_df2 = pandas2ri.py2ri(reg_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mixed_effects_model(dftouse, env, y_var, x_var, group_vars=None):\n",
    "    env = env\n",
    "    if group_vars == None:\n",
    "        print 'Not a mixed effects model!'\n",
    "        return 'Not a mixed effects model!'\n",
    "    for varname in r.colnames(dftouse):\n",
    "        env[varname] = dftouse.rx2(varname)\n",
    "    if type(group_vars) == str:\n",
    "        formula = Formula(y_var + ' ~ ' + x_var + ' + (1|' + group_vars + ')', environment = env)\n",
    "        model = lmerTest.lmer(formula)\n",
    "        return r.summary(model)\n",
    "    elif type(group_vars)== tuple or type(group_vars)== list:\n",
    "        if len(group_vars) == 2:\n",
    "            formula = Formula(y_var + ' ~ ' + x_var + ' + (1|' + group_vars[0] + ') + (1|' + group_vars[1] + ')', environment=env)\n",
    "            model = lmerTest.lmer(formula)\n",
    "            return r.summary(model)\n",
    "        elif len(group_vars) == 3:\n",
    "            formula =Formula(y_var + ' ~ ' + x_var + ' + (1|' + group_vars[0] + ' ' + group_vars[1] + ' ' + group_vars[2]+ ')', \n",
    "                             environment = env)\n",
    "            model = lmerTest.lmer(formula)\n",
    "            return r.summary(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_df(df):\n",
    "    #Use to randomize user_id to different sets of races\n",
    "    runnerA=df[0:9].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerB=df[9:18].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerC=df[18:27].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerD=df[27:36].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerE=df[36:45].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerF=df[45:54].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerG=df[54:63].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerH=df[63:72].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerI=df[72:81].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    runnerJ=df[81:90].drop(['user_id'],axis=1).reset_index(drop=True)\n",
    "    users = list(set(df.user_id))\n",
    "    random.shuffle(users, random.random)\n",
    "    dfdict = {1: runnerA, 2: runnerB, 3: runnerC, 4: runnerD, 5: runnerE, 6: runnerF, 7: runnerG, 8: runnerH, \n",
    "              9: runnerI, 10: runnerJ}\n",
    "    for i in range(0, len(users)):\n",
    "        dfdict[i+1]['user_id'] = users[i] \n",
    "    random.shuffle(runnerA.distance, random.random)\n",
    "    random.shuffle(runnerB.distance, random.random)\n",
    "    random.shuffle(runnerC.distance, random.random)\n",
    "    random.shuffle(runnerD.distance, random.random)\n",
    "    random.shuffle(runnerE.distance, random.random)\n",
    "    random.shuffle(runnerF.distance, random.random)\n",
    "    random.shuffle(runnerG.distance, random.random)\n",
    "    random.shuffle(runnerH.distance, random.random)\n",
    "    random.shuffle(runnerI.distance, random.random)\n",
    "    random.shuffle(runnerJ.distance, random.random)\n",
    "    frames = [runnerA, runnerB, runnerC, runnerD, runnerE, runnerF, runnerG, runnerH, runnerI, runnerJ]\n",
    "    new_df = pd.concat(frames).reset_index(drop=True)\n",
    "    colnames = new_df.columns.tolist()\n",
    "    colnames = colnames[-1:] + colnames[:-1]\n",
    "    new_df = new_df[colnames]\n",
    "    return new_df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjusted_alpha(reg_df, env, group_vars, weighted=False):\n",
    "    env=env\n",
    "    pandas2ri.activate()\n",
    "    if (group_vars == ['user_id', 'race_course']) or (group_vars == 'user_id'):\n",
    "        #list to keep minimum p_values\n",
    "        min_pvals = []\n",
    "\n",
    "        for i in range(0, 1000):\n",
    "            #convert to pandas first\n",
    "            pand_reg_df = pandas2ri.ri2py(reg_df)\n",
    "            #shuffle the dataframe\n",
    "            shuf_df = shuffle_df(df=pand_reg_df)\n",
    "            #switch back to R dataframe\n",
    "            r_shuf_df = pandas2ri.py2ri(shuf_df)\n",
    "\n",
    "            #list of p_values\n",
    "            p_values = []\n",
    "\n",
    "            #Run all 16 regressions\n",
    "            result1 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = group_vars)\n",
    "            result2 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = group_vars)\n",
    "            result3 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = group_vars)\n",
    "            result4 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = group_vars)\n",
    "            result5 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = group_vars)\n",
    "            result6 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = group_vars)\n",
    "            result7 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = group_vars)\n",
    "            result8 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='latency', group_vars = group_vars)\n",
    "            result9 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='cycles_count', group_vars = group_vars)\n",
    "            #result10 = mixed_effects_model(r_shuf_df, env=env, y_var = 'pace_per_k', x_var='score', group_vars = group_vars)\n",
    "            #result11 = mixed_effects_model(r_shuf_df, env=env, y_var = 'pace_per_k', x_var='recovery_score', group_vars = group_vars)\n",
    "            \n",
    "            #Collect p-values for each\n",
    "            p_values.append(r.coef(result1)[9])\n",
    "            p_values.append(r.coef(result2)[9])\n",
    "            p_values.append(r.coef(result3)[9])\n",
    "            p_values.append(r.coef(result4)[9])\n",
    "            p_values.append(r.coef(result5)[9])\n",
    "            p_values.append(r.coef(result6)[9])\n",
    "            p_values.append(r.coef(result7)[9])\n",
    "            p_values.append(r.coef(result8)[9])\n",
    "            p_values.append(r.coef(result9)[9])\n",
    "            #p_values.append(r.coef(result10)[9])\n",
    "            #p_values.append(r.coef(result11)[9])\n",
    "            \n",
    "            if weighted == True:\n",
    "                result12 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='z1', group_vars = group_vars)\n",
    "                result13 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='z2', group_vars = group_vars)\n",
    "                result14 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='z3', group_vars = group_vars)\n",
    "                result15 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='z4', group_vars = group_vars)\n",
    "                result16 = mixed_effects_model(r_shuf_df, env=env, y_var = 'distance', x_var='z5', group_vars = group_vars)\n",
    "                p_values.append(r.coef(result12)[9])\n",
    "                p_values.append(r.coef(result13)[9])\n",
    "                p_values.append(r.coef(result14)[9])\n",
    "                p_values.append(r.coef(result15)[9])\n",
    "                p_values.append(r.coef(result16)[9])\n",
    "            min_pvals.append(min(p_values))\n",
    "    \n",
    "    return np.percentile(min_pvals, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00555555555556\n",
      "0.00357142857143\n"
     ]
    }
   ],
   "source": [
    "bonf_9 = 0.05/9\n",
    "bonf_14 = 0.05/14\n",
    "print bonf_9\n",
    "print bonf_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Looking at just individual days before the bike effort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to test runner random effects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "alpha = adjusted_alpha(r_reg_df0, env=env, group_vars='user_id', weighted=False)\n",
    "result1 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = 'user_id')\n",
    "result2 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = 'user_id')\n",
    "result3 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = 'user_id')\n",
    "result4 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = 'user_id')\n",
    "result5 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = 'user_id')\n",
    "result6 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = 'user_id')\n",
    "result7 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = 'user_id')\n",
    "result8 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='latency', group_vars = 'user_id')\n",
    "result9 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='cycles_count', group_vars = 'user_id')\n",
    "result10 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='score', group_vars = 'user_id')\n",
    "result11 = mixed_effects_model(r_reg_df0, env=env, y_var = 'distance', x_var='recovery_score', group_vars = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adjusted alpha level here is 0.00399758309667\n",
      "The Bonferroni Correction here is 0.00555555555556\n"
     ]
    }
   ],
   "source": [
    "print 'The adjusted alpha level here is', alpha\n",
    "print 'The Bonferroni Correction here is', bonf_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no significant results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2nd night before bike effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "env = Environment()\n",
    "alpha = adjusted_alpha(r_reg_df1, env=env, group_vars='user_id', weighted=False)\n",
    "result1 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = 'user_id')\n",
    "result2 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = 'user_id')\n",
    "result3 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = 'user_id')\n",
    "result4 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = 'user_id')\n",
    "result5 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = 'user_id')\n",
    "result6 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = 'user_id')\n",
    "result7 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = 'user_id')\n",
    "result8 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='latency', group_vars = 'user_id')\n",
    "result9 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='cycles_count', group_vars = 'user_id')\n",
    "result10 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='score', group_vars = 'user_id')\n",
    "result11 = mixed_effects_model(r_reg_df1, env=env, y_var = 'distance', x_var='recovery_score', group_vars = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'The adjusted alpha level here is', alpha\n",
    "print 'The Bonferroni Correction here is', bonf_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant results:\n",
    "- resting heart rate - small and negative, p -value 0.0618\n",
    "- slow wave sleep duration: very small and negative, p-value 0.00175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted Recovery Data Leading up to bike effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_weight_df5 = pd.read_csv('final_bike_df_5daysweighted.csv')\n",
    "wkout_weight_df5 = pd.read_csv('workout_final_bike_df_5daysweighted.csv')\n",
    "weight_df5 = pd.merge(rec_weight_df5, wkout_weight_df5, how='left')\n",
    "r_weightdf5 = pandas2ri.py2ri(weight_df5)\n",
    "\n",
    "rec_weight_df4 = pd.read_csv('final_bike_df_4daysweighted.csv')\n",
    "wkout_weight_df4 = pd.read_csv('workout_final_bike_df_4daysweighted.csv')\n",
    "weight_df4 = pd.merge(rec_weight_df4, wkout_weight_df4, how='left')\n",
    "r_weightdf4 = pandas2ri.py2ri(weight_df4)\n",
    "\n",
    "rec_weight_df3 = pd.read_csv('final_bike_df_3daysweighted.csv')\n",
    "wkout_weight_df3 = pd.read_csv('workout_final_bike_df_3daysweighted.csv')\n",
    "weight_df3 = pd.merge(rec_weight_df3, wkout_weight_df3, how='left')\n",
    "r_weightdf3 = pandas2ri.py2ri(weight_df3)\n",
    "\n",
    "rec_weight_df2 = pd.read_csv('final_bike_df_2daysweighted.csv')\n",
    "wkout_weight_df2 = pd.read_csv('workout_final_bike_df_2daysweighted.csv')\n",
    "weight_df2 = pd.merge(rec_weight_df2, wkout_weight_df2, how='left')\n",
    "r_weightdf2 = pandas2ri.py2ri(weight_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "alpha = adjusted_alpha(r_weightdf2, env=env, group_vars='user_id', weighted=True)\n",
    "result1 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = 'user_id')\n",
    "result2 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = 'user_id')\n",
    "result3 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = 'user_id')\n",
    "result4 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = 'user_id')\n",
    "result5 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = 'user_id')\n",
    "result6 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = 'user_id')\n",
    "result7 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = 'user_id')\n",
    "result8 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='latency', group_vars = 'user_id')\n",
    "result9 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='cycles_count', group_vars = 'user_id')\n",
    "result10 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='score', group_vars = 'user_id')\n",
    "result11 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='recovery_score', group_vars = 'user_id')\n",
    "result12 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='z1', group_vars = 'user_id')\n",
    "result13 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='z2', group_vars = 'user_id')\n",
    "result14 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='z3', group_vars = 'user_id')\n",
    "result15 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='z4', group_vars = 'user_id')\n",
    "result16 = mixed_effects_model(r_weightdf2, env=env, y_var = 'distance', x_var='z5', group_vars = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'The adjusted alpha level here is', alpha\n",
    "print 'The Bonferroni Correction here is', bonf_14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant result:\n",
    "- slow wave sleep duration: small and positive, p-value 0.0103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print result5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 3 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "alpha = adjusted_alpha(r_weightdf3, env=env, group_vars='user_id', weighted=True)\n",
    "result1 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = 'user_id')\n",
    "result2 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = 'user_id')\n",
    "result3 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = 'user_id')\n",
    "result4 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = 'user_id')\n",
    "result5 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = 'user_id')\n",
    "result6 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = 'user_id')\n",
    "result7 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = 'user_id')\n",
    "result8 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='latency', group_vars = 'user_id')\n",
    "result9 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='cycles_count', group_vars = 'user_id')\n",
    "result10 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='score', group_vars = 'user_id')\n",
    "result11 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='recovery_score', group_vars = 'user_id')\n",
    "result12 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='z1', group_vars = 'user_id')\n",
    "result13 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='z2', group_vars = 'user_id')\n",
    "result14 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='z3', group_vars = 'user_id')\n",
    "result15 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='z4', group_vars = 'user_id')\n",
    "result16 = mixed_effects_model(r_weightdf3, env=env, y_var = 'distance', x_var='z5', group_vars = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'The adjusted alpha level here is', alpha\n",
    "print 'The Bonferroni Correction here is', bonf_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "significant result:\n",
    "- slow wave sleep duration, small and positive, p-value 0.0115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print result5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 4 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "alpha = adjusted_alpha(r_weightdf4, env=env, group_vars='user_id', weighted=True)\n",
    "result1 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = 'user_id')\n",
    "result2 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = 'user_id')\n",
    "result3 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = 'user_id')\n",
    "result4 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = 'user_id')\n",
    "result5 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = 'user_id')\n",
    "result6 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = 'user_id')\n",
    "result7 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = 'user_id')\n",
    "result8 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='latency', group_vars = 'user_id')\n",
    "result9 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='cycles_count', group_vars = 'user_id')\n",
    "result10 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='score', group_vars = 'user_id')\n",
    "result11 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='recovery_score', group_vars = 'user_id')\n",
    "result12 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='z1', group_vars = 'user_id')\n",
    "result13 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='z2', group_vars = 'user_id')\n",
    "result14 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='z3', group_vars = 'user_id')\n",
    "result15 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='z4', group_vars = 'user_id')\n",
    "result16 = mixed_effects_model(r_weightdf4, env=env, y_var = 'distance', x_var='z5', group_vars = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'The adjusted alpha level here is', alpha\n",
    "print 'The Bonferroni Correction here is', bonf_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant results:\n",
    "- small and positive coefficient, p-value 0.0183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print result5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Weighted 5 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = Environment()\n",
    "alpha = adjusted_alpha(r_weightdf5, env=env, group_vars='user_id', weighted=True)\n",
    "result1 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='hrv_rmssd', group_vars = 'user_id')\n",
    "result2 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='resting_heart_rate', group_vars = 'user_id')\n",
    "result3 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='sleep_duration', group_vars = 'user_id')\n",
    "result4 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='rem_sleep_duration', group_vars = 'user_id')\n",
    "result5 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='slow_wave_sleep_duration', group_vars = 'user_id')\n",
    "result6 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='light_sleep_duration', group_vars = 'user_id')\n",
    "result7 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='time_in_bed', group_vars = 'user_id')\n",
    "result8 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='latency', group_vars = 'user_id')\n",
    "result9 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='cycles_count', group_vars = 'user_id')\n",
    "result10 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='score', group_vars = 'user_id')\n",
    "result11 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='recovery_score', group_vars = 'user_id')\n",
    "result12 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='z1', group_vars = 'user_id')\n",
    "result13 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='z2', group_vars = 'user_id')\n",
    "result14 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='z3', group_vars = 'user_id')\n",
    "result15 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='z4', group_vars = 'user_id')\n",
    "result16 = mixed_effects_model(r_weightdf5, env=env, y_var = 'distance', x_var='z5', group_vars = 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'The adjusted alpha level here is', alpha\n",
    "print 'The Bonferroni Correction here is', bonf_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
