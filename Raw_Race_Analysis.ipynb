{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "import time\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Simple OLS Regressions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, I look at simple OLS regressions of each variable on race performance to see if there are any significant associations between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>race_period</th>\n",
       "      <th>resting_heart_rate</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>time_in_bed</th>\n",
       "      <th>latency</th>\n",
       "      <th>rem_sleep_duration</th>\n",
       "      <th>slow_wave_sleep_duration</th>\n",
       "      <th>light_sleep_duration</th>\n",
       "      <th>wake_duration</th>\n",
       "      <th>cycles_count</th>\n",
       "      <th>score</th>\n",
       "      <th>recovery_score</th>\n",
       "      <th>user_2439</th>\n",
       "      <th>user_2456</th>\n",
       "      <th>user_2458</th>\n",
       "      <th>user_2465</th>\n",
       "      <th>user_2466</th>\n",
       "      <th>user_2468</th>\n",
       "      <th>user_2469</th>\n",
       "      <th>user_2473</th>\n",
       "      <th>user_2508</th>\n",
       "      <th>seconds</th>\n",
       "      <th>pace_per_k</th>\n",
       "      <th>pace_time</th>\n",
       "      <th>FP_5K</th>\n",
       "      <th>Wisco_8K</th>\n",
       "      <th>Brown_8K</th>\n",
       "      <th>VCP_8K</th>\n",
       "      <th>FP_10K</th>\n",
       "      <th>race_course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "      <td>1</td>\n",
       "      <td>45.180328</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>32983054.4242</td>\n",
       "      <td>1609090.757580</td>\n",
       "      <td>4505000.00000</td>\n",
       "      <td>3321818.18182</td>\n",
       "      <td>20104090.9091</td>\n",
       "      <td>5053636.36364</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>80.984848</td>\n",
       "      <td>65.426230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1529.2</td>\n",
       "      <td>191.1500</td>\n",
       "      <td>03:11.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>47.145833</td>\n",
       "      <td>0.055524</td>\n",
       "      <td>35072882.5625</td>\n",
       "      <td>1245231.197920</td>\n",
       "      <td>3633750.00000</td>\n",
       "      <td>4436562.50000</td>\n",
       "      <td>21996562.5000</td>\n",
       "      <td>5001874.94792</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>91.906250</td>\n",
       "      <td>63.802083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1552.3</td>\n",
       "      <td>194.0375</td>\n",
       "      <td>03:14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>3</td>\n",
       "      <td>45.916667</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>35219680.7292</td>\n",
       "      <td>1261142.541670</td>\n",
       "      <td>1525625.00000</td>\n",
       "      <td>7692187.50000</td>\n",
       "      <td>19688750.0000</td>\n",
       "      <td>6312812.50000</td>\n",
       "      <td>3.364583</td>\n",
       "      <td>87.156250</td>\n",
       "      <td>56.385417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1582.5</td>\n",
       "      <td>197.8125</td>\n",
       "      <td>03:17.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>828</td>\n",
       "      <td>4</td>\n",
       "      <td>44.663366</td>\n",
       "      <td>0.078605</td>\n",
       "      <td>42391598.3267</td>\n",
       "      <td>1041284.366340</td>\n",
       "      <td>3231386.13861</td>\n",
       "      <td>8411584.15842</td>\n",
       "      <td>21082277.2277</td>\n",
       "      <td>9663564.35644</td>\n",
       "      <td>6.584158</td>\n",
       "      <td>96.257426</td>\n",
       "      <td>70.940594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1932.7</td>\n",
       "      <td>193.2700</td>\n",
       "      <td>03:13.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP_10K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>828</td>\n",
       "      <td>5</td>\n",
       "      <td>45.400000</td>\n",
       "      <td>0.066477</td>\n",
       "      <td>35584066.6000</td>\n",
       "      <td>1155980.933330</td>\n",
       "      <td>2920000.00000</td>\n",
       "      <td>7196000.00000</td>\n",
       "      <td>19642000.0000</td>\n",
       "      <td>5788000.00000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>92.866667</td>\n",
       "      <td>58.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1617.6</td>\n",
       "      <td>202.2000</td>\n",
       "      <td>03:22.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>2456</td>\n",
       "      <td>1</td>\n",
       "      <td>43.303571</td>\n",
       "      <td>0.070463</td>\n",
       "      <td>31144514.3214</td>\n",
       "      <td>987083.446429</td>\n",
       "      <td>6983571.30357</td>\n",
       "      <td>3776250.00000</td>\n",
       "      <td>16126607.1429</td>\n",
       "      <td>4293214.28571</td>\n",
       "      <td>6.535714</td>\n",
       "      <td>67.178571</td>\n",
       "      <td>40.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1490.9</td>\n",
       "      <td>186.3625</td>\n",
       "      <td>03:06.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>2456</td>\n",
       "      <td>2</td>\n",
       "      <td>45.318681</td>\n",
       "      <td>0.078180</td>\n",
       "      <td>32313066.8462</td>\n",
       "      <td>911022.582418</td>\n",
       "      <td>3143076.92308</td>\n",
       "      <td>4748901.09890</td>\n",
       "      <td>21305274.7253</td>\n",
       "      <td>3003296.70330</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>78.010989</td>\n",
       "      <td>67.505495</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1476.8</td>\n",
       "      <td>184.6000</td>\n",
       "      <td>03:04.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wisco_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>2456</td>\n",
       "      <td>3</td>\n",
       "      <td>45.864078</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>30544817.3204</td>\n",
       "      <td>1090239.621360</td>\n",
       "      <td>2326019.41748</td>\n",
       "      <td>4119902.91262</td>\n",
       "      <td>18572330.0971</td>\n",
       "      <td>5283203.88350</td>\n",
       "      <td>5.029126</td>\n",
       "      <td>66.825243</td>\n",
       "      <td>60.398058</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>197.9625</td>\n",
       "      <td>03:18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>2456</td>\n",
       "      <td>4</td>\n",
       "      <td>45.394737</td>\n",
       "      <td>0.104513</td>\n",
       "      <td>31598658.1579</td>\n",
       "      <td>1072613.697370</td>\n",
       "      <td>1628684.21053</td>\n",
       "      <td>4693421.05263</td>\n",
       "      <td>19305789.4737</td>\n",
       "      <td>6010263.15789</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>77.881579</td>\n",
       "      <td>71.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.7</td>\n",
       "      <td>190.7700</td>\n",
       "      <td>03:10.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP_10K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>2456</td>\n",
       "      <td>5</td>\n",
       "      <td>44.111111</td>\n",
       "      <td>0.077258</td>\n",
       "      <td>29843729.7778</td>\n",
       "      <td>1103767.518520</td>\n",
       "      <td>2563333.33333</td>\n",
       "      <td>5328888.88889</td>\n",
       "      <td>16787777.7778</td>\n",
       "      <td>5201111.11111</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>73.740741</td>\n",
       "      <td>50.259259</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1550.2</td>\n",
       "      <td>193.7750</td>\n",
       "      <td>03:13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>2458</td>\n",
       "      <td>1</td>\n",
       "      <td>42.714286</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>33585533.5000</td>\n",
       "      <td>1015408.678570</td>\n",
       "      <td>15206250.00000</td>\n",
       "      <td>5044821.42857</td>\n",
       "      <td>10581964.2857</td>\n",
       "      <td>2717678.57143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>93.178571</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1590.6</td>\n",
       "      <td>198.8250</td>\n",
       "      <td>03:18.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>2458</td>\n",
       "      <td>2</td>\n",
       "      <td>42.285714</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>34219982.3905</td>\n",
       "      <td>1413162.276190</td>\n",
       "      <td>13447428.57140</td>\n",
       "      <td>3886285.71429</td>\n",
       "      <td>12441428.5714</td>\n",
       "      <td>4442857.13333</td>\n",
       "      <td>8.780952</td>\n",
       "      <td>91.495238</td>\n",
       "      <td>78.609524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1538.4</td>\n",
       "      <td>192.3000</td>\n",
       "      <td>03:12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>2458</td>\n",
       "      <td>3</td>\n",
       "      <td>39.468750</td>\n",
       "      <td>0.138084</td>\n",
       "      <td>34567095.7905</td>\n",
       "      <td>1502238.961900</td>\n",
       "      <td>2659714.28571</td>\n",
       "      <td>5241428.57143</td>\n",
       "      <td>17988000.0000</td>\n",
       "      <td>6212857.14286</td>\n",
       "      <td>4.514286</td>\n",
       "      <td>81.419048</td>\n",
       "      <td>79.229167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>2458</td>\n",
       "      <td>4</td>\n",
       "      <td>40.695238</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>33360100.0952</td>\n",
       "      <td>1468671.019050</td>\n",
       "      <td>2410857.14286</td>\n",
       "      <td>4851714.28571</td>\n",
       "      <td>20514571.4286</td>\n",
       "      <td>5444000.00000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>94.495238</td>\n",
       "      <td>78.457143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>2458</td>\n",
       "      <td>5</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.137977</td>\n",
       "      <td>33835199.9167</td>\n",
       "      <td>1664840.444440</td>\n",
       "      <td>2355833.33333</td>\n",
       "      <td>6995833.33333</td>\n",
       "      <td>18274166.6667</td>\n",
       "      <td>4907500.00000</td>\n",
       "      <td>4.861111</td>\n",
       "      <td>94.638889</td>\n",
       "      <td>72.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1679.2</td>\n",
       "      <td>209.9000</td>\n",
       "      <td>03:29.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20</td>\n",
       "      <td>2465</td>\n",
       "      <td>1</td>\n",
       "      <td>47.868421</td>\n",
       "      <td>0.119033</td>\n",
       "      <td>24958339.9556</td>\n",
       "      <td>904776.777778</td>\n",
       "      <td>3599333.33333</td>\n",
       "      <td>4251333.33333</td>\n",
       "      <td>15608666.4889</td>\n",
       "      <td>1526666.66667</td>\n",
       "      <td>5.368421</td>\n",
       "      <td>61.511111</td>\n",
       "      <td>63.289474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>185.8750</td>\n",
       "      <td>03:05.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>2465</td>\n",
       "      <td>2</td>\n",
       "      <td>46.945055</td>\n",
       "      <td>0.104742</td>\n",
       "      <td>32396402.7912</td>\n",
       "      <td>1323133.571430</td>\n",
       "      <td>4364505.48352</td>\n",
       "      <td>6269010.98901</td>\n",
       "      <td>17992417.5824</td>\n",
       "      <td>3302966.91209</td>\n",
       "      <td>5.340659</td>\n",
       "      <td>78.472527</td>\n",
       "      <td>64.901099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1516.8</td>\n",
       "      <td>189.6000</td>\n",
       "      <td>03:09.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wisco_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22</td>\n",
       "      <td>2465</td>\n",
       "      <td>3</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>0.101079</td>\n",
       "      <td>27584970.6866</td>\n",
       "      <td>889105.268657</td>\n",
       "      <td>3178208.95522</td>\n",
       "      <td>6098507.46269</td>\n",
       "      <td>13980447.7612</td>\n",
       "      <td>4277462.68657</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>69.970149</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>192.3750</td>\n",
       "      <td>03:12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>2465</td>\n",
       "      <td>4</td>\n",
       "      <td>49.669903</td>\n",
       "      <td>0.093038</td>\n",
       "      <td>35216562.8447</td>\n",
       "      <td>1334429.990290</td>\n",
       "      <td>3916893.20388</td>\n",
       "      <td>9773592.23301</td>\n",
       "      <td>15815825.2427</td>\n",
       "      <td>5707864.07767</td>\n",
       "      <td>6.135922</td>\n",
       "      <td>92.893204</td>\n",
       "      <td>68.038835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>191.8000</td>\n",
       "      <td>03:11.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP_10K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24</td>\n",
       "      <td>2465</td>\n",
       "      <td>5</td>\n",
       "      <td>49.928571</td>\n",
       "      <td>0.105784</td>\n",
       "      <td>32109303.3214</td>\n",
       "      <td>811709.821429</td>\n",
       "      <td>3235714.28571</td>\n",
       "      <td>8382857.14286</td>\n",
       "      <td>15812142.8571</td>\n",
       "      <td>4661785.71429</td>\n",
       "      <td>5.071429</td>\n",
       "      <td>79.714286</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>197.8750</td>\n",
       "      <td>03:17.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  user_id  race_period  resting_heart_rate  hrv_rmssd    time_in_bed         latency  rem_sleep_duration  slow_wave_sleep_duration  light_sleep_duration  wake_duration  cycles_count      score  recovery_score  user_2439  user_2456  user_2458  user_2465  user_2466  user_2468  user_2469  user_2473  user_2508  seconds  pace_per_k pace_time  FP_5K  Wisco_8K  Brown_8K  VCP_8K  FP_10K race_course\n",
       "0            0      828            1           45.180328   0.059197  32983054.4242  1609090.757580       4505000.00000             3321818.18182         20104090.9091  5053636.36364      7.000000  80.984848       65.426230          0          0          0          0          0          0          0          0          0   1529.2    191.1500   03:11.1      0         0         0       0       0       FP_8K\n",
       "1            1      828            2           47.145833   0.055524  35072882.5625  1245231.197920       3633750.00000             4436562.50000         21996562.5000  5001874.94792      5.437500  91.906250       63.802083          0          0          0          0          0          0          0          0          0   1552.3    194.0375   03:14.0      0         0         1       0       0    Brown_8K\n",
       "2            2      828            3           45.916667   0.074007  35219680.7292  1261142.541670       1525625.00000             7692187.50000         19688750.0000  6312812.50000      3.364583  87.156250       56.385417          0          0          0          0          0          0          0          0          0   1582.5    197.8125   03:17.8      0         0         0       1       0      VCP_8K\n",
       "3            3      828            4           44.663366   0.078605  42391598.3267  1041284.366340       3231386.13861             8411584.15842         21082277.2277  9663564.35644      6.584158  96.257426       70.940594          0          0          0          0          0          0          0          0          0   1932.7    193.2700   03:13.3      0         0         0       0       1      FP_10K\n",
       "4            4      828            5           45.400000   0.066477  35584066.6000  1155980.933330       2920000.00000             7196000.00000         19642000.0000  5788000.00000      5.333333  92.866667       58.733333          0          0          0          0          0          0          0          0          0   1617.6    202.2000   03:22.2      0         0         0       1       0      VCP_8K\n",
       "5           10     2456            1           43.303571   0.070463  31144514.3214   987083.446429       6983571.30357             3776250.00000         16126607.1429  4293214.28571      6.535714  67.178571       40.071429          0          1          0          0          0          0          0          0          0   1490.9    186.3625   03:06.4      0         0         0       0       0       FP_8K\n",
       "6           11     2456            2           45.318681   0.078180  32313066.8462   911022.582418       3143076.92308             4748901.09890         21305274.7253  3003296.70330      4.692308  78.010989       67.505495          0          1          0          0          0          0          0          0          0   1476.8    184.6000   03:04.6      0         1         0       0       0    Wisco_8K\n",
       "7           12     2456            3           45.864078   0.078022  30544817.3204  1090239.621360       2326019.41748             4119902.91262         18572330.0971  5283203.88350      5.029126  66.825243       60.398058          0          1          0          0          0          0          0          0          0   1583.7    197.9625   03:18.0      0         0         0       1       0      VCP_8K\n",
       "8           13     2456            4           45.394737   0.104513  31598658.1579  1072613.697370       1628684.21053             4693421.05263         19305789.4737  6010263.15789      3.421053  77.881579       71.250000          0          1          0          0          0          0          0          0          0   1907.7    190.7700   03:10.8      0         0         0       0       1      FP_10K\n",
       "9           14     2456            5           44.111111   0.077258  29843729.7778  1103767.518520       2563333.33333             5328888.88889         16787777.7778  5201111.11111      4.444444  73.740741       50.259259          0          1          0          0          0          0          0          0          0   1550.2    193.7750   03:13.8      0         0         0       1       0      VCP_8K\n",
       "10          15     2458            1           42.714286   0.124177  33585533.5000  1015408.678570      15206250.00000             5044821.42857         10581964.2857  2717678.57143      7.714286  93.178571       78.142857          0          0          1          0          0          0          0          0          0   1590.6    198.8250   03:18.8      0         0         0       0       0       FP_8K\n",
       "11          16     2458            2           42.285714   0.129573  34219982.3905  1413162.276190      13447428.57140             3886285.71429         12441428.5714  4442857.13333      8.780952  91.495238       78.609524          0          0          1          0          0          0          0          0          0   1538.4    192.3000   03:12.3      0         0         1       0       0    Brown_8K\n",
       "12          17     2458            3           39.468750   0.138084  34567095.7905  1502238.961900       2659714.28571             5241428.57143         17988000.0000  6212857.14286      4.514286  81.419048       79.229167          0          0          1          0          0          0          0          0          0      NaN         NaN       NaN    NaN       NaN       NaN     NaN     NaN         NaN\n",
       "13          18     2458            4           40.695238   0.135200  33360100.0952  1468671.019050       2410857.14286             4851714.28571         20514571.4286  5444000.00000      4.666667  94.495238       78.457143          0          0          1          0          0          0          0          0          0      NaN         NaN       NaN    NaN       NaN       NaN     NaN     NaN         NaN\n",
       "14          19     2458            5           40.500000   0.137977  33835199.9167  1664840.444440       2355833.33333             6995833.33333         18274166.6667  4907500.00000      4.861111  94.638889       72.916667          0          0          1          0          0          0          0          0          0   1679.2    209.9000   03:29.9      0         0         0       1       0      VCP_8K\n",
       "15          20     2465            1           47.868421   0.119033  24958339.9556   904776.777778       3599333.33333             4251333.33333         15608666.4889  1526666.66667      5.368421  61.511111       63.289474          0          0          0          1          0          0          0          0          0   1487.0    185.8750   03:05.9      0         0         0       0       0       FP_8K\n",
       "16          21     2465            2           46.945055   0.104742  32396402.7912  1323133.571430       4364505.48352             6269010.98901         17992417.5824  3302966.91209      5.340659  78.472527       64.901099          0          0          0          1          0          0          0          0          0   1516.8    189.6000   03:09.6      0         1         0       0       0    Wisco_8K\n",
       "17          22     2465            3           46.300000   0.101079  27584970.6866   889105.268657       3178208.95522             6098507.46269         13980447.7612  4277462.68657      5.466667  69.970149       60.533333          0          0          0          1          0          0          0          0          0   1539.0    192.3750   03:12.4      0         0         0       1       0      VCP_8K\n",
       "18          23     2465            4           49.669903   0.093038  35216562.8447  1334429.990290       3916893.20388             9773592.23301         15815825.2427  5707864.07767      6.135922  92.893204       68.038835          0          0          0          1          0          0          0          0          0   1918.0    191.8000   03:11.8      0         0         0       0       1      FP_10K\n",
       "19          24     2465            5           49.928571   0.105784  32109303.3214   811709.821429       3235714.28571             8382857.14286         15812142.8571  4661785.71429      5.071429  79.714286       75.500000          0          0          0          1          0          0          0          0          0   1583.0    197.8750   03:17.9      0         0         0       1       0      VCP_8K"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These data contain weighted averages for ALL days before a race\n",
    "\n",
    "df = pd.read_csv('final_race_df.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a variable for total sleep\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merging the two dataframes\n",
    "reg_df = pd.merge(df, df2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'user_id', u'race_period', u'resting_heart_rate', u'hrv_rmssd', u'time_in_bed', u'latency', u'rem_sleep_duration', u'slow_wave_sleep_duration', u'light_sleep_duration', u'wake_duration', u'cycles_count', u'score', u'recovery_score', u'user_2439', u'user_2456', u'user_2458', u'user_2465', u'user_2466', u'user_2468', u'user_2469', u'user_2473', u'user_2508', u'seconds', u'pace_per_k', u'pace_time', u'FP_5K', u'Wisco_8K', u'Brown_8K', u'VCP_8K', u'FP_10K', u'race_course',\n",
       "       u'sleep_duration', u'z1', u'z2', u'z3', u'z4', u'z5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the first column, which was just the index from when saving the dataframe to a csv earlier\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "reg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>race_period</th>\n",
       "      <th>resting_heart_rate</th>\n",
       "      <th>hrv_rmssd</th>\n",
       "      <th>time_in_bed</th>\n",
       "      <th>latency</th>\n",
       "      <th>rem_sleep_duration</th>\n",
       "      <th>slow_wave_sleep_duration</th>\n",
       "      <th>light_sleep_duration</th>\n",
       "      <th>wake_duration</th>\n",
       "      <th>cycles_count</th>\n",
       "      <th>score</th>\n",
       "      <th>recovery_score</th>\n",
       "      <th>user_2439</th>\n",
       "      <th>user_2456</th>\n",
       "      <th>user_2458</th>\n",
       "      <th>user_2465</th>\n",
       "      <th>user_2466</th>\n",
       "      <th>user_2468</th>\n",
       "      <th>user_2469</th>\n",
       "      <th>user_2473</th>\n",
       "      <th>user_2508</th>\n",
       "      <th>seconds</th>\n",
       "      <th>pace_per_k</th>\n",
       "      <th>pace_time</th>\n",
       "      <th>FP_5K</th>\n",
       "      <th>Wisco_8K</th>\n",
       "      <th>Brown_8K</th>\n",
       "      <th>VCP_8K</th>\n",
       "      <th>FP_10K</th>\n",
       "      <th>race_course</th>\n",
       "      <th>sleep_duration</th>\n",
       "      <th>z1</th>\n",
       "      <th>z2</th>\n",
       "      <th>z3</th>\n",
       "      <th>z4</th>\n",
       "      <th>z5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>828</td>\n",
       "      <td>1</td>\n",
       "      <td>45.180328</td>\n",
       "      <td>0.059197</td>\n",
       "      <td>32983054.4242</td>\n",
       "      <td>1609090.757580</td>\n",
       "      <td>4505000.00000</td>\n",
       "      <td>3321818.18182</td>\n",
       "      <td>20104090.9091</td>\n",
       "      <td>5053636.36364</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>80.984848</td>\n",
       "      <td>65.426230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1529.2</td>\n",
       "      <td>191.1500</td>\n",
       "      <td>03:11.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "      <td>27930909.09092</td>\n",
       "      <td>406.527273</td>\n",
       "      <td>702.909091</td>\n",
       "      <td>818.272727</td>\n",
       "      <td>1440.890909</td>\n",
       "      <td>259.927273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>47.145833</td>\n",
       "      <td>0.055524</td>\n",
       "      <td>35072882.5625</td>\n",
       "      <td>1245231.197920</td>\n",
       "      <td>3633750.00000</td>\n",
       "      <td>4436562.50000</td>\n",
       "      <td>21996562.5000</td>\n",
       "      <td>5001874.94792</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>91.906250</td>\n",
       "      <td>63.802083</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1552.3</td>\n",
       "      <td>194.0375</td>\n",
       "      <td>03:14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown_8K</td>\n",
       "      <td>30066875.00000</td>\n",
       "      <td>521.626374</td>\n",
       "      <td>444.879121</td>\n",
       "      <td>769.120879</td>\n",
       "      <td>1471.483516</td>\n",
       "      <td>333.890110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>828</td>\n",
       "      <td>3</td>\n",
       "      <td>45.916667</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>35219680.7292</td>\n",
       "      <td>1261142.541670</td>\n",
       "      <td>1525625.00000</td>\n",
       "      <td>7692187.50000</td>\n",
       "      <td>19688750.0000</td>\n",
       "      <td>6312812.50000</td>\n",
       "      <td>3.364583</td>\n",
       "      <td>87.156250</td>\n",
       "      <td>56.385417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1582.5</td>\n",
       "      <td>197.8125</td>\n",
       "      <td>03:17.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>28906562.50000</td>\n",
       "      <td>750.230769</td>\n",
       "      <td>809.208791</td>\n",
       "      <td>601.439560</td>\n",
       "      <td>1558.263736</td>\n",
       "      <td>202.208791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>828</td>\n",
       "      <td>4</td>\n",
       "      <td>44.663366</td>\n",
       "      <td>0.078605</td>\n",
       "      <td>42391598.3267</td>\n",
       "      <td>1041284.366340</td>\n",
       "      <td>3231386.13861</td>\n",
       "      <td>8411584.15842</td>\n",
       "      <td>21082277.2277</td>\n",
       "      <td>9663564.35644</td>\n",
       "      <td>6.584158</td>\n",
       "      <td>96.257426</td>\n",
       "      <td>70.940594</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1932.7</td>\n",
       "      <td>193.2700</td>\n",
       "      <td>03:13.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP_10K</td>\n",
       "      <td>32725247.52473</td>\n",
       "      <td>472.142857</td>\n",
       "      <td>373.549451</td>\n",
       "      <td>627.571429</td>\n",
       "      <td>1631.318681</td>\n",
       "      <td>151.912088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>828</td>\n",
       "      <td>5</td>\n",
       "      <td>45.400000</td>\n",
       "      <td>0.066477</td>\n",
       "      <td>35584066.6000</td>\n",
       "      <td>1155980.933330</td>\n",
       "      <td>2920000.00000</td>\n",
       "      <td>7196000.00000</td>\n",
       "      <td>19642000.0000</td>\n",
       "      <td>5788000.00000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>92.866667</td>\n",
       "      <td>58.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1617.6</td>\n",
       "      <td>202.2000</td>\n",
       "      <td>03:22.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>29758000.00000</td>\n",
       "      <td>410.321429</td>\n",
       "      <td>412.500000</td>\n",
       "      <td>436.857143</td>\n",
       "      <td>1073.107143</td>\n",
       "      <td>79.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2456</td>\n",
       "      <td>1</td>\n",
       "      <td>43.303571</td>\n",
       "      <td>0.070463</td>\n",
       "      <td>31144514.3214</td>\n",
       "      <td>987083.446429</td>\n",
       "      <td>6983571.30357</td>\n",
       "      <td>3776250.00000</td>\n",
       "      <td>16126607.1429</td>\n",
       "      <td>4293214.28571</td>\n",
       "      <td>6.535714</td>\n",
       "      <td>67.178571</td>\n",
       "      <td>40.071429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1490.9</td>\n",
       "      <td>186.3625</td>\n",
       "      <td>03:06.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "      <td>26886428.44647</td>\n",
       "      <td>872.454545</td>\n",
       "      <td>755.690909</td>\n",
       "      <td>814.454545</td>\n",
       "      <td>1406.036364</td>\n",
       "      <td>1683.509091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2456</td>\n",
       "      <td>2</td>\n",
       "      <td>45.318681</td>\n",
       "      <td>0.078180</td>\n",
       "      <td>32313066.8462</td>\n",
       "      <td>911022.582418</td>\n",
       "      <td>3143076.92308</td>\n",
       "      <td>4748901.09890</td>\n",
       "      <td>21305274.7253</td>\n",
       "      <td>3003296.70330</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>78.010989</td>\n",
       "      <td>67.505495</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1476.8</td>\n",
       "      <td>184.6000</td>\n",
       "      <td>03:04.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wisco_8K</td>\n",
       "      <td>29197252.74728</td>\n",
       "      <td>475.153846</td>\n",
       "      <td>486.285714</td>\n",
       "      <td>431.109890</td>\n",
       "      <td>1264.923077</td>\n",
       "      <td>2581.197802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2456</td>\n",
       "      <td>3</td>\n",
       "      <td>45.864078</td>\n",
       "      <td>0.078022</td>\n",
       "      <td>30544817.3204</td>\n",
       "      <td>1090239.621360</td>\n",
       "      <td>2326019.41748</td>\n",
       "      <td>4119902.91262</td>\n",
       "      <td>18572330.0971</td>\n",
       "      <td>5283203.88350</td>\n",
       "      <td>5.029126</td>\n",
       "      <td>66.825243</td>\n",
       "      <td>60.398058</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1583.7</td>\n",
       "      <td>197.9625</td>\n",
       "      <td>03:18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>25018252.42720</td>\n",
       "      <td>535.989011</td>\n",
       "      <td>464.978022</td>\n",
       "      <td>325.142857</td>\n",
       "      <td>1083.549451</td>\n",
       "      <td>1926.208791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2456</td>\n",
       "      <td>4</td>\n",
       "      <td>45.394737</td>\n",
       "      <td>0.104513</td>\n",
       "      <td>31598658.1579</td>\n",
       "      <td>1072613.697370</td>\n",
       "      <td>1628684.21053</td>\n",
       "      <td>4693421.05263</td>\n",
       "      <td>19305789.4737</td>\n",
       "      <td>6010263.15789</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>77.881579</td>\n",
       "      <td>71.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1907.7</td>\n",
       "      <td>190.7700</td>\n",
       "      <td>03:10.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP_10K</td>\n",
       "      <td>25627894.73686</td>\n",
       "      <td>502.901099</td>\n",
       "      <td>312.384615</td>\n",
       "      <td>143.714286</td>\n",
       "      <td>401.087912</td>\n",
       "      <td>325.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2456</td>\n",
       "      <td>5</td>\n",
       "      <td>44.111111</td>\n",
       "      <td>0.077258</td>\n",
       "      <td>29843729.7778</td>\n",
       "      <td>1103767.518520</td>\n",
       "      <td>2563333.33333</td>\n",
       "      <td>5328888.88889</td>\n",
       "      <td>16787777.7778</td>\n",
       "      <td>5201111.11111</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>73.740741</td>\n",
       "      <td>50.259259</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1550.2</td>\n",
       "      <td>193.7750</td>\n",
       "      <td>03:13.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>24680000.00002</td>\n",
       "      <td>671.750000</td>\n",
       "      <td>260.357143</td>\n",
       "      <td>86.821429</td>\n",
       "      <td>384.500000</td>\n",
       "      <td>802.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2458</td>\n",
       "      <td>1</td>\n",
       "      <td>42.714286</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>33585533.5000</td>\n",
       "      <td>1015408.678570</td>\n",
       "      <td>15206250.00000</td>\n",
       "      <td>5044821.42857</td>\n",
       "      <td>10581964.2857</td>\n",
       "      <td>2717678.57143</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>93.178571</td>\n",
       "      <td>78.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1590.6</td>\n",
       "      <td>198.8250</td>\n",
       "      <td>03:18.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "      <td>30833035.71427</td>\n",
       "      <td>935.454545</td>\n",
       "      <td>782.763636</td>\n",
       "      <td>771.727273</td>\n",
       "      <td>1724.181818</td>\n",
       "      <td>32.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2458</td>\n",
       "      <td>2</td>\n",
       "      <td>42.285714</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>34219982.3905</td>\n",
       "      <td>1413162.276190</td>\n",
       "      <td>13447428.57140</td>\n",
       "      <td>3886285.71429</td>\n",
       "      <td>12441428.5714</td>\n",
       "      <td>4442857.13333</td>\n",
       "      <td>8.780952</td>\n",
       "      <td>91.495238</td>\n",
       "      <td>78.609524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1538.4</td>\n",
       "      <td>192.3000</td>\n",
       "      <td>03:12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Brown_8K</td>\n",
       "      <td>29775142.85709</td>\n",
       "      <td>900.043956</td>\n",
       "      <td>878.670330</td>\n",
       "      <td>1270.219780</td>\n",
       "      <td>2373.604396</td>\n",
       "      <td>161.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2458</td>\n",
       "      <td>3</td>\n",
       "      <td>39.468750</td>\n",
       "      <td>0.138084</td>\n",
       "      <td>34567095.7905</td>\n",
       "      <td>1502238.961900</td>\n",
       "      <td>2659714.28571</td>\n",
       "      <td>5241428.57143</td>\n",
       "      <td>17988000.0000</td>\n",
       "      <td>6212857.14286</td>\n",
       "      <td>4.514286</td>\n",
       "      <td>81.419048</td>\n",
       "      <td>79.229167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25889142.85714</td>\n",
       "      <td>859.857143</td>\n",
       "      <td>613.516484</td>\n",
       "      <td>969.659341</td>\n",
       "      <td>1973.175824</td>\n",
       "      <td>149.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2458</td>\n",
       "      <td>4</td>\n",
       "      <td>40.695238</td>\n",
       "      <td>0.135200</td>\n",
       "      <td>33360100.0952</td>\n",
       "      <td>1468671.019050</td>\n",
       "      <td>2410857.14286</td>\n",
       "      <td>4851714.28571</td>\n",
       "      <td>20514571.4286</td>\n",
       "      <td>5444000.00000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>94.495238</td>\n",
       "      <td>78.457143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27777142.85717</td>\n",
       "      <td>529.659341</td>\n",
       "      <td>647.461538</td>\n",
       "      <td>1191.032967</td>\n",
       "      <td>2021.934066</td>\n",
       "      <td>203.890110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2458</td>\n",
       "      <td>5</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.137977</td>\n",
       "      <td>33835199.9167</td>\n",
       "      <td>1664840.444440</td>\n",
       "      <td>2355833.33333</td>\n",
       "      <td>6995833.33333</td>\n",
       "      <td>18274166.6667</td>\n",
       "      <td>4907500.00000</td>\n",
       "      <td>4.861111</td>\n",
       "      <td>94.638889</td>\n",
       "      <td>72.916667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1679.2</td>\n",
       "      <td>209.9000</td>\n",
       "      <td>03:29.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>27625833.33336</td>\n",
       "      <td>917.000000</td>\n",
       "      <td>711.809524</td>\n",
       "      <td>699.142857</td>\n",
       "      <td>1404.333333</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2465</td>\n",
       "      <td>1</td>\n",
       "      <td>47.868421</td>\n",
       "      <td>0.119033</td>\n",
       "      <td>24958339.9556</td>\n",
       "      <td>904776.777778</td>\n",
       "      <td>3599333.33333</td>\n",
       "      <td>4251333.33333</td>\n",
       "      <td>15608666.4889</td>\n",
       "      <td>1526666.66667</td>\n",
       "      <td>5.368421</td>\n",
       "      <td>61.511111</td>\n",
       "      <td>63.289474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>185.8750</td>\n",
       "      <td>03:05.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>FP_8K</td>\n",
       "      <td>23459333.15556</td>\n",
       "      <td>471.472727</td>\n",
       "      <td>647.018182</td>\n",
       "      <td>946.563636</td>\n",
       "      <td>731.090909</td>\n",
       "      <td>40.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2465</td>\n",
       "      <td>2</td>\n",
       "      <td>46.945055</td>\n",
       "      <td>0.104742</td>\n",
       "      <td>32396402.7912</td>\n",
       "      <td>1323133.571430</td>\n",
       "      <td>4364505.48352</td>\n",
       "      <td>6269010.98901</td>\n",
       "      <td>17992417.5824</td>\n",
       "      <td>3302966.91209</td>\n",
       "      <td>5.340659</td>\n",
       "      <td>78.472527</td>\n",
       "      <td>64.901099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1516.8</td>\n",
       "      <td>189.6000</td>\n",
       "      <td>03:09.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wisco_8K</td>\n",
       "      <td>28625934.05493</td>\n",
       "      <td>1020.516484</td>\n",
       "      <td>908.307692</td>\n",
       "      <td>2000.065934</td>\n",
       "      <td>1937.769231</td>\n",
       "      <td>162.813187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2465</td>\n",
       "      <td>3</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>0.101079</td>\n",
       "      <td>27584970.6866</td>\n",
       "      <td>889105.268657</td>\n",
       "      <td>3178208.95522</td>\n",
       "      <td>6098507.46269</td>\n",
       "      <td>13980447.7612</td>\n",
       "      <td>4277462.68657</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>69.970149</td>\n",
       "      <td>60.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>192.3750</td>\n",
       "      <td>03:12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>23257164.17911</td>\n",
       "      <td>237.670330</td>\n",
       "      <td>295.120879</td>\n",
       "      <td>784.626374</td>\n",
       "      <td>797.615385</td>\n",
       "      <td>30.373626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2465</td>\n",
       "      <td>4</td>\n",
       "      <td>49.669903</td>\n",
       "      <td>0.093038</td>\n",
       "      <td>35216562.8447</td>\n",
       "      <td>1334429.990290</td>\n",
       "      <td>3916893.20388</td>\n",
       "      <td>9773592.23301</td>\n",
       "      <td>15815825.2427</td>\n",
       "      <td>5707864.07767</td>\n",
       "      <td>6.135922</td>\n",
       "      <td>92.893204</td>\n",
       "      <td>68.038835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>191.8000</td>\n",
       "      <td>03:11.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FP_10K</td>\n",
       "      <td>29506310.67959</td>\n",
       "      <td>231.241758</td>\n",
       "      <td>206.879121</td>\n",
       "      <td>260.626374</td>\n",
       "      <td>144.813187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2465</td>\n",
       "      <td>5</td>\n",
       "      <td>49.928571</td>\n",
       "      <td>0.105784</td>\n",
       "      <td>32109303.3214</td>\n",
       "      <td>811709.821429</td>\n",
       "      <td>3235714.28571</td>\n",
       "      <td>8382857.14286</td>\n",
       "      <td>15812142.8571</td>\n",
       "      <td>4661785.71429</td>\n",
       "      <td>5.071429</td>\n",
       "      <td>79.714286</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>197.8750</td>\n",
       "      <td>03:17.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>VCP_8K</td>\n",
       "      <td>27430714.28567</td>\n",
       "      <td>423.785714</td>\n",
       "      <td>397.892857</td>\n",
       "      <td>874.071429</td>\n",
       "      <td>762.071429</td>\n",
       "      <td>82.464286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  race_period  resting_heart_rate  hrv_rmssd    time_in_bed         latency  rem_sleep_duration  slow_wave_sleep_duration  light_sleep_duration  wake_duration  cycles_count      score  recovery_score  user_2439  user_2456  user_2458  user_2465  user_2466  user_2468  user_2469  user_2473  user_2508  seconds  pace_per_k pace_time  FP_5K  Wisco_8K  Brown_8K  VCP_8K  FP_10K race_course  sleep_duration           z1          z2           z3           z4           z5\n",
       "0       828            1           45.180328   0.059197  32983054.4242  1609090.757580       4505000.00000             3321818.18182         20104090.9091  5053636.36364      7.000000  80.984848       65.426230          0          0          0          0          0          0          0          0          0   1529.2    191.1500   03:11.1      0         0         0       0       0       FP_8K  27930909.09092   406.527273  702.909091   818.272727  1440.890909   259.927273\n",
       "1       828            2           47.145833   0.055524  35072882.5625  1245231.197920       3633750.00000             4436562.50000         21996562.5000  5001874.94792      5.437500  91.906250       63.802083          0          0          0          0          0          0          0          0          0   1552.3    194.0375   03:14.0      0         0         1       0       0    Brown_8K  30066875.00000   521.626374  444.879121   769.120879  1471.483516   333.890110\n",
       "2       828            3           45.916667   0.074007  35219680.7292  1261142.541670       1525625.00000             7692187.50000         19688750.0000  6312812.50000      3.364583  87.156250       56.385417          0          0          0          0          0          0          0          0          0   1582.5    197.8125   03:17.8      0         0         0       1       0      VCP_8K  28906562.50000   750.230769  809.208791   601.439560  1558.263736   202.208791\n",
       "3       828            4           44.663366   0.078605  42391598.3267  1041284.366340       3231386.13861             8411584.15842         21082277.2277  9663564.35644      6.584158  96.257426       70.940594          0          0          0          0          0          0          0          0          0   1932.7    193.2700   03:13.3      0         0         0       0       1      FP_10K  32725247.52473   472.142857  373.549451   627.571429  1631.318681   151.912088\n",
       "4       828            5           45.400000   0.066477  35584066.6000  1155980.933330       2920000.00000             7196000.00000         19642000.0000  5788000.00000      5.333333  92.866667       58.733333          0          0          0          0          0          0          0          0          0   1617.6    202.2000   03:22.2      0         0         0       1       0      VCP_8K  29758000.00000   410.321429  412.500000   436.857143  1073.107143    79.535714\n",
       "5      2456            1           43.303571   0.070463  31144514.3214   987083.446429       6983571.30357             3776250.00000         16126607.1429  4293214.28571      6.535714  67.178571       40.071429          0          1          0          0          0          0          0          0          0   1490.9    186.3625   03:06.4      0         0         0       0       0       FP_8K  26886428.44647   872.454545  755.690909   814.454545  1406.036364  1683.509091\n",
       "6      2456            2           45.318681   0.078180  32313066.8462   911022.582418       3143076.92308             4748901.09890         21305274.7253  3003296.70330      4.692308  78.010989       67.505495          0          1          0          0          0          0          0          0          0   1476.8    184.6000   03:04.6      0         1         0       0       0    Wisco_8K  29197252.74728   475.153846  486.285714   431.109890  1264.923077  2581.197802\n",
       "7      2456            3           45.864078   0.078022  30544817.3204  1090239.621360       2326019.41748             4119902.91262         18572330.0971  5283203.88350      5.029126  66.825243       60.398058          0          1          0          0          0          0          0          0          0   1583.7    197.9625   03:18.0      0         0         0       1       0      VCP_8K  25018252.42720   535.989011  464.978022   325.142857  1083.549451  1926.208791\n",
       "8      2456            4           45.394737   0.104513  31598658.1579  1072613.697370       1628684.21053             4693421.05263         19305789.4737  6010263.15789      3.421053  77.881579       71.250000          0          1          0          0          0          0          0          0          0   1907.7    190.7700   03:10.8      0         0         0       0       1      FP_10K  25627894.73686   502.901099  312.384615   143.714286   401.087912   325.153846\n",
       "9      2456            5           44.111111   0.077258  29843729.7778  1103767.518520       2563333.33333             5328888.88889         16787777.7778  5201111.11111      4.444444  73.740741       50.259259          0          1          0          0          0          0          0          0          0   1550.2    193.7750   03:13.8      0         0         0       1       0      VCP_8K  24680000.00002   671.750000  260.357143    86.821429   384.500000   802.142857\n",
       "10     2458            1           42.714286   0.124177  33585533.5000  1015408.678570      15206250.00000             5044821.42857         10581964.2857  2717678.57143      7.714286  93.178571       78.142857          0          0          1          0          0          0          0          0          0   1590.6    198.8250   03:18.8      0         0         0       0       0       FP_8K  30833035.71427   935.454545  782.763636   771.727273  1724.181818    32.400000\n",
       "11     2458            2           42.285714   0.129573  34219982.3905  1413162.276190      13447428.57140             3886285.71429         12441428.5714  4442857.13333      8.780952  91.495238       78.609524          0          0          1          0          0          0          0          0          0   1538.4    192.3000   03:12.3      0         0         1       0       0    Brown_8K  29775142.85709   900.043956  878.670330  1270.219780  2373.604396   161.868132\n",
       "12     2458            3           39.468750   0.138084  34567095.7905  1502238.961900       2659714.28571             5241428.57143         17988000.0000  6212857.14286      4.514286  81.419048       79.229167          0          0          1          0          0          0          0          0          0      NaN         NaN       NaN    NaN       NaN       NaN     NaN     NaN         NaN  25889142.85714   859.857143  613.516484   969.659341  1973.175824   149.076923\n",
       "13     2458            4           40.695238   0.135200  33360100.0952  1468671.019050       2410857.14286             4851714.28571         20514571.4286  5444000.00000      4.666667  94.495238       78.457143          0          0          1          0          0          0          0          0          0      NaN         NaN       NaN    NaN       NaN       NaN     NaN     NaN         NaN  27777142.85717   529.659341  647.461538  1191.032967  2021.934066   203.890110\n",
       "14     2458            5           40.500000   0.137977  33835199.9167  1664840.444440       2355833.33333             6995833.33333         18274166.6667  4907500.00000      4.861111  94.638889       72.916667          0          0          1          0          0          0          0          0          0   1679.2    209.9000   03:29.9      0         0         0       1       0      VCP_8K  27625833.33336   917.000000  711.809524   699.142857  1404.333333   130.000000\n",
       "15     2465            1           47.868421   0.119033  24958339.9556   904776.777778       3599333.33333             4251333.33333         15608666.4889  1526666.66667      5.368421  61.511111       63.289474          0          0          0          1          0          0          0          0          0   1487.0    185.8750   03:05.9      0         0         0       0       0       FP_8K  23459333.15556   471.472727  647.018182   946.563636   731.090909    40.254545\n",
       "16     2465            2           46.945055   0.104742  32396402.7912  1323133.571430       4364505.48352             6269010.98901         17992417.5824  3302966.91209      5.340659  78.472527       64.901099          0          0          0          1          0          0          0          0          0   1516.8    189.6000   03:09.6      0         1         0       0       0    Wisco_8K  28625934.05493  1020.516484  908.307692  2000.065934  1937.769231   162.813187\n",
       "17     2465            3           46.300000   0.101079  27584970.6866   889105.268657       3178208.95522             6098507.46269         13980447.7612  4277462.68657      5.466667  69.970149       60.533333          0          0          0          1          0          0          0          0          0   1539.0    192.3750   03:12.4      0         0         0       1       0      VCP_8K  23257164.17911   237.670330  295.120879   784.626374   797.615385    30.373626\n",
       "18     2465            4           49.669903   0.093038  35216562.8447  1334429.990290       3916893.20388             9773592.23301         15815825.2427  5707864.07767      6.135922  92.893204       68.038835          0          0          0          1          0          0          0          0          0   1918.0    191.8000   03:11.8      0         0         0       0       1      FP_10K  29506310.67959   231.241758  206.879121   260.626374   144.813187     0.000000\n",
       "19     2465            5           49.928571   0.105784  32109303.3214   811709.821429       3235714.28571             8382857.14286         15812142.8571  4661785.71429      5.071429  79.714286       75.500000          0          0          0          1          0          0          0          0          0   1583.0    197.8750   03:17.9      0         0         0       1       0      VCP_8K  27430714.28567   423.785714  397.892857   874.071429   762.071429    82.464286"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we regress one variable at a time, and also include the dummy variables for both racer and race course.\n",
    "\n",
    "Significant results:\n",
    "- light sleep duration, with a p-value of 0.009 but a very small coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>8.09e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:49:43</td>     <th>  Log-Likelihood:    </th> <td> -83.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  192.6618</td> <td>    4.021</td> <td>   47.917</td> <td> 0.000</td> <td>  184.300   201.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hrv_rmssd</th> <td>  -29.5197</td> <td>   57.907</td> <td>   -0.510</td> <td> 0.616</td> <td> -149.944    90.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -5.0515</td> <td>    2.268</td> <td>   -2.228</td> <td> 0.037</td> <td>   -9.767    -0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    8.3647</td> <td>    4.580</td> <td>    1.826</td> <td> 0.082</td> <td>   -1.159    17.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -3.5601</td> <td>    2.988</td> <td>   -1.192</td> <td> 0.247</td> <td>   -9.773     2.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    5.9813</td> <td>    4.793</td> <td>    1.248</td> <td> 0.226</td> <td>   -3.986    15.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -4.0645</td> <td>    2.149</td> <td>   -1.891</td> <td> 0.072</td> <td>   -8.534     0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    1.3258</td> <td>    2.676</td> <td>    0.495</td> <td> 0.625</td> <td>   -4.239     6.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -7.0749</td> <td>    3.901</td> <td>   -1.814</td> <td> 0.084</td> <td>  -15.187     1.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.6326</td> <td>    3.640</td> <td>    2.646</td> <td> 0.015</td> <td>    2.063    17.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>  -10.2513</td> <td>    4.801</td> <td>   -2.135</td> <td> 0.045</td> <td>  -20.234    -0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    1.5169</td> <td>    1.958</td> <td>    0.775</td> <td> 0.447</td> <td>   -2.555     5.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -0.9434</td> <td>    2.817</td> <td>   -0.335</td> <td> 0.741</td> <td>   -6.802     4.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>   10.4525</td> <td>    1.511</td> <td>    6.917</td> <td> 0.000</td> <td>    7.310    13.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    5.0531</td> <td>    2.043</td> <td>    2.473</td> <td> 0.022</td> <td>    0.804     9.302</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.991</td> <th>  Durbin-Watson:     </th> <td>   2.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.609</td> <th>  Jarque-Bera (JB):  </th> <td>   0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.185</td> <th>  Prob(JB):          </th> <td>   0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.279</td> <th>  Cond. No.          </th> <td>    126.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.883\n",
       "Model:                            OLS   Adj. R-squared:                  0.806\n",
       "Method:                 Least Squares   F-statistic:                     11.36\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           8.09e-07\n",
       "Time:                        09:49:43   Log-Likelihood:                -83.643\n",
       "No. Observations:                  36   AIC:                             197.3\n",
       "Df Residuals:                      21   BIC:                             221.0\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    192.6618      4.021     47.917      0.000       184.300   201.023\n",
       "hrv_rmssd    -29.5197     57.907     -0.510      0.616      -149.944    90.905\n",
       "user_2456     -5.0515      2.268     -2.228      0.037        -9.767    -0.336\n",
       "user_2458      8.3647      4.580      1.826      0.082        -1.159    17.889\n",
       "user_2465     -3.5601      2.988     -1.192      0.247        -9.773     2.653\n",
       "user_2466      5.9813      4.793      1.248      0.226        -3.986    15.949\n",
       "user_2468     -4.0645      2.149     -1.891      0.072        -8.534     0.405\n",
       "user_2469      1.3258      2.676      0.495      0.625        -4.239     6.891\n",
       "user_2473     -7.0749      3.901     -1.814      0.084       -15.187     1.037\n",
       "user_2508      9.6326      3.640      2.646      0.015         2.063    17.202\n",
       "FP_5K        -10.2513      4.801     -2.135      0.045       -20.234    -0.268\n",
       "Wisco_8K       1.5169      1.958      0.775      0.447        -2.555     5.589\n",
       "Brown_8K      -0.9434      2.817     -0.335      0.741        -6.802     4.915\n",
       "VCP_8K        10.4525      1.511      6.917      0.000         7.310    13.595\n",
       "FP_10K         5.0531      2.043      2.473      0.022         0.804     9.302\n",
       "==============================================================================\n",
       "Omnibus:                        0.991   Durbin-Watson:                   2.630\n",
       "Prob(Omnibus):                  0.609   Jarque-Bera (JB):                0.322\n",
       "Skew:                           0.185   Prob(JB):                        0.851\n",
       "Kurtosis:                       3.279   Cond. No.                         126.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>7.67e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:49:50</td>     <th>  Log-Likelihood:    </th> <td> -83.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   220.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>  177.8540</td> <td>   21.263</td> <td>    8.364</td> <td> 0.000</td> <td>  133.635   222.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>resting_heart_rate</th> <td>    0.2837</td> <td>    0.463</td> <td>    0.613</td> <td> 0.546</td> <td>   -0.679     1.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>          <td>   -5.2328</td> <td>    2.159</td> <td>   -2.423</td> <td> 0.024</td> <td>   -9.723    -0.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>          <td>    7.5398</td> <td>    3.061</td> <td>    2.463</td> <td> 0.023</td> <td>    1.174    13.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>          <td>   -5.3705</td> <td>    2.458</td> <td>   -2.185</td> <td> 0.040</td> <td>  -10.482    -0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>          <td>    4.1295</td> <td>    2.203</td> <td>    1.875</td> <td> 0.075</td> <td>   -0.452     8.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>          <td>   -3.0767</td> <td>    2.578</td> <td>   -1.193</td> <td> 0.246</td> <td>   -8.438     2.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>          <td>   -1.5628</td> <td>    6.114</td> <td>   -0.256</td> <td> 0.801</td> <td>  -14.278    11.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>          <td>   -7.8755</td> <td>    2.761</td> <td>   -2.852</td> <td> 0.010</td> <td>  -13.618    -2.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>          <td>    8.7432</td> <td>    3.880</td> <td>    2.253</td> <td> 0.035</td> <td>    0.673    16.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>              <td>  -11.7521</td> <td>    5.305</td> <td>   -2.215</td> <td> 0.038</td> <td>  -22.785    -0.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>           <td>    1.2466</td> <td>    1.912</td> <td>    0.652</td> <td> 0.521</td> <td>   -2.730     5.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>           <td>   -1.1413</td> <td>    2.842</td> <td>   -0.402</td> <td> 0.692</td> <td>   -7.051     4.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>             <td>   10.3798</td> <td>    1.461</td> <td>    7.103</td> <td> 0.000</td> <td>    7.341    13.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>             <td>    4.8099</td> <td>    1.916</td> <td>    2.511</td> <td> 0.020</td> <td>    0.826     8.794</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.641</td> <th>  Durbin-Watson:     </th> <td>   2.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.267</td> <th>  Jarque-Bera (JB):  </th> <td>   1.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.355</td> <th>  Prob(JB):          </th> <td>   0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.687</td> <th>  Cond. No.          </th> <td>1.92e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.884\n",
       "Model:                            OLS   Adj. R-squared:                  0.807\n",
       "Method:                 Least Squares   F-statistic:                     11.43\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           7.67e-07\n",
       "Time:                        09:49:50   Log-Likelihood:                -83.545\n",
       "No. Observations:                  36   AIC:                             197.1\n",
       "Df Residuals:                      21   BIC:                             220.8\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept            177.8540     21.263      8.364      0.000       133.635   222.073\n",
       "resting_heart_rate     0.2837      0.463      0.613      0.546        -0.679     1.246\n",
       "user_2456             -5.2328      2.159     -2.423      0.024        -9.723    -0.742\n",
       "user_2458              7.5398      3.061      2.463      0.023         1.174    13.906\n",
       "user_2465             -5.3705      2.458     -2.185      0.040       -10.482    -0.258\n",
       "user_2466              4.1295      2.203      1.875      0.075        -0.452     8.711\n",
       "user_2468             -3.0767      2.578     -1.193      0.246        -8.438     2.285\n",
       "user_2469             -1.5628      6.114     -0.256      0.801       -14.278    11.153\n",
       "user_2473             -7.8755      2.761     -2.852      0.010       -13.618    -2.133\n",
       "user_2508              8.7432      3.880      2.253      0.035         0.673    16.813\n",
       "FP_5K                -11.7521      5.305     -2.215      0.038       -22.785    -0.719\n",
       "Wisco_8K               1.2466      1.912      0.652      0.521        -2.730     5.223\n",
       "Brown_8K              -1.1413      2.842     -0.402      0.692        -7.051     4.768\n",
       "VCP_8K                10.3798      1.461      7.103      0.000         7.341    13.419\n",
       "FP_10K                 4.8099      1.916      2.511      0.020         0.826     8.794\n",
       "==============================================================================\n",
       "Omnibus:                        2.641   Durbin-Watson:                   2.594\n",
       "Prob(Omnibus):                  0.267   Jarque-Bera (JB):                1.464\n",
       "Skew:                           0.355   Prob(JB):                        0.481\n",
       "Kurtosis:                       3.687   Cond. No.                     1.92e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.92e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>7.06e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:49:53</td>     <th>  Log-Likelihood:    </th> <td> -83.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   196.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   220.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>  182.3790</td> <td>   11.478</td> <td>   15.889</td> <td> 0.000</td> <td>  158.509   206.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sleep_duration</th> <td> 2.796e-07</td> <td> 3.74e-07</td> <td>    0.747</td> <td> 0.464</td> <td>-4.99e-07  1.06e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>      <td>   -4.3367</td> <td>    2.584</td> <td>   -1.679</td> <td> 0.108</td> <td>   -9.710     1.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>      <td>    6.4651</td> <td>    2.400</td> <td>    2.694</td> <td> 0.014</td> <td>    1.474    11.456</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>      <td>   -3.5744</td> <td>    2.547</td> <td>   -1.403</td> <td> 0.175</td> <td>   -8.872     1.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>      <td>    5.2144</td> <td>    2.851</td> <td>    1.829</td> <td> 0.082</td> <td>   -0.715    11.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>      <td>   -3.7690</td> <td>    2.141</td> <td>   -1.760</td> <td> 0.093</td> <td>   -8.222     0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>      <td>    1.8824</td> <td>    2.434</td> <td>    0.773</td> <td> 0.448</td> <td>   -3.180     6.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>      <td>   -7.2509</td> <td>    3.072</td> <td>   -2.360</td> <td> 0.028</td> <td>  -13.640    -0.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>      <td>   11.2753</td> <td>    4.263</td> <td>    2.645</td> <td> 0.015</td> <td>    2.409    20.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>          <td>  -12.9209</td> <td>    5.881</td> <td>   -2.197</td> <td> 0.039</td> <td>  -25.150    -0.691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>       <td>    0.9010</td> <td>    1.978</td> <td>    0.456</td> <td> 0.653</td> <td>   -3.212     5.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>       <td>   -0.8099</td> <td>    2.794</td> <td>   -0.290</td> <td> 0.775</td> <td>   -6.620     5.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>         <td>   10.6289</td> <td>    1.532</td> <td>    6.937</td> <td> 0.000</td> <td>    7.442    13.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>         <td>    4.3527</td> <td>    1.947</td> <td>    2.235</td> <td> 0.036</td> <td>    0.303     8.402</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.664</td> <th>  Durbin-Watson:     </th> <td>   2.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.718</td> <th>  Jarque-Bera (JB):  </th> <td>   0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.152</td> <th>  Prob(JB):          </th> <td>   0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.156</td> <th>  Cond. No.          </th> <td>6.73e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.885\n",
       "Model:                            OLS   Adj. R-squared:                  0.808\n",
       "Method:                 Least Squares   F-statistic:                     11.54\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           7.06e-07\n",
       "Time:                        09:49:53   Log-Likelihood:                -83.392\n",
       "No. Observations:                  36   AIC:                             196.8\n",
       "Df Residuals:                      21   BIC:                             220.5\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept        182.3790     11.478     15.889      0.000       158.509   206.249\n",
       "sleep_duration  2.796e-07   3.74e-07      0.747      0.464     -4.99e-07  1.06e-06\n",
       "user_2456         -4.3367      2.584     -1.679      0.108        -9.710     1.036\n",
       "user_2458          6.4651      2.400      2.694      0.014         1.474    11.456\n",
       "user_2465         -3.5744      2.547     -1.403      0.175        -8.872     1.723\n",
       "user_2466          5.2144      2.851      1.829      0.082        -0.715    11.144\n",
       "user_2468         -3.7690      2.141     -1.760      0.093        -8.222     0.684\n",
       "user_2469          1.8824      2.434      0.773      0.448        -3.180     6.945\n",
       "user_2473         -7.2509      3.072     -2.360      0.028       -13.640    -0.862\n",
       "user_2508         11.2753      4.263      2.645      0.015         2.409    20.141\n",
       "FP_5K            -12.9209      5.881     -2.197      0.039       -25.150    -0.691\n",
       "Wisco_8K           0.9010      1.978      0.456      0.653        -3.212     5.014\n",
       "Brown_8K          -0.8099      2.794     -0.290      0.775        -6.620     5.000\n",
       "VCP_8K            10.6289      1.532      6.937      0.000         7.442    13.815\n",
       "FP_10K             4.3527      1.947      2.235      0.036         0.303     8.402\n",
       "==============================================================================\n",
       "Omnibus:                        0.664   Durbin-Watson:                   2.550\n",
       "Prob(Omnibus):                  0.718   Jarque-Bera (JB):                0.175\n",
       "Skew:                           0.152   Prob(JB):                        0.916\n",
       "Kurtosis:                       3.156   Cond. No.                     6.73e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.73e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>4.44e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:49:56</td>     <th>  Log-Likelihood:    </th> <td> -82.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   195.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   218.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>  192.8308</td> <td>    2.381</td> <td>   80.980</td> <td> 0.000</td> <td>  187.879   197.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rem_sleep_duration</th> <td>-3.642e-07</td> <td> 2.88e-07</td> <td>   -1.266</td> <td> 0.220</td> <td>-9.63e-07  2.34e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>          <td>   -5.2205</td> <td>    2.082</td> <td>   -2.507</td> <td> 0.020</td> <td>   -9.551    -0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>          <td>    8.6290</td> <td>    2.939</td> <td>    2.936</td> <td> 0.008</td> <td>    2.517    14.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>          <td>   -4.2893</td> <td>    2.092</td> <td>   -2.050</td> <td> 0.053</td> <td>   -8.640     0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>          <td>    5.2073</td> <td>    2.357</td> <td>    2.210</td> <td> 0.038</td> <td>    0.307    10.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>          <td>   -3.6112</td> <td>    2.094</td> <td>   -1.724</td> <td> 0.099</td> <td>   -7.966     0.744</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>          <td>    1.6031</td> <td>    2.387</td> <td>    0.672</td> <td> 0.509</td> <td>   -3.361     6.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>          <td>   -6.8419</td> <td>    2.796</td> <td>   -2.447</td> <td> 0.023</td> <td>  -12.657    -1.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>          <td>    9.6871</td> <td>    3.530</td> <td>    2.744</td> <td> 0.012</td> <td>    2.346    17.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>              <td>  -11.9674</td> <td>    4.826</td> <td>   -2.480</td> <td> 0.022</td> <td>  -22.003    -1.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>           <td>    0.5378</td> <td>    1.954</td> <td>    0.275</td> <td> 0.786</td> <td>   -3.526     4.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>           <td>   -0.8665</td> <td>    2.728</td> <td>   -0.318</td> <td> 0.754</td> <td>   -6.539     4.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>             <td>    8.8043</td> <td>    1.794</td> <td>    4.909</td> <td> 0.000</td> <td>    5.074    12.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>             <td>    3.3332</td> <td>    2.137</td> <td>    1.560</td> <td> 0.134</td> <td>   -1.111     7.777</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.563</td> <th>  Durbin-Watson:     </th> <td>   2.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.458</td> <th>  Jarque-Bera (JB):  </th> <td>   0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.351</td> <th>  Prob(JB):          </th> <td>   0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.230</td> <th>  Cond. No.          </th> <td>6.46e+07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.890\n",
       "Model:                            OLS   Adj. R-squared:                  0.817\n",
       "Method:                 Least Squares   F-statistic:                     12.17\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           4.44e-07\n",
       "Time:                        09:49:56   Log-Likelihood:                -82.541\n",
       "No. Observations:                  36   AIC:                             195.1\n",
       "Df Residuals:                      21   BIC:                             218.8\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept            192.8308      2.381     80.980      0.000       187.879   197.783\n",
       "rem_sleep_duration -3.642e-07   2.88e-07     -1.266      0.220     -9.63e-07  2.34e-07\n",
       "user_2456             -5.2205      2.082     -2.507      0.020        -9.551    -0.890\n",
       "user_2458              8.6290      2.939      2.936      0.008         2.517    14.741\n",
       "user_2465             -4.2893      2.092     -2.050      0.053        -8.640     0.062\n",
       "user_2466              5.2073      2.357      2.210      0.038         0.307    10.108\n",
       "user_2468             -3.6112      2.094     -1.724      0.099        -7.966     0.744\n",
       "user_2469              1.6031      2.387      0.672      0.509        -3.361     6.567\n",
       "user_2473             -6.8419      2.796     -2.447      0.023       -12.657    -1.027\n",
       "user_2508              9.6871      3.530      2.744      0.012         2.346    17.028\n",
       "FP_5K                -11.9674      4.826     -2.480      0.022       -22.003    -1.932\n",
       "Wisco_8K               0.5378      1.954      0.275      0.786        -3.526     4.601\n",
       "Brown_8K              -0.8665      2.728     -0.318      0.754        -6.539     4.806\n",
       "VCP_8K                 8.8043      1.794      4.909      0.000         5.074    12.534\n",
       "FP_10K                 3.3332      2.137      1.560      0.134        -1.111     7.777\n",
       "==============================================================================\n",
       "Omnibus:                        1.563   Durbin-Watson:                   2.769\n",
       "Prob(Omnibus):                  0.458   Jarque-Bera (JB):                0.817\n",
       "Skew:                           0.351   Prob(JB):                        0.665\n",
       "Kurtosis:                       3.230   Cond. No.                     6.46e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.46e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>4.88e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:50:00</td>     <th>  Log-Likelihood:    </th> <td> -82.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   195.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   219.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>  193.8662</td> <td>    3.138</td> <td>   61.773</td> <td> 0.000</td> <td>  187.340   200.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slow_wave_sleep_duration</th> <td>-5.937e-07</td> <td> 5.05e-07</td> <td>   -1.176</td> <td> 0.253</td> <td>-1.64e-06  4.56e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>                <td>   -6.6799</td> <td>    2.339</td> <td>   -2.855</td> <td> 0.009</td> <td>  -11.545    -1.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>                <td>    6.2931</td> <td>    2.354</td> <td>    2.673</td> <td> 0.014</td> <td>    1.398    11.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>                <td>   -4.4311</td> <td>    2.092</td> <td>   -2.118</td> <td> 0.046</td> <td>   -8.782    -0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>                <td>    1.5712</td> <td>    2.815</td> <td>    0.558</td> <td> 0.583</td> <td>   -4.284     7.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>                <td>   -4.0500</td> <td>    2.087</td> <td>   -1.941</td> <td> 0.066</td> <td>   -8.390     0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>                <td>    0.4423</td> <td>    2.681</td> <td>    0.165</td> <td> 0.871</td> <td>   -5.133     6.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>                <td>   -9.6521</td> <td>    2.597</td> <td>   -3.717</td> <td> 0.001</td> <td>  -15.053    -4.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>                <td>    8.0831</td> <td>    3.769</td> <td>    2.144</td> <td> 0.044</td> <td>    0.244    15.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>                    <td>  -10.2881</td> <td>    4.675</td> <td>   -2.201</td> <td> 0.039</td> <td>  -20.011    -0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>                 <td>    2.0442</td> <td>    1.968</td> <td>    1.039</td> <td> 0.311</td> <td>   -2.049     6.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>                 <td>   -1.3731</td> <td>    2.775</td> <td>   -0.495</td> <td> 0.626</td> <td>   -7.144     4.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>                   <td>   11.3770</td> <td>    1.714</td> <td>    6.636</td> <td> 0.000</td> <td>    7.812    14.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>                   <td>    6.1990</td> <td>    2.264</td> <td>    2.738</td> <td> 0.012</td> <td>    1.491    10.907</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.016</td> <th>  Durbin-Watson:     </th> <td>   2.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.992</td> <th>  Jarque-Bera (JB):  </th> <td>   0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.019</td> <th>  Prob(JB):          </th> <td>   0.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.770</td> <th>  Cond. No.          </th> <td>6.43e+07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.889\n",
       "Model:                            OLS   Adj. R-squared:                  0.815\n",
       "Method:                 Least Squares   F-statistic:                     12.04\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           4.88e-07\n",
       "Time:                        09:50:00   Log-Likelihood:                -82.716\n",
       "No. Observations:                  36   AIC:                             195.4\n",
       "Df Residuals:                      21   BIC:                             219.2\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                  193.8662      3.138     61.773      0.000       187.340   200.393\n",
       "slow_wave_sleep_duration -5.937e-07   5.05e-07     -1.176      0.253     -1.64e-06  4.56e-07\n",
       "user_2456                   -6.6799      2.339     -2.855      0.009       -11.545    -1.815\n",
       "user_2458                    6.2931      2.354      2.673      0.014         1.398    11.188\n",
       "user_2465                   -4.4311      2.092     -2.118      0.046        -8.782    -0.080\n",
       "user_2466                    1.5712      2.815      0.558      0.583        -4.284     7.426\n",
       "user_2468                   -4.0500      2.087     -1.941      0.066        -8.390     0.290\n",
       "user_2469                    0.4423      2.681      0.165      0.871        -5.133     6.018\n",
       "user_2473                   -9.6521      2.597     -3.717      0.001       -15.053    -4.252\n",
       "user_2508                    8.0831      3.769      2.144      0.044         0.244    15.922\n",
       "FP_5K                      -10.2881      4.675     -2.201      0.039       -20.011    -0.565\n",
       "Wisco_8K                     2.0442      1.968      1.039      0.311        -2.049     6.138\n",
       "Brown_8K                    -1.3731      2.775     -0.495      0.626        -7.144     4.398\n",
       "VCP_8K                      11.3770      1.714      6.636      0.000         7.812    14.942\n",
       "FP_10K                       6.1990      2.264      2.738      0.012         1.491    10.907\n",
       "==============================================================================\n",
       "Omnibus:                        0.016   Durbin-Watson:                   2.864\n",
       "Prob(Omnibus):                  0.992   Jarque-Bera (JB):                0.082\n",
       "Skew:                           0.019   Prob(JB):                        0.960\n",
       "Kurtosis:                       2.770   Cond. No.                     6.43e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.43e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>3.47e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:50:03</td>     <th>  Log-Likelihood:    </th> <td> -77.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   185.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   209.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>  176.6698</td> <td>    5.185</td> <td>   34.071</td> <td> 0.000</td> <td>  165.886   187.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>light_sleep_duration</th> <td> 7.195e-07</td> <td> 2.51e-07</td> <td>    2.868</td> <td> 0.009</td> <td> 1.98e-07  1.24e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>            <td>   -3.6994</td> <td>    1.923</td> <td>   -1.924</td> <td> 0.068</td> <td>   -7.698     0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>            <td>   10.9338</td> <td>    2.600</td> <td>    4.205</td> <td> 0.000</td> <td>    5.527    16.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>            <td>   -1.0338</td> <td>    2.213</td> <td>   -0.467</td> <td> 0.645</td> <td>   -5.636     3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>            <td>    7.5420</td> <td>    2.245</td> <td>    3.360</td> <td> 0.003</td> <td>    2.874    12.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>            <td>   -2.8725</td> <td>    1.865</td> <td>   -1.541</td> <td> 0.138</td> <td>   -6.750     1.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>            <td>   -0.3695</td> <td>    2.232</td> <td>   -0.166</td> <td> 0.870</td> <td>   -5.012     4.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>            <td>   -2.9268</td> <td>    2.910</td> <td>   -1.006</td> <td> 0.326</td> <td>   -8.978     3.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>            <td>   12.3119</td> <td>    3.246</td> <td>    3.793</td> <td> 0.001</td> <td>    5.562    19.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>                <td>  -20.1042</td> <td>    5.321</td> <td>   -3.778</td> <td> 0.001</td> <td>  -31.171    -9.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>             <td>   -0.3657</td> <td>    1.734</td> <td>   -0.211</td> <td> 0.835</td> <td>   -3.972     3.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>             <td>   -1.3568</td> <td>    2.405</td> <td>   -0.564</td> <td> 0.579</td> <td>   -6.358     3.645</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>               <td>    9.8580</td> <td>    1.237</td> <td>    7.967</td> <td> 0.000</td> <td>    7.285    12.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>               <td>    3.0047</td> <td>    1.731</td> <td>    1.736</td> <td> 0.097</td> <td>   -0.594     6.604</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.720</td> <th>  Durbin-Watson:     </th> <td>   2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.423</td> <th>  Jarque-Bera (JB):  </th> <td>   1.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.099</td> <th>  Prob(JB):          </th> <td>   0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.155</td> <th>  Cond. No.          </th> <td>3.12e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.915\n",
       "Model:                            OLS   Adj. R-squared:                  0.859\n",
       "Method:                 Least Squares   F-statistic:                     16.18\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.47e-08\n",
       "Time:                        09:50:03   Log-Likelihood:                -77.916\n",
       "No. Observations:                  36   AIC:                             185.8\n",
       "Df Residuals:                      21   BIC:                             209.6\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept              176.6698      5.185     34.071      0.000       165.886   187.453\n",
       "light_sleep_duration  7.195e-07   2.51e-07      2.868      0.009      1.98e-07  1.24e-06\n",
       "user_2456               -3.6994      1.923     -1.924      0.068        -7.698     0.300\n",
       "user_2458               10.9338      2.600      4.205      0.000         5.527    16.341\n",
       "user_2465               -1.0338      2.213     -0.467      0.645        -5.636     3.569\n",
       "user_2466                7.5420      2.245      3.360      0.003         2.874    12.210\n",
       "user_2468               -2.8725      1.865     -1.541      0.138        -6.750     1.005\n",
       "user_2469               -0.3695      2.232     -0.166      0.870        -5.012     4.273\n",
       "user_2473               -2.9268      2.910     -1.006      0.326        -8.978     3.124\n",
       "user_2508               12.3119      3.246      3.793      0.001         5.562    19.062\n",
       "FP_5K                  -20.1042      5.321     -3.778      0.001       -31.171    -9.038\n",
       "Wisco_8K                -0.3657      1.734     -0.211      0.835        -3.972     3.241\n",
       "Brown_8K                -1.3568      2.405     -0.564      0.579        -6.358     3.645\n",
       "VCP_8K                   9.8580      1.237      7.967      0.000         7.285    12.431\n",
       "FP_10K                   3.0047      1.731      1.736      0.097        -0.594     6.604\n",
       "==============================================================================\n",
       "Omnibus:                        1.720   Durbin-Watson:                   2.942\n",
       "Prob(Omnibus):                  0.423   Jarque-Bera (JB):                1.129\n",
       "Skew:                          -0.099   Prob(JB):                        0.569\n",
       "Kurtosis:                       2.155   Cond. No.                     3.12e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.12e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>8.96e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:08</td>     <th>  Log-Likelihood:    </th> <td> -83.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>  188.6651</td> <td>   11.195</td> <td>   16.853</td> <td> 0.000</td> <td>  165.384   211.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_in_bed</th> <td> 6.136e-08</td> <td> 3.11e-07</td> <td>    0.197</td> <td> 0.846</td> <td>-5.86e-07  7.09e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>   <td>   -5.0886</td> <td>    2.775</td> <td>   -1.834</td> <td> 0.081</td> <td>  -10.859     0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>   <td>    6.4817</td> <td>    2.480</td> <td>    2.613</td> <td> 0.016</td> <td>    1.324    11.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>   <td>   -4.2386</td> <td>    2.904</td> <td>   -1.460</td> <td> 0.159</td> <td>  -10.277     1.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>   <td>    4.0431</td> <td>    2.492</td> <td>    1.622</td> <td> 0.120</td> <td>   -1.140     9.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>   <td>   -3.8268</td> <td>    2.260</td> <td>   -1.693</td> <td> 0.105</td> <td>   -8.527     0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>   <td>    2.0522</td> <td>    2.627</td> <td>    0.781</td> <td> 0.443</td> <td>   -3.410     7.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>   <td>   -8.2050</td> <td>    3.218</td> <td>   -2.549</td> <td> 0.019</td> <td>  -14.898    -1.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>   <td>   10.0989</td> <td>    4.490</td> <td>    2.249</td> <td> 0.035</td> <td>    0.761    19.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>       <td>  -10.8653</td> <td>    5.495</td> <td>   -1.977</td> <td> 0.061</td> <td>  -22.294     0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>    <td>    1.1635</td> <td>    2.059</td> <td>    0.565</td> <td> 0.578</td> <td>   -3.118     5.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>    <td>   -0.8632</td> <td>    2.827</td> <td>   -0.305</td> <td> 0.763</td> <td>   -6.742     5.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>      <td>   10.2109</td> <td>    1.452</td> <td>    7.032</td> <td> 0.000</td> <td>    7.191    13.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>      <td>    4.4640</td> <td>    2.217</td> <td>    2.013</td> <td> 0.057</td> <td>   -0.147     9.075</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.153</td> <th>  Durbin-Watson:     </th> <td>   2.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.562</td> <th>  Jarque-Bera (JB):  </th> <td>   0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.217</td> <th>  Prob(JB):          </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.309</td> <th>  Cond. No.          </th> <td>7.75e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.804\n",
       "Method:                 Least Squares   F-statistic:                     11.23\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           8.96e-07\n",
       "Time:                        09:51:08   Log-Likelihood:                -83.831\n",
       "No. Observations:                  36   AIC:                             197.7\n",
       "Df Residuals:                      21   BIC:                             221.4\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept     188.6651     11.195     16.853      0.000       165.384   211.947\n",
       "time_in_bed  6.136e-08   3.11e-07      0.197      0.846     -5.86e-07  7.09e-07\n",
       "user_2456      -5.0886      2.775     -1.834      0.081       -10.859     0.682\n",
       "user_2458       6.4817      2.480      2.613      0.016         1.324    11.640\n",
       "user_2465      -4.2386      2.904     -1.460      0.159       -10.277     1.800\n",
       "user_2466       4.0431      2.492      1.622      0.120        -1.140     9.226\n",
       "user_2468      -3.8268      2.260     -1.693      0.105        -8.527     0.874\n",
       "user_2469       2.0522      2.627      0.781      0.443        -3.410     7.515\n",
       "user_2473      -8.2050      3.218     -2.549      0.019       -14.898    -1.512\n",
       "user_2508      10.0989      4.490      2.249      0.035         0.761    19.437\n",
       "FP_5K         -10.8653      5.495     -1.977      0.061       -22.294     0.563\n",
       "Wisco_8K        1.1635      2.059      0.565      0.578        -3.118     5.445\n",
       "Brown_8K       -0.8632      2.827     -0.305      0.763        -6.742     5.016\n",
       "VCP_8K         10.2109      1.452      7.032      0.000         7.191    13.231\n",
       "FP_10K          4.4640      2.217      2.013      0.057        -0.147     9.075\n",
       "==============================================================================\n",
       "Omnibus:                        1.153   Durbin-Watson:                   2.644\n",
       "Prob(Omnibus):                  0.562   Jarque-Bera (JB):                0.426\n",
       "Skew:                           0.217   Prob(JB):                        0.808\n",
       "Kurtosis:                       3.309   Cond. No.                     7.75e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.75e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.45</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>3.65e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:09</td>     <th>  Log-Likelihood:    </th> <td> -82.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   194.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   218.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>  194.9773</td> <td>    3.386</td> <td>   57.589</td> <td> 0.000</td> <td>  187.936   202.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cycles_count</th> <td>   -0.6817</td> <td>    0.476</td> <td>   -1.433</td> <td> 0.166</td> <td>   -1.671     0.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>    <td>   -5.8538</td> <td>    2.076</td> <td>   -2.820</td> <td> 0.010</td> <td>  -10.171    -1.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>    <td>    7.2591</td> <td>    2.398</td> <td>    3.027</td> <td> 0.006</td> <td>    2.272    12.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>    <td>   -4.5983</td> <td>    2.055</td> <td>   -2.237</td> <td> 0.036</td> <td>   -8.872    -0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>    <td>    4.8987</td> <td>    2.195</td> <td>    2.232</td> <td> 0.037</td> <td>    0.335     9.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>    <td>   -4.1702</td> <td>    2.060</td> <td>   -2.024</td> <td> 0.056</td> <td>   -8.454     0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>    <td>    1.0924</td> <td>    2.416</td> <td>    0.452</td> <td> 0.656</td> <td>   -3.932     6.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>    <td>   -7.2059</td> <td>    2.592</td> <td>   -2.780</td> <td> 0.011</td> <td>  -12.596    -1.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>    <td>    7.6459</td> <td>    3.747</td> <td>    2.040</td> <td> 0.054</td> <td>   -0.147    15.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>        <td>  -11.1570</td> <td>    4.641</td> <td>   -2.404</td> <td> 0.026</td> <td>  -20.809    -1.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>     <td>    1.2252</td> <td>    1.839</td> <td>    0.666</td> <td> 0.513</td> <td>   -2.600     5.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>     <td>   -0.5918</td> <td>    2.707</td> <td>   -0.219</td> <td> 0.829</td> <td>   -6.222     5.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>       <td>    9.4660</td> <td>    1.483</td> <td>    6.382</td> <td> 0.000</td> <td>    6.382    12.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>       <td>    4.1396</td> <td>    1.872</td> <td>    2.211</td> <td> 0.038</td> <td>    0.246     8.034</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.557</td> <th>  Durbin-Watson:     </th> <td>   2.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.757</td> <th>  Jarque-Bera (JB):  </th> <td>   0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.174</td> <th>  Prob(JB):          </th> <td>   0.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.060</td> <th>  Cond. No.          </th> <td>    62.8</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.892\n",
       "Model:                            OLS   Adj. R-squared:                  0.821\n",
       "Method:                 Least Squares   F-statistic:                     12.45\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.65e-07\n",
       "Time:                        09:51:09   Log-Likelihood:                -82.184\n",
       "No. Observations:                  36   AIC:                             194.4\n",
       "Df Residuals:                      21   BIC:                             218.1\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept      194.9773      3.386     57.589      0.000       187.936   202.018\n",
       "cycles_count    -0.6817      0.476     -1.433      0.166        -1.671     0.307\n",
       "user_2456       -5.8538      2.076     -2.820      0.010       -10.171    -1.537\n",
       "user_2458        7.2591      2.398      3.027      0.006         2.272    12.246\n",
       "user_2465       -4.5983      2.055     -2.237      0.036        -8.872    -0.324\n",
       "user_2466        4.8987      2.195      2.232      0.037         0.335     9.463\n",
       "user_2468       -4.1702      2.060     -2.024      0.056        -8.454     0.114\n",
       "user_2469        1.0924      2.416      0.452      0.656        -3.932     6.117\n",
       "user_2473       -7.2059      2.592     -2.780      0.011       -12.596    -1.816\n",
       "user_2508        7.6459      3.747      2.040      0.054        -0.147    15.438\n",
       "FP_5K          -11.1570      4.641     -2.404      0.026       -20.809    -1.506\n",
       "Wisco_8K         1.2252      1.839      0.666      0.513        -2.600     5.051\n",
       "Brown_8K        -0.5918      2.707     -0.219      0.829        -6.222     5.038\n",
       "VCP_8K           9.4660      1.483      6.382      0.000         6.382    12.550\n",
       "FP_10K           4.1396      1.872      2.211      0.038         0.246     8.034\n",
       "==============================================================================\n",
       "Omnibus:                        0.557   Durbin-Watson:                   2.659\n",
       "Prob(Omnibus):                  0.757   Jarque-Bera (JB):                0.188\n",
       "Skew:                           0.174   Prob(JB):                        0.910\n",
       "Kurtosis:                       3.060   Cond. No.                         62.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>8.96e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:12</td>     <th>  Log-Likelihood:    </th> <td> -83.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>  188.6651</td> <td>   11.195</td> <td>   16.853</td> <td> 0.000</td> <td>  165.384   211.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_in_bed</th> <td> 6.136e-08</td> <td> 3.11e-07</td> <td>    0.197</td> <td> 0.846</td> <td>-5.86e-07  7.09e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>   <td>   -5.0886</td> <td>    2.775</td> <td>   -1.834</td> <td> 0.081</td> <td>  -10.859     0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>   <td>    6.4817</td> <td>    2.480</td> <td>    2.613</td> <td> 0.016</td> <td>    1.324    11.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>   <td>   -4.2386</td> <td>    2.904</td> <td>   -1.460</td> <td> 0.159</td> <td>  -10.277     1.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>   <td>    4.0431</td> <td>    2.492</td> <td>    1.622</td> <td> 0.120</td> <td>   -1.140     9.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>   <td>   -3.8268</td> <td>    2.260</td> <td>   -1.693</td> <td> 0.105</td> <td>   -8.527     0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>   <td>    2.0522</td> <td>    2.627</td> <td>    0.781</td> <td> 0.443</td> <td>   -3.410     7.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>   <td>   -8.2050</td> <td>    3.218</td> <td>   -2.549</td> <td> 0.019</td> <td>  -14.898    -1.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>   <td>   10.0989</td> <td>    4.490</td> <td>    2.249</td> <td> 0.035</td> <td>    0.761    19.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>       <td>  -10.8653</td> <td>    5.495</td> <td>   -1.977</td> <td> 0.061</td> <td>  -22.294     0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>    <td>    1.1635</td> <td>    2.059</td> <td>    0.565</td> <td> 0.578</td> <td>   -3.118     5.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>    <td>   -0.8632</td> <td>    2.827</td> <td>   -0.305</td> <td> 0.763</td> <td>   -6.742     5.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>      <td>   10.2109</td> <td>    1.452</td> <td>    7.032</td> <td> 0.000</td> <td>    7.191    13.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>      <td>    4.4640</td> <td>    2.217</td> <td>    2.013</td> <td> 0.057</td> <td>   -0.147     9.075</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.153</td> <th>  Durbin-Watson:     </th> <td>   2.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.562</td> <th>  Jarque-Bera (JB):  </th> <td>   0.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.217</td> <th>  Prob(JB):          </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.309</td> <th>  Cond. No.          </th> <td>7.75e+08</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.804\n",
       "Method:                 Least Squares   F-statistic:                     11.23\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           8.96e-07\n",
       "Time:                        09:51:12   Log-Likelihood:                -83.831\n",
       "No. Observations:                  36   AIC:                             197.7\n",
       "Df Residuals:                      21   BIC:                             221.4\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept     188.6651     11.195     16.853      0.000       165.384   211.947\n",
       "time_in_bed  6.136e-08   3.11e-07      0.197      0.846     -5.86e-07  7.09e-07\n",
       "user_2456      -5.0886      2.775     -1.834      0.081       -10.859     0.682\n",
       "user_2458       6.4817      2.480      2.613      0.016         1.324    11.640\n",
       "user_2465      -4.2386      2.904     -1.460      0.159       -10.277     1.800\n",
       "user_2466       4.0431      2.492      1.622      0.120        -1.140     9.226\n",
       "user_2468      -3.8268      2.260     -1.693      0.105        -8.527     0.874\n",
       "user_2469       2.0522      2.627      0.781      0.443        -3.410     7.515\n",
       "user_2473      -8.2050      3.218     -2.549      0.019       -14.898    -1.512\n",
       "user_2508      10.0989      4.490      2.249      0.035         0.761    19.437\n",
       "FP_5K         -10.8653      5.495     -1.977      0.061       -22.294     0.563\n",
       "Wisco_8K        1.1635      2.059      0.565      0.578        -3.118     5.445\n",
       "Brown_8K       -0.8632      2.827     -0.305      0.763        -6.742     5.016\n",
       "VCP_8K         10.2109      1.452      7.032      0.000         7.191    13.231\n",
       "FP_10K          4.4640      2.217      2.013      0.057        -0.147     9.075\n",
       "==============================================================================\n",
       "Omnibus:                        1.153   Durbin-Watson:                   2.644\n",
       "Prob(Omnibus):                  0.562   Jarque-Bera (JB):                0.426\n",
       "Skew:                           0.217   Prob(JB):                        0.808\n",
       "Kurtosis:                       3.309   Cond. No.                     7.75e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.75e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.26</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>8.72e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:14</td>     <th>  Log-Likelihood:    </th> <td> -83.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  190.3294</td> <td>    2.469</td> <td>   77.088</td> <td> 0.000</td> <td>  185.195   195.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latency</th>   <td> 4.655e-07</td> <td> 1.49e-06</td> <td>    0.312</td> <td> 0.758</td> <td>-2.63e-06  3.56e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -5.3446</td> <td>    2.167</td> <td>   -2.466</td> <td> 0.022</td> <td>   -9.852    -0.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    6.3248</td> <td>    2.430</td> <td>    2.603</td> <td> 0.017</td> <td>    1.271    11.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -4.5428</td> <td>    2.164</td> <td>   -2.100</td> <td> 0.048</td> <td>   -9.042    -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    3.7198</td> <td>    2.162</td> <td>    1.721</td> <td> 0.100</td> <td>   -0.776     8.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -4.2075</td> <td>    2.286</td> <td>   -1.841</td> <td> 0.080</td> <td>   -8.961     0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    2.0095</td> <td>    2.499</td> <td>    0.804</td> <td> 0.430</td> <td>   -3.188     7.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -8.6108</td> <td>    2.511</td> <td>   -3.429</td> <td> 0.003</td> <td>  -13.834    -3.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.8087</td> <td>    3.722</td> <td>    2.636</td> <td> 0.015</td> <td>    2.069    17.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>  -10.5140</td> <td>    4.845</td> <td>   -2.170</td> <td> 0.042</td> <td>  -20.590    -0.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    1.3155</td> <td>    1.922</td> <td>    0.684</td> <td> 0.501</td> <td>   -2.682     5.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -0.9419</td> <td>    2.835</td> <td>   -0.332</td> <td> 0.743</td> <td>   -6.837     4.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>   10.0985</td> <td>    1.503</td> <td>    6.718</td> <td> 0.000</td> <td>    6.973    13.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    4.6289</td> <td>    1.925</td> <td>    2.405</td> <td> 0.025</td> <td>    0.627     8.631</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.840</td> <th>  Durbin-Watson:     </th> <td>   2.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.398</td> <th>  Jarque-Bera (JB):  </th> <td>   0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.295</td> <th>  Prob(JB):          </th> <td>   0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.479</td> <th>  Cond. No.          </th> <td>1.41e+07</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.804\n",
       "Method:                 Least Squares   F-statistic:                     11.26\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           8.72e-07\n",
       "Time:                        09:51:14   Log-Likelihood:                -83.781\n",
       "No. Observations:                  36   AIC:                             197.6\n",
       "Df Residuals:                      21   BIC:                             221.3\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    190.3294      2.469     77.088      0.000       185.195   195.464\n",
       "latency     4.655e-07   1.49e-06      0.312      0.758     -2.63e-06  3.56e-06\n",
       "user_2456     -5.3446      2.167     -2.466      0.022        -9.852    -0.838\n",
       "user_2458      6.3248      2.430      2.603      0.017         1.271    11.378\n",
       "user_2465     -4.5428      2.164     -2.100      0.048        -9.042    -0.043\n",
       "user_2466      3.7198      2.162      1.721      0.100        -0.776     8.215\n",
       "user_2468     -4.2075      2.286     -1.841      0.080        -8.961     0.546\n",
       "user_2469      2.0095      2.499      0.804      0.430        -3.188     7.207\n",
       "user_2473     -8.6108      2.511     -3.429      0.003       -13.834    -3.388\n",
       "user_2508      9.8087      3.722      2.636      0.015         2.069    17.548\n",
       "FP_5K        -10.5140      4.845     -2.170      0.042       -20.590    -0.438\n",
       "Wisco_8K       1.3155      1.922      0.684      0.501        -2.682     5.313\n",
       "Brown_8K      -0.9419      2.835     -0.332      0.743        -6.837     4.953\n",
       "VCP_8K        10.0985      1.503      6.718      0.000         6.973    13.225\n",
       "FP_10K         4.6289      1.925      2.405      0.025         0.627     8.631\n",
       "==============================================================================\n",
       "Omnibus:                        1.840   Durbin-Watson:                   2.678\n",
       "Prob(Omnibus):                  0.398   Jarque-Bera (JB):                0.867\n",
       "Skew:                           0.295   Prob(JB):                        0.648\n",
       "Kurtosis:                       3.479   Cond. No.                     1.41e+07\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.41e+07. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>3.91e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:15</td>     <th>  Log-Likelihood:    </th> <td> -82.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   194.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   218.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  175.6728</td> <td>   11.165</td> <td>   15.735</td> <td> 0.000</td> <td>  152.455   198.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>score</th>     <td>    0.1771</td> <td>    0.129</td> <td>    1.376</td> <td> 0.183</td> <td>   -0.091     0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -2.2172</td> <td>    3.117</td> <td>   -0.711</td> <td> 0.485</td> <td>   -8.700     4.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    5.4233</td> <td>    2.428</td> <td>    2.233</td> <td> 0.037</td> <td>    0.373    10.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -2.0764</td> <td>    2.771</td> <td>   -0.749</td> <td> 0.462</td> <td>   -7.839     3.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    7.8926</td> <td>    3.622</td> <td>    2.179</td> <td> 0.041</td> <td>    0.360    15.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -3.3596</td> <td>    2.108</td> <td>   -1.593</td> <td> 0.126</td> <td>   -7.744     1.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    1.4870</td> <td>    2.379</td> <td>    0.625</td> <td> 0.539</td> <td>   -3.460     6.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -6.7062</td> <td>    2.776</td> <td>   -2.416</td> <td> 0.025</td> <td>  -12.480    -0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>   13.7806</td> <td>    4.646</td> <td>    2.966</td> <td> 0.007</td> <td>    4.118    23.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>  -17.0809</td> <td>    6.732</td> <td>   -2.537</td> <td> 0.019</td> <td>  -31.081    -3.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>   -0.2215</td> <td>    2.154</td> <td>   -0.103</td> <td> 0.919</td> <td>   -4.700     4.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -1.4536</td> <td>    2.744</td> <td>   -0.530</td> <td> 0.602</td> <td>   -7.160     4.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>    9.7310</td> <td>    1.436</td> <td>    6.776</td> <td> 0.000</td> <td>    6.745    12.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    2.5605</td> <td>    2.401</td> <td>    1.066</td> <td> 0.298</td> <td>   -2.433     7.554</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.321</td> <th>  Durbin-Watson:     </th> <td>   2.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.852</td> <th>  Jarque-Bera (JB):  </th> <td>   0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.121</td> <th>  Prob(JB):          </th> <td>   0.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.982</td> <th>  Cond. No.          </th> <td>2.18e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.892\n",
       "Model:                            OLS   Adj. R-squared:                  0.820\n",
       "Method:                 Least Squares   F-statistic:                     12.35\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.91e-07\n",
       "Time:                        09:51:15   Log-Likelihood:                -82.310\n",
       "No. Observations:                  36   AIC:                             194.6\n",
       "Df Residuals:                      21   BIC:                             218.4\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    175.6728     11.165     15.735      0.000       152.455   198.891\n",
       "score          0.1771      0.129      1.376      0.183        -0.091     0.445\n",
       "user_2456     -2.2172      3.117     -0.711      0.485        -8.700     4.265\n",
       "user_2458      5.4233      2.428      2.233      0.037         0.373    10.473\n",
       "user_2465     -2.0764      2.771     -0.749      0.462        -7.839     3.686\n",
       "user_2466      7.8926      3.622      2.179      0.041         0.360    15.425\n",
       "user_2468     -3.3596      2.108     -1.593      0.126        -7.744     1.025\n",
       "user_2469      1.4870      2.379      0.625      0.539        -3.460     6.434\n",
       "user_2473     -6.7062      2.776     -2.416      0.025       -12.480    -0.933\n",
       "user_2508     13.7806      4.646      2.966      0.007         4.118    23.443\n",
       "FP_5K        -17.0809      6.732     -2.537      0.019       -31.081    -3.080\n",
       "Wisco_8K      -0.2215      2.154     -0.103      0.919        -4.700     4.257\n",
       "Brown_8K      -1.4536      2.744     -0.530      0.602        -7.160     4.253\n",
       "VCP_8K         9.7310      1.436      6.776      0.000         6.745    12.717\n",
       "FP_10K         2.5605      2.401      1.066      0.298        -2.433     7.554\n",
       "==============================================================================\n",
       "Omnibus:                        0.321   Durbin-Watson:                   2.419\n",
       "Prob(Omnibus):                  0.852   Jarque-Bera (JB):                0.089\n",
       "Skew:                           0.121   Prob(JB):                        0.957\n",
       "Kurtosis:                       2.982   Cond. No.                     2.18e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.18e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>9.07e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:16</td>     <th>  Log-Likelihood:    </th> <td> -83.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>  190.2984</td> <td>    5.139</td> <td>   37.032</td> <td> 0.000</td> <td>  179.612   200.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recovery_score</th> <td>    0.0094</td> <td>    0.083</td> <td>    0.113</td> <td> 0.911</td> <td>   -0.163     0.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th>      <td>   -5.3745</td> <td>    2.216</td> <td>   -2.426</td> <td> 0.024</td> <td>   -9.982    -0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th>      <td>    6.2372</td> <td>    2.740</td> <td>    2.276</td> <td> 0.033</td> <td>    0.539    11.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th>      <td>   -4.6435</td> <td>    2.160</td> <td>   -2.149</td> <td> 0.043</td> <td>   -9.136    -0.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th>      <td>    3.8478</td> <td>    2.202</td> <td>    1.747</td> <td> 0.095</td> <td>   -0.732     8.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th>      <td>   -3.9831</td> <td>    2.160</td> <td>   -1.844</td> <td> 0.079</td> <td>   -8.475     0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th>      <td>    1.8210</td> <td>    2.508</td> <td>    0.726</td> <td> 0.476</td> <td>   -3.395     7.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th>      <td>   -8.6932</td> <td>    2.646</td> <td>   -3.285</td> <td> 0.004</td> <td>  -14.196    -3.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th>      <td>    9.7313</td> <td>    3.880</td> <td>    2.508</td> <td> 0.020</td> <td>    1.663    17.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>          <td>  -10.7026</td> <td>    5.764</td> <td>   -1.857</td> <td> 0.077</td> <td>  -22.690     1.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>       <td>    1.1997</td> <td>    2.148</td> <td>    0.558</td> <td> 0.582</td> <td>   -3.268     5.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>       <td>   -0.9142</td> <td>    2.867</td> <td>   -0.319</td> <td> 0.753</td> <td>   -6.875     5.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>         <td>   10.1844</td> <td>    1.493</td> <td>    6.821</td> <td> 0.000</td> <td>    7.079    13.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>         <td>    4.5747</td> <td>    2.145</td> <td>    2.133</td> <td> 0.045</td> <td>    0.114     9.036</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.324</td> <th>  Durbin-Watson:     </th> <td>   2.694</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.516</td> <th>  Jarque-Bera (JB):  </th> <td>   0.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.253</td> <th>  Prob(JB):          </th> <td>   0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.328</td> <th>  Cond. No.          </th> <td>    903.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.803\n",
       "Method:                 Least Squares   F-statistic:                     11.21\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           9.07e-07\n",
       "Time:                        09:51:16   Log-Likelihood:                -83.853\n",
       "No. Observations:                  36   AIC:                             197.7\n",
       "Df Residuals:                      21   BIC:                             221.5\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================\n",
       "                     coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept        190.2984      5.139     37.032      0.000       179.612   200.985\n",
       "recovery_score     0.0094      0.083      0.113      0.911        -0.163     0.181\n",
       "user_2456         -5.3745      2.216     -2.426      0.024        -9.982    -0.767\n",
       "user_2458          6.2372      2.740      2.276      0.033         0.539    11.935\n",
       "user_2465         -4.6435      2.160     -2.149      0.043        -9.136    -0.151\n",
       "user_2466          3.8478      2.202      1.747      0.095        -0.732     8.428\n",
       "user_2468         -3.9831      2.160     -1.844      0.079        -8.475     0.508\n",
       "user_2469          1.8210      2.508      0.726      0.476        -3.395     7.037\n",
       "user_2473         -8.6932      2.646     -3.285      0.004       -14.196    -3.190\n",
       "user_2508          9.7313      3.880      2.508      0.020         1.663    17.800\n",
       "FP_5K            -10.7026      5.764     -1.857      0.077       -22.690     1.285\n",
       "Wisco_8K           1.1997      2.148      0.558      0.582        -3.268     5.668\n",
       "Brown_8K          -0.9142      2.867     -0.319      0.753        -6.875     5.047\n",
       "VCP_8K            10.1844      1.493      6.821      0.000         7.079    13.290\n",
       "FP_10K             4.5747      2.145      2.133      0.045         0.114     9.036\n",
       "==============================================================================\n",
       "Omnibus:                        1.324   Durbin-Watson:                   2.694\n",
       "Prob(Omnibus):                  0.516   Jarque-Bera (JB):                0.545\n",
       "Skew:                           0.253   Prob(JB):                        0.761\n",
       "Kurtosis:                       3.328   Cond. No.                         903.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>9.13e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:19</td>     <th>  Log-Likelihood:    </th> <td> -83.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  190.8715</td> <td>    2.698</td> <td>   70.753</td> <td> 0.000</td> <td>  185.261   196.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z1</th>        <td>-4.283e-05</td> <td>    0.003</td> <td>   -0.016</td> <td> 0.987</td> <td>   -0.006     0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -5.4298</td> <td>    2.168</td> <td>   -2.504</td> <td> 0.021</td> <td>   -9.939    -0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    6.3953</td> <td>    2.594</td> <td>    2.465</td> <td> 0.022</td> <td>    1.001    11.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -4.6245</td> <td>    2.156</td> <td>   -2.145</td> <td> 0.044</td> <td>   -9.108    -0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    3.7982</td> <td>    2.162</td> <td>    1.757</td> <td> 0.093</td> <td>   -0.697     8.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -3.9604</td> <td>    2.161</td> <td>   -1.833</td> <td> 0.081</td> <td>   -8.454     0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    1.9076</td> <td>    3.284</td> <td>    0.581</td> <td> 0.568</td> <td>   -4.922     8.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -8.5979</td> <td>    2.523</td> <td>   -3.408</td> <td> 0.003</td> <td>  -13.845    -3.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.5821</td> <td>    3.668</td> <td>    2.612</td> <td> 0.016</td> <td>    1.954    17.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>  -10.3712</td> <td>    5.077</td> <td>   -2.043</td> <td> 0.054</td> <td>  -20.928     0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    1.3001</td> <td>    1.979</td> <td>    0.657</td> <td> 0.518</td> <td>   -2.816     5.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -0.8700</td> <td>    2.875</td> <td>   -0.303</td> <td> 0.765</td> <td>   -6.849     5.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>   10.2124</td> <td>    1.622</td> <td>    6.298</td> <td> 0.000</td> <td>    6.840    13.585</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    4.6671</td> <td>    2.156</td> <td>    2.165</td> <td> 0.042</td> <td>    0.183     9.151</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.375</td> <th>  Durbin-Watson:     </th> <td>   2.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.503</td> <th>  Jarque-Bera (JB):  </th> <td>   0.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.255</td> <th>  Prob(JB):          </th> <td>   0.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.349</td> <th>  Cond. No.          </th> <td>8.03e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.803\n",
       "Method:                 Least Squares   F-statistic:                     11.21\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           9.13e-07\n",
       "Time:                        09:51:19   Log-Likelihood:                -83.864\n",
       "No. Observations:                  36   AIC:                             197.7\n",
       "Df Residuals:                      21   BIC:                             221.5\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    190.8715      2.698     70.753      0.000       185.261   196.482\n",
       "z1         -4.283e-05      0.003     -0.016      0.987        -0.006     0.006\n",
       "user_2456     -5.4298      2.168     -2.504      0.021        -9.939    -0.920\n",
       "user_2458      6.3953      2.594      2.465      0.022         1.001    11.790\n",
       "user_2465     -4.6245      2.156     -2.145      0.044        -9.108    -0.141\n",
       "user_2466      3.7982      2.162      1.757      0.093        -0.697     8.293\n",
       "user_2468     -3.9604      2.161     -1.833      0.081        -8.454     0.533\n",
       "user_2469      1.9076      3.284      0.581      0.568        -4.922     8.737\n",
       "user_2473     -8.5979      2.523     -3.408      0.003       -13.845    -3.351\n",
       "user_2508      9.5821      3.668      2.612      0.016         1.954    17.211\n",
       "FP_5K        -10.3712      5.077     -2.043      0.054       -20.928     0.186\n",
       "Wisco_8K       1.3001      1.979      0.657      0.518        -2.816     5.416\n",
       "Brown_8K      -0.8700      2.875     -0.303      0.765        -6.849     5.109\n",
       "VCP_8K        10.2124      1.622      6.298      0.000         6.840    13.585\n",
       "FP_10K         4.6671      2.156      2.165      0.042         0.183     9.151\n",
       "==============================================================================\n",
       "Omnibus:                        1.375   Durbin-Watson:                   2.688\n",
       "Prob(Omnibus):                  0.503   Jarque-Bera (JB):                0.571\n",
       "Skew:                           0.255   Prob(JB):                        0.752\n",
       "Kurtosis:                       3.349   Cond. No.                     8.03e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.03e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>8.15e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:20</td>     <th>  Log-Likelihood:    </th> <td> -83.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  192.0613</td> <td>    3.082</td> <td>   62.323</td> <td> 0.000</td> <td>  185.652   198.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z2</th>        <td>   -0.0017</td> <td>    0.003</td> <td>   -0.495</td> <td> 0.626</td> <td>   -0.009     0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -5.6190</td> <td>    2.173</td> <td>   -2.585</td> <td> 0.017</td> <td>  -10.139    -1.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    6.6776</td> <td>    2.489</td> <td>    2.683</td> <td> 0.014</td> <td>    1.502    11.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -4.7499</td> <td>    2.156</td> <td>   -2.203</td> <td> 0.039</td> <td>   -9.234    -0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    4.2458</td> <td>    2.327</td> <td>    1.825</td> <td> 0.082</td> <td>   -0.593     9.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -3.4607</td> <td>    2.370</td> <td>   -1.460</td> <td> 0.159</td> <td>   -8.389     1.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    2.3043</td> <td>    2.603</td> <td>    0.885</td> <td> 0.386</td> <td>   -3.108     7.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -8.9787</td> <td>    2.617</td> <td>   -3.431</td> <td> 0.003</td> <td>  -14.420    -3.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.5269</td> <td>    3.642</td> <td>    2.616</td> <td> 0.016</td> <td>    1.953    17.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>  -11.3860</td> <td>    5.239</td> <td>   -2.173</td> <td> 0.041</td> <td>  -22.282    -0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    1.1920</td> <td>    1.929</td> <td>    0.618</td> <td> 0.543</td> <td>   -2.821     5.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -1.1364</td> <td>    2.868</td> <td>   -0.396</td> <td> 0.696</td> <td>   -7.100     4.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>    9.8713</td> <td>    1.610</td> <td>    6.131</td> <td> 0.000</td> <td>    6.523    13.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    4.0957</td> <td>    2.249</td> <td>    1.821</td> <td> 0.083</td> <td>   -0.581     8.773</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.245</td> <th>  Durbin-Watson:     </th> <td>   2.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.536</td> <th>  Jarque-Bera (JB):  </th> <td>   0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.229</td> <th>  Prob(JB):          </th> <td>   0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.332</td> <th>  Cond. No.          </th> <td>7.84e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.883\n",
       "Model:                            OLS   Adj. R-squared:                  0.806\n",
       "Method:                 Least Squares   F-statistic:                     11.35\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           8.15e-07\n",
       "Time:                        09:51:20   Log-Likelihood:                -83.656\n",
       "No. Observations:                  36   AIC:                             197.3\n",
       "Df Residuals:                      21   BIC:                             221.1\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    192.0613      3.082     62.323      0.000       185.652   198.470\n",
       "z2            -0.0017      0.003     -0.495      0.626        -0.009     0.005\n",
       "user_2456     -5.6190      2.173     -2.585      0.017       -10.139    -1.099\n",
       "user_2458      6.6776      2.489      2.683      0.014         1.502    11.853\n",
       "user_2465     -4.7499      2.156     -2.203      0.039        -9.234    -0.266\n",
       "user_2466      4.2458      2.327      1.825      0.082        -0.593     9.085\n",
       "user_2468     -3.4607      2.370     -1.460      0.159        -8.389     1.468\n",
       "user_2469      2.3043      2.603      0.885      0.386        -3.108     7.717\n",
       "user_2473     -8.9787      2.617     -3.431      0.003       -14.420    -3.537\n",
       "user_2508      9.5269      3.642      2.616      0.016         1.953    17.101\n",
       "FP_5K        -11.3860      5.239     -2.173      0.041       -22.282    -0.490\n",
       "Wisco_8K       1.1920      1.929      0.618      0.543        -2.821     5.205\n",
       "Brown_8K      -1.1364      2.868     -0.396      0.696        -7.100     4.827\n",
       "VCP_8K         9.8713      1.610      6.131      0.000         6.523    13.220\n",
       "FP_10K         4.0957      2.249      1.821      0.083        -0.581     8.773\n",
       "==============================================================================\n",
       "Omnibus:                        1.245   Durbin-Watson:                   2.699\n",
       "Prob(Omnibus):                  0.536   Jarque-Bera (JB):                0.481\n",
       "Skew:                           0.229   Prob(JB):                        0.786\n",
       "Kurtosis:                       3.332   Cond. No.                     7.84e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.84e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result14.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>4.44e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:21</td>     <th>  Log-Likelihood:    </th> <td> -82.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   195.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   218.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  188.7387</td> <td>    2.440</td> <td>   77.345</td> <td> 0.000</td> <td>  183.664   193.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z3</th>        <td>    0.0027</td> <td>    0.002</td> <td>    1.265</td> <td> 0.220</td> <td>   -0.002     0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -4.6460</td> <td>    2.167</td> <td>   -2.144</td> <td> 0.044</td> <td>   -9.153    -0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    5.9609</td> <td>    2.365</td> <td>    2.521</td> <td> 0.020</td> <td>    1.043    10.879</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -5.4953</td> <td>    2.187</td> <td>   -2.513</td> <td> 0.020</td> <td>  -10.044    -0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    1.9498</td> <td>    2.537</td> <td>    0.769</td> <td> 0.451</td> <td>   -3.326     7.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -4.9826</td> <td>    2.226</td> <td>   -2.238</td> <td> 0.036</td> <td>   -9.613    -0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    1.0570</td> <td>    2.463</td> <td>    0.429</td> <td> 0.672</td> <td>   -4.066     6.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -7.5725</td> <td>    2.559</td> <td>   -2.959</td> <td> 0.007</td> <td>  -12.894    -2.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.1684</td> <td>    3.544</td> <td>    2.587</td> <td> 0.017</td> <td>    1.797    16.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>   -8.3216</td> <td>    4.920</td> <td>   -1.691</td> <td> 0.106</td> <td>  -18.553     1.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    0.8509</td> <td>    1.892</td> <td>    0.450</td> <td> 0.657</td> <td>   -3.083     4.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -1.3124</td> <td>    2.751</td> <td>   -0.477</td> <td> 0.638</td> <td>   -7.033     4.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>   10.8138</td> <td>    1.475</td> <td>    7.331</td> <td> 0.000</td> <td>    7.746    13.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    5.6492</td> <td>    2.003</td> <td>    2.820</td> <td> 0.010</td> <td>    1.483     9.815</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.018</td> <th>  Durbin-Watson:     </th> <td>   2.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.991</td> <th>  Jarque-Bera (JB):  </th> <td>   0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.039</td> <th>  Prob(JB):          </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.750</td> <th>  Cond. No.          </th> <td>1.03e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.890\n",
       "Model:                            OLS   Adj. R-squared:                  0.817\n",
       "Method:                 Least Squares   F-statistic:                     12.17\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           4.44e-07\n",
       "Time:                        09:51:21   Log-Likelihood:                -82.542\n",
       "No. Observations:                  36   AIC:                             195.1\n",
       "Df Residuals:                      21   BIC:                             218.8\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    188.7387      2.440     77.345      0.000       183.664   193.813\n",
       "z3             0.0027      0.002      1.265      0.220        -0.002     0.007\n",
       "user_2456     -4.6460      2.167     -2.144      0.044        -9.153    -0.140\n",
       "user_2458      5.9609      2.365      2.521      0.020         1.043    10.879\n",
       "user_2465     -5.4953      2.187     -2.513      0.020       -10.044    -0.947\n",
       "user_2466      1.9498      2.537      0.769      0.451        -3.326     7.225\n",
       "user_2468     -4.9826      2.226     -2.238      0.036        -9.613    -0.352\n",
       "user_2469      1.0570      2.463      0.429      0.672        -4.066     6.180\n",
       "user_2473     -7.5725      2.559     -2.959      0.007       -12.894    -2.251\n",
       "user_2508      9.1684      3.544      2.587      0.017         1.797    16.540\n",
       "FP_5K         -8.3216      4.920     -1.691      0.106       -18.553     1.910\n",
       "Wisco_8K       0.8509      1.892      0.450      0.657        -3.083     4.785\n",
       "Brown_8K      -1.3124      2.751     -0.477      0.638        -7.033     4.408\n",
       "VCP_8K        10.8138      1.475      7.331      0.000         7.746    13.881\n",
       "FP_10K         5.6492      2.003      2.820      0.010         1.483     9.815\n",
       "==============================================================================\n",
       "Omnibus:                        0.018   Durbin-Watson:                   2.686\n",
       "Prob(Omnibus):                  0.991   Jarque-Bera (JB):                0.103\n",
       "Skew:                           0.039   Prob(JB):                        0.950\n",
       "Kurtosis:                       2.750   Cond. No.                     1.03e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.03e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>7.20e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:22</td>     <th>  Log-Likelihood:    </th> <td> -83.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   196.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   220.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  189.0170</td> <td>    3.131</td> <td>   60.379</td> <td> 0.000</td> <td>  182.507   195.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z4</th>        <td>    0.0010</td> <td>    0.001</td> <td>    0.718</td> <td> 0.480</td> <td>   -0.002     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -4.8650</td> <td>    2.270</td> <td>   -2.143</td> <td> 0.044</td> <td>   -9.586    -0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    6.1482</td> <td>    2.421</td> <td>    2.539</td> <td> 0.019</td> <td>    1.112    11.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -4.0196</td> <td>    2.287</td> <td>   -1.758</td> <td> 0.093</td> <td>   -8.776     0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    3.3138</td> <td>    2.230</td> <td>    1.486</td> <td> 0.152</td> <td>   -1.324     7.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -4.1478</td> <td>    2.143</td> <td>   -1.936</td> <td> 0.066</td> <td>   -8.604     0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    1.8021</td> <td>    2.439</td> <td>    0.739</td> <td> 0.468</td> <td>   -3.269     6.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -8.2216</td> <td>    2.542</td> <td>   -3.234</td> <td> 0.004</td> <td>  -13.508    -2.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.7015</td> <td>    3.621</td> <td>    2.680</td> <td> 0.014</td> <td>    2.172    17.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>   -8.7892</td> <td>    5.238</td> <td>   -1.678</td> <td> 0.108</td> <td>  -19.682     2.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    1.1390</td> <td>    1.918</td> <td>    0.594</td> <td> 0.559</td> <td>   -2.849     5.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -0.9091</td> <td>    2.796</td> <td>   -0.325</td> <td> 0.748</td> <td>   -6.724     4.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>   10.7526</td> <td>    1.612</td> <td>    6.669</td> <td> 0.000</td> <td>    7.400    14.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    5.3741</td> <td>    2.128</td> <td>    2.525</td> <td> 0.020</td> <td>    0.948     9.800</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.446</td> <th>  Durbin-Watson:     </th> <td>   2.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.800</td> <th>  Jarque-Bera (JB):  </th> <td>   0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.052</td> <th>  Prob(JB):          </th> <td>   0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.124</td> <th>  Cond. No.          </th> <td>1.68e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.885\n",
       "Model:                            OLS   Adj. R-squared:                  0.808\n",
       "Method:                 Least Squares   F-statistic:                     11.52\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           7.20e-07\n",
       "Time:                        09:51:22   Log-Likelihood:                -83.427\n",
       "No. Observations:                  36   AIC:                             196.9\n",
       "Df Residuals:                      21   BIC:                             220.6\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    189.0170      3.131     60.379      0.000       182.507   195.527\n",
       "z4             0.0010      0.001      0.718      0.480        -0.002     0.004\n",
       "user_2456     -4.8650      2.270     -2.143      0.044        -9.586    -0.144\n",
       "user_2458      6.1482      2.421      2.539      0.019         1.112    11.184\n",
       "user_2465     -4.0196      2.287     -1.758      0.093        -8.776     0.737\n",
       "user_2466      3.3138      2.230      1.486      0.152        -1.324     7.952\n",
       "user_2468     -4.1478      2.143     -1.936      0.066        -8.604     0.308\n",
       "user_2469      1.8021      2.439      0.739      0.468        -3.269     6.874\n",
       "user_2473     -8.2216      2.542     -3.234      0.004       -13.508    -2.935\n",
       "user_2508      9.7015      3.621      2.680      0.014         2.172    17.231\n",
       "FP_5K         -8.7892      5.238     -1.678      0.108       -19.682     2.103\n",
       "Wisco_8K       1.1390      1.918      0.594      0.559        -2.849     5.127\n",
       "Brown_8K      -0.9091      2.796     -0.325      0.748        -6.724     4.906\n",
       "VCP_8K        10.7526      1.612      6.669      0.000         7.400    14.105\n",
       "FP_10K         5.3741      2.128      2.525      0.020         0.948     9.800\n",
       "==============================================================================\n",
       "Omnibus:                        0.446   Durbin-Watson:                   2.637\n",
       "Prob(Omnibus):                  0.800   Jarque-Bera (JB):                0.039\n",
       "Skew:                           0.052   Prob(JB):                        0.981\n",
       "Kurtosis:                       3.124   Cond. No.                     1.68e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.68e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>pace_per_k</td>    <th>  R-squared:         </th> <td>   0.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 29 Jan 2016</td> <th>  Prob (F-statistic):</th> <td>9.10e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:51:23</td>     <th>  Log-Likelihood:    </th> <td> -83.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    36</td>      <th>  AIC:               </th> <td>   197.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    21</td>      <th>  BIC:               </th> <td>   221.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  190.7922</td> <td>    1.939</td> <td>   98.393</td> <td> 0.000</td> <td>  186.760   194.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>z5</th>        <td>    0.0002</td> <td>    0.002</td> <td>    0.085</td> <td> 0.933</td> <td>   -0.004     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2456</th> <td>   -5.6426</td> <td>    3.272</td> <td>   -1.725</td> <td> 0.099</td> <td>  -12.447     1.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2458</th> <td>    6.4103</td> <td>    2.454</td> <td>    2.613</td> <td> 0.016</td> <td>    1.308    11.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2465</th> <td>   -4.5893</td> <td>    2.189</td> <td>   -2.096</td> <td> 0.048</td> <td>   -9.142    -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2466</th> <td>    3.7953</td> <td>    2.153</td> <td>    1.763</td> <td> 0.092</td> <td>   -0.682     8.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2468</th> <td>   -3.9680</td> <td>    2.154</td> <td>   -1.842</td> <td> 0.080</td> <td>   -8.447     0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2469</th> <td>    1.9003</td> <td>    2.487</td> <td>    0.764</td> <td> 0.453</td> <td>   -3.272     7.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2473</th> <td>   -8.5535</td> <td>    2.578</td> <td>   -3.318</td> <td> 0.003</td> <td>  -13.914    -3.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_2508</th> <td>    9.6031</td> <td>    3.666</td> <td>    2.619</td> <td> 0.016</td> <td>    1.979    17.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_5K</th>     <td>  -10.3158</td> <td>    4.839</td> <td>   -2.132</td> <td> 0.045</td> <td>  -20.379    -0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Wisco_8K</th>  <td>    1.2529</td> <td>    2.031</td> <td>    0.617</td> <td> 0.544</td> <td>   -2.970     5.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Brown_8K</th>  <td>   -0.8715</td> <td>    2.832</td> <td>   -0.308</td> <td> 0.761</td> <td>   -6.760     5.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VCP_8K</th>    <td>   10.2328</td> <td>    1.455</td> <td>    7.031</td> <td> 0.000</td> <td>    7.206    13.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FP_10K</th>    <td>    4.7371</td> <td>    2.025</td> <td>    2.339</td> <td> 0.029</td> <td>    0.526     8.949</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.337</td> <th>  Durbin-Watson:     </th> <td>   2.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.513</td> <th>  Jarque-Bera (JB):  </th> <td>   0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.249</td> <th>  Prob(JB):          </th> <td>   0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.342</td> <th>  Cond. No.          </th> <td>6.81e+03</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             pace_per_k   R-squared:                       0.882\n",
       "Model:                            OLS   Adj. R-squared:                  0.803\n",
       "Method:                 Least Squares   F-statistic:                     11.21\n",
       "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           9.10e-07\n",
       "Time:                        09:51:23   Log-Likelihood:                -83.858\n",
       "No. Observations:                  36   AIC:                             197.7\n",
       "Df Residuals:                      21   BIC:                             221.5\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    190.7922      1.939     98.393      0.000       186.760   194.825\n",
       "z5             0.0002      0.002      0.085      0.933        -0.004     0.004\n",
       "user_2456     -5.6426      3.272     -1.725      0.099       -12.447     1.162\n",
       "user_2458      6.4103      2.454      2.613      0.016         1.308    11.513\n",
       "user_2465     -4.5893      2.189     -2.096      0.048        -9.142    -0.037\n",
       "user_2466      3.7953      2.153      1.763      0.092        -0.682     8.273\n",
       "user_2468     -3.9680      2.154     -1.842      0.080        -8.447     0.511\n",
       "user_2469      1.9003      2.487      0.764      0.453        -3.272     7.072\n",
       "user_2473     -8.5535      2.578     -3.318      0.003       -13.914    -3.193\n",
       "user_2508      9.6031      3.666      2.619      0.016         1.979    17.227\n",
       "FP_5K        -10.3158      4.839     -2.132      0.045       -20.379    -0.253\n",
       "Wisco_8K       1.2529      2.031      0.617      0.544        -2.970     5.476\n",
       "Brown_8K      -0.8715      2.832     -0.308      0.761        -6.760     5.017\n",
       "VCP_8K        10.2328      1.455      7.031      0.000         7.206    13.260\n",
       "FP_10K         4.7371      2.025      2.339      0.029         0.526     8.949\n",
       "==============================================================================\n",
       "Omnibus:                        1.337   Durbin-Watson:                   2.688\n",
       "Prob(Omnibus):                  0.513   Jarque-Bera (JB):                0.546\n",
       "Skew:                           0.249   Prob(JB):                        0.761\n",
       "Kurtosis:                       3.342   Cond. No.                     6.81e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.81e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result17.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###10 days weighted\n",
    "To avoid printing everything, I run the same analysis for the other weighted average dataframes, and summarize any significant results below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_10daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_10daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant results:\n",
    "- light sleep duration, weighted 10 days. It has a very small coefficient but p-value of 0.011\n",
    "- light sleep duration, weighted 7 days. It has a very small coefficient  but p-value at 0.022\n",
    "- light sleep duration, weighted 6 days. It has a very small coefficient  but p-value at 0.024\n",
    "- light sleep duration, weighted 5 days. It has a very small coefficient but p-value at 0.015\n",
    "- light sleep duration, weighted 4 days. It has a very small coefficient but p-value at 0.14\n",
    "- sleep score, weighted 4 days. The coefficient is 0.22 and the p-value is 0.05\n",
    "- REM sleep duration, weighted 3 days. The coefficient is very small and the pvalue is 0.08\n",
    "- light sleep duration, weighted 3 days. The coefficient is very small and the pvalue is 0.05\n",
    "- sleep latency, weighted 3 days. The coefficient is very small, the p-value is 0.023\n",
    "- sleep score, weighted 3 days. The coefficient is 0.26 and the p-value is 0.085\n",
    "- REM sleepd duration, weighted 2 days. Coefficient is very small, p-value 0.056\n",
    "- light sleep duration, weighted 2 days. Coefficient is very small, p-value is 0.077\n",
    "- sleep latency, weighted 2 days. Coefficient is very small, p-value is 0.004\n",
    "- sleep score, weighted 2 days. Coefficient is 0.27, p-value is 0.063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.914\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     15.94\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.99e-08\n",
      "Time:                        10:10:35   Log-Likelihood:                -78.166\n",
      "No. Observations:                  36   AIC:                             186.3\n",
      "Df Residuals:                      21   BIC:                             210.1\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              176.6892      5.302     33.323      0.000       165.663   187.716\n",
      "light_sleep_duration  7.211e-07   2.58e-07      2.796      0.011      1.85e-07  1.26e-06\n",
      "user_2456               -3.6531      1.945     -1.878      0.074        -7.699     0.392\n",
      "user_2458               10.7781      2.602      4.142      0.000         5.366    16.190\n",
      "user_2465               -0.9757      2.254     -0.433      0.669        -5.663     3.711\n",
      "user_2466                7.4594      2.257      3.305      0.003         2.765    12.154\n",
      "user_2468               -3.0320      1.868     -1.623      0.119        -6.917     0.853\n",
      "user_2469               -0.4743      2.267     -0.209      0.836        -5.188     4.239\n",
      "user_2473               -2.8973      2.962     -0.978      0.339        -9.058     3.263\n",
      "user_2508               12.2579      3.268      3.751      0.001         5.462    19.054\n",
      "FP_5K                  -20.1171      5.402     -3.724      0.001       -31.352    -8.883\n",
      "Wisco_8K                -0.4203      1.757     -0.239      0.813        -4.073     3.233\n",
      "Brown_8K                -1.2989      2.421     -0.537      0.597        -6.333     3.735\n",
      "VCP_8K                   9.8661      1.246      7.918      0.000         7.275    12.457\n",
      "FP_10K                   2.9964      1.747      1.715      0.101        -0.638     6.630\n",
      "==============================================================================\n",
      "Omnibus:                        1.544   Durbin-Watson:                   2.956\n",
      "Prob(Omnibus):                  0.462   Jarque-Bera (JB):                1.051\n",
      "Skew:                          -0.062   Prob(JB):                        0.591\n",
      "Kurtosis:                       2.172   Cond. No.                     3.16e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.16e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###7 Days weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_7daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_7daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.909\n",
      "Model:                            OLS   Adj. R-squared:                  0.848\n",
      "Method:                 Least Squares   F-statistic:                     14.90\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           7.34e-08\n",
      "Time:                        10:02:22   Log-Likelihood:                -79.269\n",
      "No. Observations:                  36   AIC:                             188.5\n",
      "Df Residuals:                      21   BIC:                             212.3\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              178.3246      5.321     33.515      0.000       167.260   189.389\n",
      "light_sleep_duration  6.346e-07   2.57e-07      2.471      0.022      1.01e-07  1.17e-06\n",
      "user_2456               -3.8050      2.007     -1.896      0.072        -7.978     0.368\n",
      "user_2458               10.1494      2.626      3.865      0.001         4.688    15.610\n",
      "user_2465               -1.4704      2.284     -0.644      0.527        -6.221     3.280\n",
      "user_2466                6.9320      2.281      3.039      0.006         2.188    11.676\n",
      "user_2468               -3.2155      1.919     -1.675      0.109        -7.207     0.776\n",
      "user_2469               -0.4552      2.366     -0.192      0.849        -5.376     4.466\n",
      "user_2473               -3.4740      3.035     -1.145      0.265        -9.786     2.838\n",
      "user_2508               11.8620      3.351      3.539      0.002         4.892    18.832\n",
      "FP_5K                  -18.7882      5.451     -3.447      0.002       -30.124    -7.452\n",
      "Wisco_8K                -0.0395      1.781     -0.022      0.983        -3.743     3.664\n",
      "Brown_8K                -0.8508      2.491     -0.342      0.736        -6.030     4.329\n",
      "VCP_8K                  10.0465      1.280      7.849      0.000         7.385    12.708\n",
      "FP_10K                   3.3782      1.772      1.907      0.070        -0.306     7.062\n",
      "==============================================================================\n",
      "Omnibus:                        0.504   Durbin-Watson:                   2.972\n",
      "Prob(Omnibus):                  0.777   Jarque-Bera (JB):                0.605\n",
      "Skew:                          -0.006   Prob(JB):                        0.739\n",
      "Kurtosis:                       2.365   Cond. No.                     3.06e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.06e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Weighted 6 Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_6daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_6daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.908\n",
      "Model:                            OLS   Adj. R-squared:                  0.846\n",
      "Method:                 Least Squares   F-statistic:                     14.76\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           7.98e-08\n",
      "Time:                        10:07:57   Log-Likelihood:                -79.419\n",
      "No. Observations:                  36   AIC:                             188.8\n",
      "Df Residuals:                      21   BIC:                             212.6\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              178.8417      5.212     34.315      0.000       168.003   189.680\n",
      "light_sleep_duration  5.997e-07   2.47e-07      2.425      0.024      8.55e-08  1.11e-06\n",
      "user_2456               -3.7079      2.032     -1.825      0.082        -7.933     0.518\n",
      "user_2458               10.0707      2.631      3.827      0.001         4.598    15.543\n",
      "user_2465               -1.5932      2.277     -0.700      0.492        -6.327     3.141\n",
      "user_2466                6.8088      2.273      2.996      0.007         2.082    11.536\n",
      "user_2468               -3.1589      1.932     -1.635      0.117        -7.176     0.859\n",
      "user_2469               -0.3179      2.360     -0.135      0.894        -5.225     4.589\n",
      "user_2473               -3.6688      3.014     -1.217      0.237        -9.937     2.599\n",
      "user_2508               11.9564      3.380      3.537      0.002         4.927    18.986\n",
      "FP_5K                  -18.3614      5.396     -3.403      0.003       -29.584    -7.139\n",
      "Wisco_8K                 0.1682      1.766      0.095      0.925        -3.505     3.841\n",
      "Brown_8K                -0.6673      2.502     -0.267      0.792        -5.871     4.537\n",
      "VCP_8K                  10.0556      1.285      7.824      0.000         7.383    12.728\n",
      "FP_10K                   3.5279      1.764      2.000      0.059        -0.140     7.196\n",
      "==============================================================================\n",
      "Omnibus:                        0.188   Durbin-Watson:                   2.987\n",
      "Prob(Omnibus):                  0.910   Jarque-Bera (JB):                0.397\n",
      "Skew:                           0.009   Prob(JB):                        0.820\n",
      "Kurtosis:                       2.486   Cond. No.                     3.02e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.02e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###5 days weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_5daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_5daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.914\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     15.94\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.99e-08\n",
      "Time:                        10:11:25   Log-Likelihood:                -78.166\n",
      "No. Observations:                  36   AIC:                             186.3\n",
      "Df Residuals:                      21   BIC:                             210.1\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              176.6892      5.302     33.323      0.000       165.663   187.716\n",
      "light_sleep_duration  7.211e-07   2.58e-07      2.796      0.011      1.85e-07  1.26e-06\n",
      "user_2456               -3.6531      1.945     -1.878      0.074        -7.699     0.392\n",
      "user_2458               10.7781      2.602      4.142      0.000         5.366    16.190\n",
      "user_2465               -0.9757      2.254     -0.433      0.669        -5.663     3.711\n",
      "user_2466                7.4594      2.257      3.305      0.003         2.765    12.154\n",
      "user_2468               -3.0320      1.868     -1.623      0.119        -6.917     0.853\n",
      "user_2469               -0.4743      2.267     -0.209      0.836        -5.188     4.239\n",
      "user_2473               -2.8973      2.962     -0.978      0.339        -9.058     3.263\n",
      "user_2508               12.2579      3.268      3.751      0.001         5.462    19.054\n",
      "FP_5K                  -20.1171      5.402     -3.724      0.001       -31.352    -8.883\n",
      "Wisco_8K                -0.4203      1.757     -0.239      0.813        -4.073     3.233\n",
      "Brown_8K                -1.2989      2.421     -0.537      0.597        -6.333     3.735\n",
      "VCP_8K                   9.8661      1.246      7.918      0.000         7.275    12.457\n",
      "FP_10K                   2.9964      1.747      1.715      0.101        -0.638     6.630\n",
      "==============================================================================\n",
      "Omnibus:                        1.544   Durbin-Watson:                   2.956\n",
      "Prob(Omnibus):                  0.462   Jarque-Bera (JB):                1.051\n",
      "Skew:                          -0.062   Prob(JB):                        0.591\n",
      "Kurtosis:                       2.172   Cond. No.                     3.16e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.16e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###4 days weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_4daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_4daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.912\n",
      "Model:                            OLS   Adj. R-squared:                  0.853\n",
      "Method:                 Least Squares   F-statistic:                     15.51\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           5.10e-08\n",
      "Time:                        10:17:02   Log-Likelihood:                -78.611\n",
      "No. Observations:                  36   AIC:                             187.2\n",
      "Df Residuals:                      21   BIC:                             211.0\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              179.1124      4.679     38.279      0.000       169.382   188.843\n",
      "light_sleep_duration  5.572e-07   2.09e-07      2.668      0.014      1.23e-07  9.92e-07\n",
      "user_2456               -3.1295      2.052     -1.525      0.142        -7.396     1.137\n",
      "user_2458               10.3311      2.569      4.022      0.001         4.989    15.674\n",
      "user_2465               -1.3996      2.219     -0.631      0.535        -6.014     3.215\n",
      "user_2466                6.9451      2.204      3.151      0.005         2.362    11.528\n",
      "user_2468               -2.6241      1.927     -1.361      0.188        -6.632     1.384\n",
      "user_2469                0.4776      2.195      0.218      0.830        -4.087     5.042\n",
      "user_2473               -3.6527      2.859     -1.278      0.215        -9.598     2.292\n",
      "user_2508               12.3453      3.329      3.709      0.001         5.423    19.268\n",
      "FP_5K                  -17.7382      5.008     -3.542      0.002       -28.152    -7.324\n",
      "Wisco_8K                 0.5590      1.688      0.331      0.744        -2.952     4.070\n",
      "Brown_8K                -0.2572      2.456     -0.105      0.918        -5.365     4.850\n",
      "VCP_8K                  10.0711      1.256      8.018      0.000         7.459    12.683\n",
      "FP_10K                   3.8259      1.691      2.262      0.034         0.309     7.343\n",
      "==============================================================================\n",
      "Omnibus:                        0.161   Durbin-Watson:                   3.031\n",
      "Prob(Omnibus):                  0.923   Jarque-Bera (JB):                0.371\n",
      "Skew:                           0.057   Prob(JB):                        0.831\n",
      "Kurtosis:                       2.516   Cond. No.                     2.87e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.87e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.902\n",
      "Model:                            OLS   Adj. R-squared:                  0.837\n",
      "Method:                 Least Squares   F-statistic:                     13.81\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           1.45e-07\n",
      "Time:                        10:14:57   Log-Likelihood:                -80.502\n",
      "No. Observations:                  36   AIC:                             191.0\n",
      "Df Residuals:                      21   BIC:                             214.8\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    171.0465      9.680     17.670      0.000       150.916   191.177\n",
      "score          0.2179      0.105      2.077      0.050        -0.000     0.436\n",
      "user_2456     -0.7407      2.992     -0.248      0.807        -6.964     5.482\n",
      "user_2458      5.1376      2.292      2.242      0.036         0.371     9.904\n",
      "user_2465     -1.8192      2.381     -0.764      0.453        -6.771     3.132\n",
      "user_2466      8.9343      3.158      2.829      0.010         2.368    15.501\n",
      "user_2468     -2.6540      2.060     -1.288      0.212        -6.938     1.630\n",
      "user_2469      1.6396      2.249      0.729      0.474        -3.038     6.317\n",
      "user_2473     -5.3939      2.764     -1.951      0.064       -11.142     0.355\n",
      "user_2508     15.4951      4.384      3.535      0.002         6.379    24.612\n",
      "FP_5K        -18.2550      5.816     -3.139      0.005       -30.351    -6.159\n",
      "Wisco_8K      -1.0092      2.079     -0.485      0.632        -5.333     3.315\n",
      "Brown_8K      -1.1067      2.580     -0.429      0.672        -6.472     4.259\n",
      "VCP_8K        10.3059      1.323      7.789      0.000         7.554    13.057\n",
      "FP_10K         2.5237      2.036      1.240      0.229        -1.709     6.757\n",
      "==============================================================================\n",
      "Omnibus:                        0.105   Durbin-Watson:                   2.577\n",
      "Prob(Omnibus):                  0.949   Jarque-Bera (JB):                0.016\n",
      "Skew:                          -0.002   Prob(JB):                        0.992\n",
      "Kurtosis:                       2.897   Cond. No.                     2.04e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.04e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result11.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###3 days weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_3daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_3daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.904\n",
      "Model:                            OLS   Adj. R-squared:                  0.837\n",
      "Method:                 Least Squares   F-statistic:                     13.47\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.05e-07\n",
      "Time:                        10:23:06   Log-Likelihood:                -78.385\n",
      "No. Observations:                  35   AIC:                             186.8\n",
      "Df Residuals:                      20   BIC:                             210.1\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    166.7038     13.354     12.484      0.000       138.848   194.559\n",
      "score          0.2654      0.146      1.814      0.085        -0.040     0.571\n",
      "user_2456      0.2413      3.688      0.065      0.948        -7.452     7.934\n",
      "user_2458      4.6929      2.426      1.935      0.067        -0.367     9.753\n",
      "user_2465     -1.7967      2.512     -0.715      0.483        -7.037     3.443\n",
      "user_2466      9.8604      3.871      2.547      0.019         1.786    17.935\n",
      "user_2468     -2.5805      2.139     -1.206      0.242        -7.042     1.881\n",
      "user_2469      1.5599      2.282      0.683      0.502        -3.201     6.321\n",
      "user_2473     -6.1387      2.676     -2.294      0.033       -11.722    -0.556\n",
      "user_2508     16.5686      5.190      3.193      0.005         5.743    27.394\n",
      "FP_5K        -19.7330      6.949     -2.840      0.010       -34.229    -5.238\n",
      "Wisco_8K      -1.1677      2.215     -0.527      0.604        -5.787     3.452\n",
      "Brown_8K      -1.5065      2.650     -0.569      0.576        -7.033     4.020\n",
      "VCP_8K        10.4978      1.361      7.711      0.000         7.658    13.337\n",
      "FP_10K         2.1806      2.223      0.981      0.338        -2.457     6.818\n",
      "==============================================================================\n",
      "Omnibus:                        0.087   Durbin-Watson:                   2.611\n",
      "Prob(Omnibus):                  0.958   Jarque-Bera (JB):                0.288\n",
      "Skew:                           0.065   Prob(JB):                        0.866\n",
      "Kurtosis:                       2.575   Cond. No.                     2.70e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.7e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.914\n",
      "Model:                            OLS   Adj. R-squared:                  0.854\n",
      "Method:                 Least Squares   F-statistic:                     15.21\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           1.07e-07\n",
      "Time:                        10:22:51   Log-Likelihood:                -76.447\n",
      "No. Observations:                  35   AIC:                             182.9\n",
      "Df Residuals:                      20   BIC:                             206.2\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    184.7577      2.923     63.205      0.000       178.660   190.855\n",
      "latency     4.958e-06   2.02e-06      2.453      0.023      7.42e-07  9.17e-06\n",
      "user_2456     -4.6127      1.908     -2.417      0.025        -8.593    -0.632\n",
      "user_2458      5.3791      2.160      2.490      0.022         0.873     9.885\n",
      "user_2465     -4.2647      1.886     -2.261      0.035        -8.199    -0.331\n",
      "user_2466      4.6559      1.911      2.436      0.024         0.670     8.642\n",
      "user_2468     -3.3697      2.007     -1.679      0.109        -7.556     0.816\n",
      "user_2469      3.2296      2.232      1.447      0.163        -1.426     7.885\n",
      "user_2473     -9.7549      2.254     -4.327      0.000       -14.457    -5.052\n",
      "user_2508     11.1025      3.273      3.392      0.003         4.276    17.929\n",
      "FP_5K        -10.8212      4.234     -2.556      0.019       -19.652    -1.990\n",
      "Wisco_8K       1.7302      1.697      1.019      0.320        -1.810     5.271\n",
      "Brown_8K      -0.2830      2.481     -0.114      0.910        -5.459     4.893\n",
      "VCP_8K        10.2247      1.293      7.909      0.000         7.528    12.921\n",
      "FP_10K         3.0212      1.800      1.679      0.109        -0.733     6.776\n",
      "==============================================================================\n",
      "Omnibus:                        1.352   Durbin-Watson:                   2.659\n",
      "Prob(Omnibus):                  0.509   Jarque-Bera (JB):                0.978\n",
      "Skew:                          -0.060   Prob(JB):                        0.613\n",
      "Kurtosis:                       2.190   Cond. No.                     1.31e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.31e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.908\n",
      "Model:                            OLS   Adj. R-squared:                  0.844\n",
      "Method:                 Least Squares   F-statistic:                     14.16\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           1.99e-07\n",
      "Time:                        10:20:04   Log-Likelihood:                -77.592\n",
      "No. Observations:                  35   AIC:                             185.2\n",
      "Df Residuals:                      20   BIC:                             208.5\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              179.4310      5.655     31.728      0.000       167.634   191.228\n",
      "light_sleep_duration  5.389e-07   2.58e-07      2.090      0.050      1.15e-09  1.08e-06\n",
      "user_2456               -3.0914      2.234     -1.384      0.182        -7.751     1.568\n",
      "user_2458               10.3052      2.891      3.565      0.002         4.275    16.335\n",
      "user_2465               -1.6251      2.404     -0.676      0.507        -6.639     3.389\n",
      "user_2466                6.8668      2.425      2.832      0.010         1.809    11.925\n",
      "user_2468               -2.9565      2.072     -1.427      0.169        -7.279     1.366\n",
      "user_2469                0.6386      2.297      0.278      0.784        -4.152     5.429\n",
      "user_2473               -4.3398      3.035     -1.430      0.168       -10.670     1.990\n",
      "user_2508               12.1332      3.551      3.417      0.003         4.726    19.540\n",
      "FP_5K                  -17.2770      5.560     -3.108      0.006       -28.874    -5.680\n",
      "Wisco_8K                 1.0017      1.744      0.574      0.572        -2.636     4.639\n",
      "Brown_8K                -0.2637      2.567     -0.103      0.919        -5.618     5.090\n",
      "VCP_8K                  10.0575      1.347      7.465      0.000         7.247    12.868\n",
      "FP_10K                   4.0195      1.758      2.286      0.033         0.352     7.687\n",
      "==============================================================================\n",
      "Omnibus:                        0.453   Durbin-Watson:                   2.985\n",
      "Prob(Omnibus):                  0.797   Jarque-Bera (JB):                0.596\n",
      "Skew:                           0.144   Prob(JB):                        0.742\n",
      "Kurtosis:                       2.429   Cond. No.                     3.18e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.18e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.904\n",
      "Model:                            OLS   Adj. R-squared:                  0.837\n",
      "Method:                 Least Squares   F-statistic:                     13.51\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           2.98e-07\n",
      "Time:                        10:18:04   Log-Likelihood:                -78.342\n",
      "No. Observations:                  35   AIC:                             186.7\n",
      "Df Residuals:                      20   BIC:                             210.0\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept            193.3746      2.245     86.133      0.000       188.691   198.058\n",
      "rem_sleep_duration  -4.88e-07   2.67e-07     -1.829      0.082     -1.04e-06  6.84e-08\n",
      "user_2456             -4.7817      2.014     -2.374      0.028        -8.983    -0.581\n",
      "user_2458              9.9977      2.993      3.341      0.003         3.755    16.241\n",
      "user_2465             -3.6508      2.050     -1.781      0.090        -7.927     0.626\n",
      "user_2466              5.8915      2.282      2.582      0.018         1.132    10.651\n",
      "user_2468             -2.3630      2.156     -1.096      0.286        -6.859     2.133\n",
      "user_2469              1.6088      2.278      0.706      0.488        -3.143     6.361\n",
      "user_2473             -5.5017      2.856     -1.926      0.068       -11.459     0.455\n",
      "user_2508              9.7875      3.385      2.892      0.009         2.727    16.848\n",
      "FP_5K                -12.4720      4.646     -2.684      0.014       -22.164    -2.780\n",
      "Wisco_8K              -0.3888      1.984     -0.196      0.847        -4.527     3.750\n",
      "Brown_8K              -0.7390      2.612     -0.283      0.780        -6.188     4.710\n",
      "VCP_8K                 8.3474      1.797      4.646      0.000         4.599    12.096\n",
      "FP_10K                 3.0662      1.963      1.562      0.134        -1.029     7.161\n",
      "==============================================================================\n",
      "Omnibus:                        0.160   Durbin-Watson:                   2.883\n",
      "Prob(Omnibus):                  0.923   Jarque-Bera (JB):                0.297\n",
      "Skew:                           0.140   Prob(JB):                        0.862\n",
      "Kurtosis:                       2.646   Cond. No.                     7.12e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.12e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2 days weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_race_df_2daysweighted.csv')\n",
    "df2 = pd.read_csv('workout_final_race_df_2daysweighted.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "reg_df = pd.merge(df, df2, how='left')\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1)\n",
    "\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result1 = sm.ols(formula=\"pace_per_k~ hrv_rmssd + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result2 = sm.ols(formula=\"pace_per_k~ resting_heart_rate + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result3 = sm.ols(formula=\"pace_per_k~ sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result4 = sm.ols(formula=\"pace_per_k~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result5 = sm.ols(formula=\"pace_per_k~ slow_wave_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result6 = sm.ols(formula=\"pace_per_k~ light_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result7 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result8 = sm.ols(formula=\"pace_per_k~ cycles_count + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result9 = sm.ols(formula=\"pace_per_k~ time_in_bed + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result10 = sm.ols(formula=\"pace_per_k~ latency + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result11 = sm.ols(formula=\"pace_per_k~ score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result12 = sm.ols(formula=\"pace_per_k~ recovery_score + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result13 = sm.ols(formula=\"pace_per_k~ z1 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result14 = sm.ols(formula=\"pace_per_k~ z2 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result15 = sm.ols(formula=\"pace_per_k~ z3 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result16 = sm.ols(formula=\"pace_per_k~ z4 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "result17 = sm.ols(formula=\"pace_per_k~ z5 + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.905\n",
      "Model:                            OLS   Adj. R-squared:                  0.835\n",
      "Method:                 Least Squares   F-statistic:                     12.94\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           7.17e-07\n",
      "Time:                        10:26:35   Log-Likelihood:                -75.938\n",
      "No. Observations:                  34   AIC:                             181.9\n",
      "Df Residuals:                      19   BIC:                             204.8\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    166.1200     12.446     13.347      0.000       140.070   192.170\n",
      "score          0.2696      0.136      1.978      0.063        -0.016     0.555\n",
      "user_2456      0.7283      3.644      0.200      0.844        -6.899     8.356\n",
      "user_2458      4.5380      2.571      1.765      0.094        -0.843     9.918\n",
      "user_2465     -1.8924      2.467     -0.767      0.453        -7.056     3.272\n",
      "user_2466     10.0031      3.663      2.731      0.013         2.336    17.670\n",
      "user_2468     -2.2596      2.280     -0.991      0.334        -7.032     2.512\n",
      "user_2469      1.7190      2.454      0.701      0.492        -3.417     6.855\n",
      "user_2473     -6.1702      2.684     -2.299      0.033       -11.788    -0.553\n",
      "user_2508     17.1004      5.110      3.346      0.003         6.405    27.796\n",
      "FP_5K        -20.0976      6.736     -2.984      0.008       -34.196    -5.999\n",
      "Wisco_8K      -1.4609      2.235     -0.654      0.521        -6.139     3.217\n",
      "Brown_8K      -1.7732      2.718     -0.652      0.522        -7.463     3.917\n",
      "VCP_8K        10.7611      1.404      7.662      0.000         7.822    13.701\n",
      "FP_10K         2.1166      2.190      0.966      0.346        -2.468     6.701\n",
      "==============================================================================\n",
      "Omnibus:                        0.266   Durbin-Watson:                   2.544\n",
      "Prob(Omnibus):                  0.876   Jarque-Bera (JB):                0.457\n",
      "Skew:                           0.077   Prob(JB):                        0.796\n",
      "Kurtosis:                       2.453   Cond. No.                     2.49e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.49e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.927\n",
      "Model:                            OLS   Adj. R-squared:                  0.873\n",
      "Method:                 Least Squares   F-statistic:                     17.19\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           6.87e-08\n",
      "Time:                        10:26:23   Log-Likelihood:                -71.510\n",
      "No. Observations:                  34   AIC:                             173.0\n",
      "Df Residuals:                      19   BIC:                             195.9\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    183.1758      2.757     66.443      0.000       177.406   188.946\n",
      "latency      5.25e-06    1.6e-06      3.275      0.004      1.89e-06   8.6e-06\n",
      "user_2456     -3.5674      1.946     -1.833      0.082        -7.641     0.506\n",
      "user_2458      6.1957      2.064      3.002      0.007         1.876    10.516\n",
      "user_2465     -3.5916      1.901     -1.889      0.074        -7.571     0.388\n",
      "user_2466      5.8816      1.963      2.996      0.007         1.773     9.991\n",
      "user_2468     -2.2506      1.993     -1.129      0.273        -6.423     1.922\n",
      "user_2469      4.3225      2.248      1.923      0.070        -0.382     9.027\n",
      "user_2473     -7.3773      2.186     -3.375      0.003       -11.953    -2.802\n",
      "user_2508     12.2117      3.185      3.834      0.001         5.545    18.878\n",
      "FP_5K        -10.7849      3.949     -2.731      0.013       -19.050    -2.520\n",
      "Wisco_8K       1.8531      1.587      1.167      0.257        -1.469     5.175\n",
      "Brown_8K       0.5009      2.353      0.213      0.834        -4.424     5.426\n",
      "VCP_8K        10.5390      1.223      8.616      0.000         7.979    13.099\n",
      "FP_10K         3.4545      1.608      2.149      0.045         0.090     6.819\n",
      "==============================================================================\n",
      "Omnibus:                        0.945   Durbin-Watson:                   2.565\n",
      "Prob(Omnibus):                  0.623   Jarque-Bera (JB):                0.847\n",
      "Skew:                           0.126   Prob(JB):                        0.655\n",
      "Kurtosis:                       2.269   Cond. No.                     1.41e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.41e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.903\n",
      "Model:                            OLS   Adj. R-squared:                  0.832\n",
      "Method:                 Least Squares   F-statistic:                     12.68\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           8.45e-07\n",
      "Time:                        10:25:51   Log-Likelihood:                -76.248\n",
      "No. Observations:                  34   AIC:                             182.5\n",
      "Df Residuals:                      19   BIC:                             205.4\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              180.4680      5.662     31.871      0.000       168.616   192.320\n",
      "light_sleep_duration  4.783e-07   2.56e-07      1.870      0.077     -5.71e-08  1.01e-06\n",
      "user_2456               -2.7534      2.506     -1.099      0.286        -7.998     2.491\n",
      "user_2458               10.0353      2.992      3.354      0.003         3.772    16.298\n",
      "user_2465               -1.6079      2.599     -0.619      0.544        -7.048     3.832\n",
      "user_2466                6.8326      2.606      2.622      0.017         1.378    12.287\n",
      "user_2468               -2.4829      2.290     -1.084      0.292        -7.276     2.310\n",
      "user_2469                1.1368      2.524      0.450      0.658        -4.147     6.420\n",
      "user_2473               -4.8734      3.076     -1.585      0.130       -11.311     1.564\n",
      "user_2508               12.0545      3.761      3.205      0.005         4.182    19.927\n",
      "FP_5K                  -16.4019      5.627     -2.915      0.009       -28.179    -4.625\n",
      "Wisco_8K                 1.0725      1.810      0.592      0.561        -2.716     4.861\n",
      "Brown_8K                -0.0607      2.693     -0.023      0.982        -5.697     5.575\n",
      "VCP_8K                   9.9987      1.421      7.035      0.000         7.024    12.974\n",
      "FP_10K                   4.1004      1.823      2.249      0.037         0.284     7.917\n",
      "==============================================================================\n",
      "Omnibus:                        0.322   Durbin-Watson:                   2.952\n",
      "Prob(Omnibus):                  0.851   Jarque-Bera (JB):                0.495\n",
      "Skew:                           0.153   Prob(JB):                        0.781\n",
      "Kurtosis:                       2.495   Cond. No.                     3.03e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.03e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.906\n",
      "Model:                            OLS   Adj. R-squared:                  0.837\n",
      "Method:                 Least Squares   F-statistic:                     13.08\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           6.55e-07\n",
      "Time:                        10:25:32   Log-Likelihood:                -75.764\n",
      "No. Observations:                  34   AIC:                             181.5\n",
      "Df Residuals:                      19   BIC:                             204.4\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept            193.1159      2.260     85.456      0.000       188.386   197.846\n",
      "rem_sleep_duration  -5.29e-07    2.6e-07     -2.037      0.056     -1.07e-06  1.47e-08\n",
      "user_2456             -3.9596      2.212     -1.790      0.089        -8.590     0.671\n",
      "user_2458             10.8922      3.140      3.468      0.003         4.319    17.465\n",
      "user_2465             -2.8943      2.247     -1.288      0.213        -7.597     1.808\n",
      "user_2466              6.6219      2.464      2.688      0.015         1.465    11.779\n",
      "user_2468             -1.5864      2.331     -0.680      0.504        -6.466     3.293\n",
      "user_2469              2.3322      2.434      0.958      0.350        -2.763     7.427\n",
      "user_2473             -4.6032      3.038     -1.515      0.146       -10.963     1.756\n",
      "user_2508             10.5859      3.532      2.997      0.007         3.192    17.979\n",
      "FP_5K                -12.9764      4.677     -2.774      0.012       -22.767    -3.186\n",
      "Wisco_8K              -0.6836      2.005     -0.341      0.737        -4.879     3.512\n",
      "Brown_8K              -0.4750      2.640     -0.180      0.859        -6.001     5.051\n",
      "VCP_8K                 7.8607      1.863      4.219      0.000         3.961    11.761\n",
      "FP_10K                 2.9352      1.961      1.497      0.151        -1.169     7.039\n",
      "==============================================================================\n",
      "Omnibus:                        0.244   Durbin-Watson:                   2.937\n",
      "Prob(Omnibus):                  0.885   Jarque-Bera (JB):                0.375\n",
      "Skew:                           0.174   Prob(JB):                        0.829\n",
      "Kurtosis:                       2.621   Cond. No.                     7.84e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.84e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Looking at just the 5 individual days before the race - OLS regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The night before the race (when buildup_day = 0, as that sleep data is from the night before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things that came up as significant, but likely because of random error\n",
    "\n",
    "- Latency is significant the night before the race, but the coefficient is basically zero with a pvalue of 0.002\n",
    "- Sleep score has a coefficient of 0.21 and p-pvalue of 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('race_df_pre_weighting.csv')\n",
    "df['sleep_duration'] = df['rem_sleep_duration'] + df['slow_wave_sleep_duration'] + df['light_sleep_duration']\n",
    "dummies = pd.get_dummies(df['user_id'], prefix='user')\n",
    "temp_df = pd.concat([df, dummies], axis=1)\n",
    "race_times = pd.read_csv('huxc_race_times.csv')\n",
    "race_times=race_times[race_times['user_id']!=2461]\n",
    "race_times=race_times[race_times['user_id']!=2509]\n",
    "reg_df = temp_df.merge(race_times, how='left')\n",
    "reg_df = reg_df[reg_df['user_id']!=2439]\n",
    "reg_df = reg_df.drop(['user_828'], axis=1)\n",
    "reg_df = reg_df.drop(df.columns[0], axis=1).reset_index(drop=True)\n",
    "\n",
    "#Use to see if each of the 5 days leading up to a race have significant variables\n",
    "reg_df0 = reg_df[reg_df['buildup_days']==0].reset_index(drop=True)\n",
    "reg_df1 = reg_df[reg_df['buildup_days']==1].reset_index(drop=True)\n",
    "reg_df2 = reg_df[reg_df['buildup_days']==2].reset_index(drop=True)\n",
    "reg_df3 = reg_df[reg_df['buildup_days']==3].reset_index(drop=True)\n",
    "reg_df4 = reg_df[reg_df['buildup_days']==4].reset_index(drop=True)\n",
    "reg_df5 = reg_df[reg_df['buildup_days']==5].reset_index(drop=True)\n",
    "reg_df6 = reg_df[reg_df['buildup_days']==6].reset_index(drop=True)\n",
    "reg_df7 = reg_df[reg_df['buildup_days']==7].reset_index(drop=True)\n",
    "reg_df8 = reg_df[reg_df['buildup_days']==8].reset_index(drop=True)\n",
    "reg_df9 = reg_df[reg_df['buildup_days']==9].reset_index(drop=True)\n",
    "reg_df10 = reg_df[reg_df['buildup_days']==10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Only showing results that came up significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ols_regressions(y_var, x_vars, df):\n",
    "    return sm.ols(formula= y_var + \"~ \" + x_vars + \" + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=df).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result1 = ols_regressions('pace_per_k', 'hrv_rmssd', reg_df0)\n",
    "result2 = ols_regressions('pace_per_k', 'resting_heart_rate', reg_df0)\n",
    "result3 = ols_regressions('pace_per_k', 'sleep_duration', reg_df0)\n",
    "result4 = ols_regressions('pace_per_k', 'rem_sleep_duration', reg_df0)\n",
    "result5 = ols_regressions('pace_per_k', 'slow_wave_sleep_duration', reg_df0)\n",
    "result6 = ols_regressions('pace_per_k', 'light_sleep_duration', reg_df0)\n",
    "result7 = ols_regressions('pace_per_k', 'time_in_bed', reg_df0)\n",
    "result8 = ols_regressions('pace_per_k', 'cycles_count', reg_df0)\n",
    "result9 = ols_regressions('pace_per_k', 'latency', reg_df0)\n",
    "result10 = ols_regressions('pace_per_k', 'score', reg_df0)\n",
    "result11 = ols_regressions('pace_per_k', 'recovery_score', reg_df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.938\n",
      "Model:                            OLS   Adj. R-squared:                  0.876\n",
      "Method:                 Least Squares   F-statistic:                     15.17\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           4.26e-06\n",
      "Time:                        11:20:22   Log-Likelihood:                -59.572\n",
      "No. Observations:                  29   AIC:                             149.1\n",
      "Df Residuals:                      14   BIC:                             169.7\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    170.8008     10.554     16.184      0.000       148.165   193.437\n",
      "score          0.2141      0.113      1.898      0.079        -0.028     0.456\n",
      "user_2456     -0.0620      3.160     -0.020      0.985        -6.840     6.716\n",
      "user_2458      5.2089      2.275      2.289      0.038         0.329    10.089\n",
      "user_2465     -3.9341      2.303     -1.708      0.110        -8.873     1.005\n",
      "user_2466      9.1933      3.388      2.714      0.017         1.928    16.459\n",
      "user_2468     -4.1544      2.303     -1.804      0.093        -9.094     0.785\n",
      "user_2469      3.2304      2.240      1.442      0.171        -1.573     8.034\n",
      "user_2473     -5.7396      2.705     -2.122      0.052       -11.541     0.061\n",
      "user_2508     16.5877      4.565      3.634      0.003         6.798    26.378\n",
      "FP_5K        -18.7163      5.802     -3.226      0.006       -31.161    -6.272\n",
      "Wisco_8K      -1.0705      2.115     -0.506      0.621        -5.606     3.465\n",
      "Brown_8K      -1.6443      2.440     -0.674      0.511        -6.877     3.588\n",
      "VCP_8K        10.6309      1.484      7.165      0.000         7.449    13.813\n",
      "FP_10K         3.3729      1.860      1.813      0.091        -0.616     7.362\n",
      "==============================================================================\n",
      "Omnibus:                        1.283   Durbin-Watson:                   2.890\n",
      "Prob(Omnibus):                  0.526   Jarque-Bera (JB):                1.001\n",
      "Skew:                          -0.191   Prob(JB):                        0.606\n",
      "Kurtosis:                       2.174   Cond. No.                     2.16e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.16e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.961\n",
      "Model:                            OLS   Adj. R-squared:                  0.922\n",
      "Method:                 Least Squares   F-statistic:                     24.64\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           1.92e-07\n",
      "Time:                        11:20:22   Log-Likelihood:                -52.888\n",
      "No. Observations:                  29   AIC:                             135.8\n",
      "Df Residuals:                      14   BIC:                             156.3\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    178.5169      3.499     51.023      0.000       171.013   186.021\n",
      "latency     6.611e-06   1.77e-06      3.729      0.002      2.81e-06  1.04e-05\n",
      "user_2456     -3.2654      1.602     -2.038      0.061        -6.702     0.171\n",
      "user_2458     10.4045      1.934      5.381      0.000         6.257    14.552\n",
      "user_2465     -2.8741      1.847     -1.556      0.142        -6.837     1.088\n",
      "user_2466      7.7169      1.880      4.104      0.001         3.684    11.750\n",
      "user_2468     -0.3142      2.175     -0.144      0.887        -4.979     4.350\n",
      "user_2469      4.3069      1.818      2.369      0.033         0.408     8.206\n",
      "user_2473     -6.0587      2.117     -2.861      0.013       -10.600    -1.517\n",
      "user_2508     13.7657      2.695      5.109      0.000         7.986    19.545\n",
      "FP_5K         -9.9378      3.256     -3.052      0.009       -16.921    -2.954\n",
      "Wisco_8K       4.8537      2.067      2.348      0.034         0.420     9.287\n",
      "Brown_8K       0.6209      1.944      0.319      0.754        -3.549     4.791\n",
      "VCP_8K        13.4088      1.494      8.976      0.000        10.205    16.613\n",
      "FP_10K         6.7021      1.352      4.956      0.000         3.802     9.602\n",
      "==============================================================================\n",
      "Omnibus:                        0.320   Durbin-Watson:                   2.743\n",
      "Prob(Omnibus):                  0.852   Jarque-Bera (JB):                0.259\n",
      "Skew:                          -0.205   Prob(JB):                        0.879\n",
      "Kurtosis:                       2.784   Cond. No.                     1.61e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.61e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2 nights before the race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- REM sleep has a very small coefficient but p-value of 0.008\n",
    "- light sleep has a very small coefficient but p-value of 0.010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = ols_regressions('pace_per_k', 'hrv_rmssd', reg_df1)\n",
    "result2 = ols_regressions('pace_per_k', 'resting_heart_rate', reg_df1)\n",
    "result3 = ols_regressions('pace_per_k', 'sleep_duration', reg_df1)\n",
    "result4 = ols_regressions('pace_per_k', 'rem_sleep_duration', reg_df1)\n",
    "result5 = ols_regressions('pace_per_k', 'slow_wave_sleep_duration', reg_df1)\n",
    "result6 = ols_regressions('pace_per_k', 'light_sleep_duration', reg_df1)\n",
    "result7 = ols_regressions('pace_per_k', 'time_in_bed', reg_df1)\n",
    "result8 = ols_regressions('pace_per_k', 'cycles_count', reg_df1)\n",
    "result9 = ols_regressions('pace_per_k', 'latency', reg_df1)\n",
    "result10 = ols_regressions('pace_per_k', 'score', reg_df1)\n",
    "result11 = ols_regressions('pace_per_k', 'recovery_score', reg_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.928\n",
      "Model:                            OLS   Adj. R-squared:                  0.868\n",
      "Method:                 Least Squares   F-statistic:                     15.58\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           5.24e-07\n",
      "Time:                        11:26:29   Log-Likelihood:                -67.927\n",
      "No. Observations:                  32   AIC:                             165.9\n",
      "Df Residuals:                      17   BIC:                             187.8\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept              173.5654      6.033     28.768      0.000       160.836   186.295\n",
      "light_sleep_duration  7.691e-07   2.67e-07      2.878      0.010      2.05e-07  1.33e-06\n",
      "user_2456               -1.3392      2.346     -0.571      0.576        -6.289     3.611\n",
      "user_2458               13.9817      3.360      4.162      0.001         6.893    21.070\n",
      "user_2465                1.2715      2.757      0.461      0.650        -4.544     7.088\n",
      "user_2466                8.4620      2.478      3.415      0.003         3.233    13.691\n",
      "user_2468               -0.2829      2.243     -0.126      0.901        -5.016     4.450\n",
      "user_2469               -0.4925      2.405     -0.205      0.840        -5.567     4.582\n",
      "user_2473               -2.8106      2.960     -0.950      0.356        -9.056     3.435\n",
      "user_2508               12.7440      3.451      3.693      0.002         5.463    20.025\n",
      "FP_5K                  -19.2335      5.343     -3.600      0.002       -30.506    -7.961\n",
      "Wisco_8K                 0.7482      1.654      0.452      0.657        -2.742     4.238\n",
      "Brown_8K                -1.2546      2.465     -0.509      0.617        -6.456     3.946\n",
      "VCP_8K                  10.6351      1.363      7.803      0.000         7.760    13.511\n",
      "FP_10K                   3.3619      1.712      1.963      0.066        -0.251     6.975\n",
      "==============================================================================\n",
      "Omnibus:                        0.653   Durbin-Watson:                   3.255\n",
      "Prob(Omnibus):                  0.721   Jarque-Bera (JB):                0.745\n",
      "Skew:                           0.268   Prob(JB):                        0.689\n",
      "Kurtosis:                       2.480   Cond. No.                     3.44e+08\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.44e+08. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pace_per_k   R-squared:                       0.930\n",
      "Model:                            OLS   Adj. R-squared:                  0.873\n",
      "Method:                 Least Squares   F-statistic:                     16.18\n",
      "Date:                Fri, 29 Jan 2016   Prob (F-statistic):           3.94e-07\n",
      "Time:                        11:26:29   Log-Likelihood:                -67.365\n",
      "No. Observations:                  32   AIC:                             164.7\n",
      "Df Residuals:                      17   BIC:                             186.7\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept            193.8482      2.067     93.771      0.000       189.487   198.210\n",
      "rem_sleep_duration -8.062e-07   2.66e-07     -3.031      0.008     -1.37e-06 -2.45e-07\n",
      "user_2456             -2.9248      2.105     -1.389      0.183        -7.366     1.516\n",
      "user_2458             13.9018      3.217      4.322      0.000         7.115    20.688\n",
      "user_2465             -2.0395      2.076     -0.983      0.340        -6.419     2.340\n",
      "user_2466              7.6845      2.264      3.395      0.003         2.908    12.461\n",
      "user_2468             -0.5360      2.165     -0.248      0.807        -5.103     4.031\n",
      "user_2469              3.3747      2.257      1.495      0.153        -1.388     8.137\n",
      "user_2473             -4.8077      2.652     -1.813      0.088       -10.403     0.787\n",
      "user_2508             11.9518      3.303      3.619      0.002         4.984    18.920\n",
      "FP_5K                -15.2605      4.492     -3.397      0.003       -24.738    -5.783\n",
      "Wisco_8K              -1.2359      1.781     -0.694      0.497        -4.994     2.522\n",
      "Brown_8K               0.1088      2.406      0.045      0.964        -4.967     5.184\n",
      "VCP_8K                 6.6155      1.972      3.355      0.004         2.455    10.776\n",
      "FP_10K                 1.9887      1.852      1.074      0.298        -1.918     5.895\n",
      "==============================================================================\n",
      "Omnibus:                        0.443   Durbin-Watson:                   2.780\n",
      "Prob(Omnibus):                  0.801   Jarque-Bera (JB):                0.299\n",
      "Skew:                           0.225   Prob(JB):                        0.861\n",
      "Kurtosis:                       2.854   Cond. No.                     7.50e+07\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.5e+07. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print result4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Regression Assumption Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x = sm.ols(formula= \"pace_per_k ~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()\n",
    "\n",
    "#def regression_assumption_plots(regression_fit):\n",
    "\n",
    "#x = sm.ols(formula= \"pace_per_k ~ rem_sleep_duration + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data=reg_df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.hist(x.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mixed Effects Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_race_df_4daysweighted.csv')\n",
    "data = data.drop([data.columns[0]], axis=1)\n",
    "\n",
    "#md = sm.mixedlm('pace_per_k ~ race_period', data = data, groups=data['user_id'])\n",
    "#md = sm.mixedlm('pace_per_k~ hrv_rmssd + race_period + user_2456 + user_2458 + user_2465 + user_2466 + user_2468 + user_2469 + user_2473 + user_2508 + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K', data, groups=data['user_id']) \n",
    "#md = sm.mixedlm(\"pace_per_k~ hrv_rmssd + FP_5K + Wisco_8K + Brown_8K + VCP_8K + FP_10K\", data, groups=data['user_id']) \n",
    "#mdf = md.fit() \n",
    "#print(mdf.summary())\n",
    "\n",
    "#data = sm.datasets.get_rdataset('dietox', 'geepack').data\n",
    "#md = smf.mixedlm(\"Weight ~ Time\", data, groups=data[\"Pig\"])\n",
    "#mdf = md.fit()\n",
    "#print mdf.summary()\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear mixed model fit by REML ['lmerMod']\r\n",
      "\r\n",
      "Formula: pace_per_k ~ rem_sleep_duration + (1 | user_id) + (1 | race_course)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "REML criterion at convergence: 218.4\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Scaled residuals: \r\n",
      "\r\n",
      "     Min       1Q   Median       3Q      Max \r\n",
      "\r\n",
      "-1.64809 -0.65615  0.08258  0.49768  1.65460 \r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Random effects:\r\n",
      "\r\n",
      " Groups      Name        Variance Std.Dev.\r\n",
      "\r\n",
      " user_id     (Intercept) 30.817   5.551   \r\n",
      "\r\n",
      " race_course (Intercept) 28.894   5.375   \r\n",
      "\r\n",
      " Residual                 8.512   2.918   \r\n",
      "\r\n",
      "Number of obs: 32, groups:  user_id, 9; race_course, 6\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Fixed effects:\r\n",
      "\r\n",
      "                     Estimate Std. Error t value\r\n",
      "\r\n",
      "(Intercept)         1.951e+02  3.198e+00   61.02\r\n",
      "\r\n",
      "rem_sleep_duration -5.764e-07  2.572e-07   -2.24\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Correlation of Fixed Effects:\r\n",
      "\r\n",
      "            (Intr)\r\n",
      "\r\n",
      "rm_slp_drtn -0.381\r\n",
      "\r\n",
      "fit warnings:\r\n",
      "\r\n",
      "Some predictor variables are on very different scales: consider rescaling\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Connect to an R session\n",
    "import rpy2.robjects\n",
    "r = rpy2.robjects.r\n",
    "\n",
    "# For a Pythonic interface to R\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import Formula\n",
    "from rpy2.robjects.environments import Environment\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "# Make it so we can send numpy arrays to R\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "#Specify path with downloaded R packages\n",
    "lib_path = 'C:/Users/BUCKBEAK/Documents/BUCKBEAK/R/win-library/3.2'\n",
    "\n",
    "# load some required packages\n",
    "utils = importr('utils')\n",
    "langR = importr('languageR', lib_loc=lib_path)\n",
    "lme4 = importr('lme4', lib_path)\n",
    "lmerTest=importr('lmerTest', lib_path)\n",
    "\n",
    "#allow to convert pandas dataframes into R dataframes\n",
    "pandas2ri.activate()\n",
    "r_reg_df0 = pandas2ri.py2ri(reg_df0)\n",
    "r_reg_df1 = pandas2ri.py2ri(reg_df1)\n",
    "r_reg_df2 = pandas2ri.py2ri(reg_df2)\n",
    "r_reg_df3 = pandas2ri.py2ri(reg_df3)\n",
    "r_reg_df4 = pandas2ri.py2ri(reg_df4)\n",
    "r_reg_df5 = pandas2ri.py2ri(reg_df5)\n",
    "r_reg_df6 = pandas2ri.py2ri(reg_df6)\n",
    "r_reg_df7 = pandas2ri.py2ri(reg_df7)\n",
    "r_reg_df8 = pandas2ri.py2ri(reg_df8)\n",
    "r_reg_df9 = pandas2ri.py2ri(reg_df9)\n",
    "r_reg_df10 = pandas2ri.py2ri(reg_df10)\n",
    "\n",
    "#confirm whether r_reg_df1 looks at 1 day before the race or two nights before the race\n",
    "datatouse = r_reg_df1\n",
    "env = Environment()\n",
    "for varname in r.colnames(datatouse):\n",
    "    env[varname] = datatouse.rx2(varname)\n",
    "\n",
    "formula = Formula('pace_per_k ~  rem_sleep_duration + (1|user_id)  + (1|race_course)',\n",
    "                  environment=env)\n",
    "model = lme4.lmer(formula)\n",
    "result = r.summary(model)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Regression  Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZgAAALICAYAAADyhJW9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a100f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('final_race_df.csv')\n",
    "y_vars_temp = df.pace_per_k.values\n",
    "y_vars = []\n",
    "for i in y_vars_temp:\n",
    "    if ~np.isnan(i):\n",
    "        y_vars.append(i)\n",
    "data = [y_vars, np.log(y_vars)]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 10), tight_layout=True)\n",
    "for ax, i in zip(axes.ravel(), range(0, len(data))):\n",
    "    ax.hist(data[i])\n",
    "    if i == 0:\n",
    "        ax.set_xlabel('Pace Per K (Seconds)')\n",
    "        ax.set_title('Pace Per K Distribution')\n",
    "    elif i == 1:\n",
    "        ax.set_xlabel('log(Pace Per K)')\n",
    "        ax.set_title('Log(Pace Per K) Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
